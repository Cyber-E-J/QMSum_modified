professor b: OK . phd c: Oh , I don't {disfmarker} phd a: I think I 'm zero . professor b: Wow ! Unprecedented . phd c: Hello , hello , hello , hello . phd e: Ah grad f: Wh - what causes the crash ? phd a: Did you fix something ? phd c: Hello . phd e: Five , five . phd c: Hello , hello . grad f: Oh , maybe it 's the turning {disfmarker} turning off and turning on of the mike , right ? professor b: Uh , you think that 's you ? Oh . phd c: Aaa - aaa - aaa . grad f: Yeah , OK , mine 's working . phd c: OK . That 's me . professor b: OK . OK . So , um I guess we are {pause} um {pause} gonna do the digits at the end . Uh phd d: Channel {disfmarker} channel three , yeah . phd c: Channel two . phd d: OK . phd e: Mmm , channel five ? Doesn't work ? professor b: Yeah , that 's the mike number there , uh {pause} Uh , mike number five , and {pause} channel {disfmarker} channel four . phd c: Two . phd a: Is it written on her sheet , I believe . phd e: No ? Ah , phd d: Mike four . grad f: Watch this . phd e: era el cuatro . grad f: Yep , that 's me . phd e: Yeah . phd a: But , channel phd e: Yeah yeah yeah . professor b: This is you . phd e: OK . I saw that . Ah {disfmarker} yeah , it 's OK . professor b: Yeah . And I 'm channel uh two I think , phd c: Ooo . professor b: or channel {disfmarker} phd c: I think I 'm channel two . professor b: Oh , I 'm channel {disfmarker} must be channel one . Channel one ? phd e: Channel {disfmarker} {vocalsound} I decided to talk about that . professor b: Yes , OK . OK . So uh {pause} I also copied uh the results that we all got in the mail I think from uh {disfmarker} {pause} from OGI and we 'll go {disfmarker} go through them also . So where are we on {disfmarker} {pause} on uh {vocalsound} {pause} our runs ? phd d: Uh so . {pause} uh {disfmarker} We {disfmarker} So {pause} As I was already said , we {disfmarker} we mainly focused on uh four kind of features . professor b: Excuse me . phd d: The PLP , the PLP with JRASTA , the MSG , and the MFCC from the baseline Aurora . professor b: Mm - hmm . phd d: Uh , and we focused for the {disfmarker} the test part on the English and the Italian . Um . We 've trained uh several neural networks on {disfmarker} so {disfmarker} on the TI - digits English {pause} and on the Italian data and also on the broad uh {pause} English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we {disfmarker} we @ @ observed is that if the network is trained on the task data it works pretty well . professor b: OK . Our {disfmarker} our uh {disfmarker} {pause} There 's a {disfmarker} {pause} We 're pausing for a photo {disfmarker} phd c: Chicken on the grill . Try that corner . phd a: How about over th from the front of the room ? phd c: Yeah , it 's longer . professor b: We 're pausing for a photo opportunity here . Uh . {vocalsound} Uh . So . grad f: Oh wait wait wait wait wait . Wait . phd c: Get out of the {disfmarker} Yeah . grad f: Hold on . Hold on . professor b: OK . grad f: Let me give you a black screen . professor b: He 's facing this way . What ? OK , this {disfmarker} this would be a {pause} good section for our silence detection . grad f: OK . phd c: Mm - hmm . professor b: Um Oh . grad f: Musical chairs everybody ! professor b: OK . So um , {pause} you were saying {pause} about the training data {disfmarker} Yeah . phd d: Yeah , so if the network is trained on the task data um {pause} tandem works pretty well . And uh actually we have uh , results are similar Only on , phd a: Do you mean if it 's trained only on {disfmarker} On data from just that task , phd d: yeah . phd a: that language ? phd d: Just that task . But actually we didn't train network on {pause} uh both types of data I mean {pause} uh {pause} phonetically ba phonetically balanced uh data and task data . phd a: Mmm . phd d: We only did either task {disfmarker} task data or {pause} uh broad {pause} data . phd a: Mm - hmm . phd d: Um {pause} Yeah . So , professor b: So how {disfmarker} I mean {disfmarker} clearly it 's gonna be good then phd a: So what 's th professor b: but the question is how much {pause} worse is it {pause} if you have broad data ? I mean , {pause} my assump From what I saw from the earlier results , uh I guess last week , {pause} was that um , {pause} if you {pause} trained on one language and tested on another , say , that {pause} the results were {disfmarker} were relatively poor . phd d: Mmm . Yeah . professor b: But {disfmarker} but the question is if you train on one language {pause} but you have a broad coverage {pause} and then test in another , {pause} does that {disfmarker} {pause} is that improve things {pause} i c in comparison ? phd d: If we use the same language ? professor b: No , no , no . Different lang So {pause} um {pause} If you train on TI - digits {pause} and test on Italian digits , {pause} you do poorly , {pause} let 's say . phd d: Mm - hmm . professor b: I don't have the numbers in front of me , phd d: But {disfmarker} Yeah but I did not uh do that . professor b: so I 'm just imagining . E So , you didn't train on {pause} TIMIT and test on {disfmarker} {pause} on Italian digits , say ? phd d: We {disfmarker} No , we did four {disfmarker} four kind of {disfmarker} of testing , actually . The first testing is {pause} with task data {disfmarker} So , with nets trained on task data . So for Italian on the Italian speech @ @ . The second test is trained on a single language um with broad database , but the same language as the t task data . professor b: OK . phd d: But for Italian we choose Spanish which {pause} we assume is close to Italian . The third test is by using , um the three language database professor b: W which in {disfmarker} phd d: and the fourth is professor b: It has three languages . That 's including the w the {disfmarker} {pause} the {disfmarker} phd d: This includes {disfmarker} professor b: the one that it 's {disfmarker} phd d: Yeah . phd a: In phd d: But {pause} not digits . I mean it 's {disfmarker} phd a: The three languages {pause} is not digits , professor b: Right . phd a: it 's the broad {pause} data . OK . phd d: Yeah And the fourth test is uh {pause} excluding from these three languages the language {pause} that is {pause} the task language . professor b: Oh , OK , yeah , so , that is what I wanted to know . phd d: Yeah . professor b: I just wasn't saying it very well , I guess . phd d: Uh , yeah . So um {pause} for uh TI - digits for ins example {pause} uh when we go from TI - digits training to {pause} TIMIT training {pause} uh we lose {pause} uh around ten percent , uh . The error rate increase u of {disfmarker} of {disfmarker} of ten percent , relative . professor b: Relative . Right . phd d: So this is not so bad . And then when we jump to the multilingual data it 's uh it become worse and , well Around uh , let 's say , {pause} twenty perc twenty percent further . professor b: Ab - about how much ? phd d: So . Yeah . professor b: Twenty percent further ? phd d: Twenty to {disfmarker} to thirty percent further . Yeah . phd a: And so , remind me , the multilingual stuff is just the broad data . Right ? It 's not the digits . phd d: Yeah . phd a: So it 's the combination of {pause} two things there . It 's {pause} removing the {pause} task specific {pause} training and {pause} it 's adding other languages . phd d: Yeah . Yeah . phd a: OK . phd d: But the first step is al already removing the task s specific from {disfmarker} from {disfmarker} phd a: Already , right right right . phd d: So . phd a: So they were sort of building {pause} here ? phd d: And we lose {disfmarker} phd a: OK ? phd d: Yeah . Uh {pause} So , basically when it 's trained on the {disfmarker} the multilingual broad data {pause} um or number {disfmarker} so , the {disfmarker} the {pause} ratio of our error rates uh with the {pause} baseline error rate is around {pause} uh one point one . professor b: Yes . {vocalsound} And it 's something like one point three of {disfmarker} of the {pause} uh {disfmarker} phd d: So . professor b: I i if you compare everything to the first case at the baseline , you get something like one point one for the {disfmarker} for the using the same language but a different task , and something like one point three {pause} for three {disfmarker} three languages {pause} broad stuff . phd d: No no no . Uh same language we are at uh {disfmarker} for at English at O point eight . So it improves , {pause} compared to the baseline . But {disfmarker} So . Le - let me . professor b: I {disfmarker} I {disfmarker} I 'm sorry . phd d: Tas - task data professor b: I {disfmarker} I {disfmarker} I meant something different by baseline phd d: we are u Yeah . professor b: So let me {disfmarker} let me {disfmarker} Um , {pause} so , {pause} um {disfmarker} phd d: Mmm . professor b: OK , fine . Let 's {disfmarker} let 's use the conventional meaning of baseline . phd d: Hmm . professor b: I {disfmarker} I {disfmarker} By baseline here I meant {pause} uh using the task specific data . phd d: Oh yeah , the f Yeah , OK . professor b: But uh {disfmarker} {pause} uh , because that 's what you were just doing with this ten percent . phd d: Yeah . professor b: So I was just {disfmarker} I just trying to understand that . phd d: Yeah . Sure . professor b: So if we call {pause} a factor of w just one , just normalized to one , the word error rate {pause} that you have {pause} for using TI - digits as {disfmarker} as {pause} training and TI - digits as test , phd d: Mmm . professor b: uh different words , I 'm sure , phd d: Mm - hmm . professor b: but {disfmarker} {pause} but uh , uh the same {pause} task and so on . phd d: Mm - hmm . professor b: If we call that " one " , {pause} then what you 're saying is {pause} that the word error rate {pause} for the same language but using {pause} uh different training data than you 're testing on , say TIMIT and so forth , {pause} it 's one point one . phd d: Mm - hmm . Yeah , it 's around one point one . professor b: Right . And if it 's {disfmarker} phd d: Yeah . professor b: you {pause} do {pause} go to {pause} three languages including the English , {pause} it 's something like one point three . That 's what you were just saying , I think . phd d: Ye Uh , more actually . phd a: One point four ? phd d: If I {disfmarker} Yeah . phd a: So , it 's an additional thirty percent . phd d: What would you say ? Around one point four professor b: OK . phd d: yeah . professor b: And if you exclude {pause} English , {pause} from this combination , what 's that ? phd d: If we exclude English , {pause} um {pause} there is {pause} not much difference with the {pause} data with English . professor b: Aha ! phd d: So . Yeah . professor b: That 's interesting . {pause} That 's interesting . Do you see ? Because {disfmarker} Uh , phd d: Uh . professor b: so {disfmarker} No , that {disfmarker} that 's important . So what {disfmarker} what it 's saying here is just that " yes , there is a reduction {pause} in performance , {pause} when you don't {pause} um {pause} have the s {pause} when you don't have {pause} um phd a: Task data . professor b: Wait a minute , th th the {disfmarker} phd d: Hmm . professor b: No , actually {pause} it 's interesting . So it 's {disfmarker} So when you go to a different task , there 's actually not so {pause} different . It 's when you went to these {disfmarker} So what 's the difference between two and three ? Between the one point one case and the one point four case ? I 'm confused . phd a: It 's multilingual . phd d: Yeah . The only difference it 's {disfmarker} is that it 's multilingual {disfmarker} Um professor b: Cuz in both {disfmarker} in both {disfmarker} both of those cases , you don't have the same task . phd d: Yeah . Yeah sure . professor b: So is {disfmarker} is the training data for the {disfmarker} for this one point four case {disfmarker} does it include the training data for the one point one case ? phd d: Uh yeah . grad f: Yeah , a fraction of it . phd d: A part of it , yeah . professor b: How m how much bigger is it ? phd d: Um {pause} It 's two times , grad f: Yeah , um . phd d: actually ? Yeah . Um . The English data {disfmarker} {pause} No , the multilingual databases are two times the {pause} broad English {pause} data . We just wanted to keep this , w well , not too huge . So . professor b: So it 's two times , but it includes the {disfmarker} but it includes the broad English data . phd d: I think so . Do you {disfmarker} Uh , Yeah . professor b: And the broad English data is what you got this one point one {pause} with . So that 's TIMIT basically right ? phd d: Yeah . grad f: Mm - hmm . professor b: So it 's band - limited TIMIT . This is all eight kilohertz sampling . phd d: Mm - hmm . grad f: Mm - hmm . phd d: Yeah . grad f: Downs Right . professor b: So you have band - limited TIMIT , {pause} gave you uh almost as good as a result as using TI - digits {pause} on a TI - digits test . OK ? phd d: Hmm ? professor b: Um {pause} and {pause} um But , {pause} when you add in more training data but keep the neural net the same size , {pause} it {pause} um performs worse on the TI - digits . OK , now all of this is {disfmarker} {pause} This is noisy {pause} TI - digits , I assume ? Both training and test ? phd d:  professor b: Yeah . OK . Um OK . Well . {pause} We {disfmarker} we {disfmarker} we may just need to uh {disfmarker} So I mean it 's interesting that h going to a different {disfmarker} different task didn't seem to hurt us that much , and going to a different language um It doesn't seem to matter {disfmarker} The difference between three and four is not particularly great , so that means that {pause} whether you have the language in or not is not such a big deal . phd d: Mmm . professor b: It sounds like um {pause} uh {pause} we may need to have more {pause} of uh things that are similar to a target language or {disfmarker} I mean . {pause} You have the same number of parameters in the neural net , you haven't increased the size of the neural net , and maybe there 's just {disfmarker} {pause} just not enough {pause} complexity to it to represent {pause} the variab increased variability in the {disfmarker} in the training set . That {disfmarker} that could be . Um {pause} So , what about {disfmarker} So these are results with {pause} uh th {pause} that you 're describing now , that {pause} they are pretty similar for the different features or {disfmarker} {pause} or uh {disfmarker} phd d: Uh , let me check . Uh . professor b: Yeah . phd d: So . This was for the PLP , professor b: Yeah . phd d: Um . The {disfmarker} Yeah . For the PLP with JRASTA the {disfmarker} {pause} the {disfmarker} we {disfmarker} This is quite the same {pause} tendency , {pause} with a slight increase of the error rate , {pause} uh if we go to {disfmarker} to TIMIT . And then it 's {disfmarker} it gets worse with the multilingual . Um . Yeah . There {disfmarker} there is a difference actually with {disfmarker} b between PLP and JRASTA is that {pause} JRASTA {pause} seems to {pause} perform better with the highly mismatched {pause} condition {pause} but slightly {disfmarker} slightly worse {pause} for the well matched condition . Mmm . professor b: I have a suggestion , actually , even though it 'll delay us slightly , would {disfmarker} would you mind {pause} running into the other room and making {pause} copies of this ? Cuz we 're all sort of {disfmarker} If we c if we could look at it , while we 're talking , I think it 'd be phd d: Yeah , yeah . OK . professor b: uh {disfmarker} {pause} Uh , I 'll {disfmarker} I 'll sing a song or dance or something while you {vocalsound} do it , too . phd a: So um {disfmarker} grad f: Alright . phd a: Go ahead . Ah , while you 're gone I 'll ask s some of my questions . professor b: Yeah . phd a: Um . professor b: Yeah . Uh , this way and just slightly to the left , yeah . phd a: The um {disfmarker} What was {disfmarker} Was this number {pause} forty or {disfmarker} It was roughly the same as this one , {pause} he said ? When you had the two language versus the three language ? professor b: Um . That 's what he was saying . phd a: That 's where he removed English , grad f: Yeah . phd a: right ? professor b: Right . grad f: It sometimes , actually , depends on what features you 're using . professor b: Yeah . But {disfmarker} but i it sounds like {disfmarker} grad f: Um , but {disfmarker} {vocalsound} {vocalsound} He {disfmarker} Mm - hmm . professor b: I mean . That 's interesting because {pause} it {disfmarker} it seems like what it 's saying is not so much that you got hurt {pause} uh because {pause} you {pause} uh didn't have so much representation of English , because in the other case you don't get hurt any more , at least when {pause} it seemed like uh it {disfmarker} it might simply be a case that you have something that is just much more diverse , phd a: Mm - hmm . professor b: but you have the same number of parameters representing it . phd a: Mm - hmm . I wonder {disfmarker} were um all three of these nets {pause} using the same output ? This multi - language {pause} uh labelling ? grad f: He was using uh sixty - four phonemes from {pause} SAMPA . phd a: OK , OK . grad f: Yeah . phd a: So this would {disfmarker} {pause} From this you would say , " well , it doesn't really matter if we put Finnish {pause} into {pause} the training of the neural net , {pause} if there 's {pause} gonna be , {pause} you know , Finnish in the test data . " Right ? professor b: Well , it 's {disfmarker} it sounds {disfmarker} {pause} I mean , we have to be careful , cuz we haven't gotten a good result yet . phd a: Yeah . professor b: And comparing different bad results can be {pause} tricky . phd a: Hmm . professor b: But I {disfmarker} I {disfmarker} I {disfmarker} {pause} I think it does suggest that it 's not so much uh {pause} uh cross {pause} language as cross type of speech . phd a: Mm - hmm . professor b: It 's {disfmarker} it 's um {disfmarker} {vocalsound} But we did {disfmarker} Oh yeah , the other thing I was asking him , though , is that I think that in the case {disfmarker} Yeah , you {disfmarker} you do have to be careful because of com compounded results . I think we got some earlier results {pause} in which you trained on one language and tested on another and you didn't have {pause} three , but you just had one {pause} language . So you trained on {pause} one type of digits and tested on another . Didn - Wasn't there something of that ? Where you , {pause} say , trained on Spanish and tested on {disfmarker} on TI - digits , or the other way around ? Something like that ? phd e: No . professor b: I thought there was something like that , {pause} that he showed me {pause} last week . We 'll have to wait till we get {disfmarker} phd a: Yeah , that would be interesting . professor b: Um , This may have been what I was asking before , Stephane , but {disfmarker} {pause} but , um , wasn't there something that you did , {pause} where you trained {pause} on one language and tested on another ? I mean no {disfmarker} no mixture but just {disfmarker} grad f: I 'll get it for you . phd d: Uh , no , no . professor b: We 've never just trained on one lang phd d: Training on a single language , you mean , and testing on the other one ? professor b: Yeah . phd d: Uh , no . phd e: Not yet . phd d: So the only {pause} task that 's similar to this is the training on two languages , and {comment} that {disfmarker} professor b: But we 've done a bunch of things where we just trained on one language . Right ? I mean , you haven't {disfmarker} you haven't done all your tests on multiple languages . phd d: Uh , No . Either thi this is test with {pause} uh the same language {pause} but from the broad data , or it 's test with {pause} uh different languages also from the broad data , excluding the {disfmarker} So , it 's {disfmarker} it 's three or {disfmarker} three and four . phd e: The early experiment that {disfmarker} phd a: Did you do different languages from digits ? phd d: Uh . No . You mean {pause} training digits {pause} on one language and using the net {pause} to recognize on the other ? phd a: Digits on another language ? phd d: No . professor b: See , I thought you showed me something like that last week . You had a {disfmarker} you had a little {disfmarker} phd d: Uh , {pause} No , I don't think so . professor b: Um What {disfmarker} phd c: These numbers are uh {pause} ratio to baseline ? professor b: So , I mean wha what 's the {disfmarker} phd d: So . professor b: This {disfmarker} this chart {disfmarker} this table that we 're looking at {pause} is um , show is all testing for TI - digits , or {disfmarker} ? grad f: Bigger is worse . phd d: So you have uh basically two {pause} uh parts . grad f: This is error rate , I think . phd c: Ratio . grad f: No . {pause} No . phd d: The upper part is for TI - digits grad f: Yeah , yeah , yeah . phd d: and it 's divided in three {pause} rows {pause} of four {disfmarker} four rows each . grad f: Mm - hmm . professor b: Yeah . phd d: And the first four rows is well - matched , then the s the second group of four rows is mismatched , and {pause} finally highly mismatched . And then the lower part is for Italian and it 's the same {disfmarker} {pause} the same thing . phd a: So , so the upper part is training {pause} TI - digits ? phd d: So . It 's {disfmarker} it 's the HTK results , I mean . So it 's {pause} HTK training testings {pause} with different kind of features phd a: Ah . phd d: and what appears in the {pause} uh left column is {pause} the networks that are used for doing this . professor b: Hmm . phd d: So . Uh Yeah . professor b: Well , What was is that i What was it that you had {pause} done {pause} last week when you showed {disfmarker} Do you remember ? Wh - when you showed me {pause} the {disfmarker} your table last week ? phd d: It - It was part of these results . Mmm . Mmm . phd a: So where is the baseline {pause} for the TI - digits {pause} located in here ? phd d: You mean the HTK Aurora baseline ? phd a: Yeah . phd d: It 's uh the one hundred number . It 's , well , all these numbers are the ratio {pause} with respect to the baseline . phd a: Ah ! Ah , OK , OK . professor b: So this is word {disfmarker} word error rate , so a high number is bad . phd d: Yeah , this is {pause} a word error rate ratio . phd e: Yeah . phd a: OK , I see . phd d: Yeah . So , seventy point two means that {pause} we reduced the error rate uh by thirty {disfmarker} thirty percent . phd a: OK , OK , gotcha . phd d: So . professor b: OK , {vocalsound} so if we take phd d: Hmm . professor b: uh um let 's see PLP {pause} uh with on - line {pause} normalization and {pause} delta - del so that 's this thing you have circled here {pause} in the second column , phd d: Yeah . professor b: um {pause} and " multi - English " refers to what ? phd d: To TIMIT . Mmm . Then you have {pause} uh MF , {pause} MS and ME which are for French , Spanish and English . And , yeah . Actually I {disfmarker} {pause} I uh forgot to say that {pause} the multilingual net are trained {pause} on {pause} uh {pause} features without the s derivatives uh but with {pause} increased frame numbers . Mmm . And we can {disfmarker} we can see on the first line of the table that it {disfmarker} it {disfmarker} {pause} it 's slightly {disfmarker} slightly worse when we don't use delta but it 's not {disfmarker} {pause} not that much . professor b: Right . So w w So , I 'm sorry . I missed that . What 's MF , MS and ME ? phd a: Multi - French , Multi - Spanish phd d: So . Multi - French , Multi - Spanish , and Multi - English . professor b: Uh OK . So , it 's {pause} uh {pause} broader vocabulary . Then {disfmarker} And {disfmarker} phd d: Yeah . professor b: OK so I think what I 'm {disfmarker} what I saw in your smaller chart that I was thinking of was {disfmarker} was {pause} there were some numbers I saw , I think , that included these multiple languages and it {disfmarker} and I was seeing {pause} that it got worse . I {disfmarker} I think that was all it was . You had some very limited results that {disfmarker} at that point phd d: Yeah . professor b: which showed {pause} having in these {disfmarker} these other languages . In fact it might have been just this last category , {pause} having two languages broad that were {disfmarker} where {disfmarker} where English was removed . So that was cross language and the {disfmarker} and the result was quite poor . What I {disfmarker} {pause} we hadn't seen yet was that if you added in the English , it 's still poor . phd d: Yeah . professor b: Uh {vocalsound} {vocalsound} Um now , what 's the noise condition {pause} um {pause} of the training data {disfmarker} phd d: Still poor . professor b: Well , I think this is what you were explaining . The noise condition is the same {disfmarker} It 's the same uh Aurora noises uh , in all these cases {pause} for the training . phd d: Yeah . Yeah . professor b: So there 's not a {pause} statistical {disfmarker} sta a strong st {pause} statistically different {pause} noise characteristic between {pause} uh the training and test phd d: No these are the s s s same noises , professor b: and yet we 're seeing some kind of effect {disfmarker} phd d: yeah . At least {disfmarker} at least for the first {disfmarker} {pause} for the well - matched , grad f: Well matched condition . professor b: Right . phd d: yeah . professor b: So there 's some kind of a {disfmarker} a {disfmarker} an effect from having these {disfmarker} uh this broader coverage um Now I guess what we should try doing with this is try {pause} testing these on u this same sort of thing on {disfmarker} you probably must have this {pause} lined up to do . To try the same t {pause} with the exact same training , do testing on {pause} the other languages . phd d: Mmm . professor b: On {disfmarker} on um {disfmarker} So . Um , oh I well , wait a minute . You have this here , for the Italian . That 's right . OK , so , {pause} So . phd d: Yeah . Yeah , so for the Italian the results are {vocalsound} uh {pause} stranger um {pause} Mmm . So what appears is that perhaps Spanish is {pause} not very close to Italian because uh , well , {pause} when using the {disfmarker} the network trained only on Spanish it 's {disfmarker} {pause} the error rate is {pause} almost uh twice {pause} the baseline error rate . professor b: Mm - hmm . phd d: Mmm . {vocalsound} Uh . professor b: Well , I mean , let 's see . Is there any difference in {disfmarker} So it 's in {pause} the uh {disfmarker} So you 're saying that {pause} when you train on English {pause} and {pause} uh {pause} and {disfmarker} and test on {disfmarker} phd d: Yeah . professor b: No , you don't have training on English testing {disfmarker} phd d: There {disfmarker} there is {disfmarker} another difference , is that the noise {disfmarker} the noises are different . professor b: In {disfmarker} in what ? phd d: Well , For {disfmarker} for the Italian part I mean the {pause} uh {pause} the um {pause} networks are trained with noise from {pause} Aurora {disfmarker} TI - digits , phd e: Aurora - two . phd d: mmm . professor b: And the noise is different in th phd d: Yeah . And perhaps the noise are {pause} quite different from the noises {pause} in the speech that Italian . professor b: Do we have any um {pause} test sets {pause} uh in {pause} any other language that um have the same noise as in {pause} the Aurora ? phd d: And {disfmarker} phd e: Mmm , no . phd d: No . phd a: Can I ask something real quick ? In {disfmarker} in the upper part {disfmarker} {pause} in the English {pause} stuff , {pause} it looks like the very best number is sixty point nine ? and that 's in the uh {disfmarker} {pause} the third {pause} section in the upper part under PLP JRASTA , sort of the middle column ? phd d: Yeah . phd a: I is that {pause} a noisy condition ? phd d: Yeah . phd a: So that 's matched training ? Is that what that is ? phd d: It 's {disfmarker} no , the third part , so it 's uh {pause} highly mismatched . So . Training and {pause} test noise are different . phd a: So {disfmarker} why do you get your best number in {disfmarker} Wouldn't you get your best number in the clean case ? phd c: Well , it 's relative to the um {pause} baseline mismatching phd d: Yeah . phd a: Ah , phd d: Yeah . Yeah . phd a: OK so these are not {disfmarker} OK , alright , I see . phd c: Yeah . phd a: OK . And then {disfmarker} so , in the {disfmarker} in the um {disfmarker} {pause} in the {pause} non - mismatched clean case , {pause} your best one was under MFCC ? That sixty - one point four ? phd d: Yeah . {pause} But it 's not a clean case . It 's {pause} a noisy case but {pause} uh training and test noises are the same . phd a: Oh ! So this upper third ? phd d: So {disfmarker} Yeah . phd a: Uh that 's still noisy ? phd d: Yeah . phd a: Ah , OK . phd d: So it 's always noisy basically , phd a: Mm - hmm . phd d: and , {pause} well , the {disfmarker} phd a: I see . phd d: Mmm . professor b: OK ? Um {pause} So uh , I think this will take some {pause} looking at , thinking about . But , {pause} what is uh {disfmarker} what is currently running , that 's {disfmarker} uh , i that {disfmarker} just filling in the holes here or {disfmarker} or {disfmarker} ? {comment} {pause} pretty much ? phd d: Uh , no we don't plan to fill the holes professor b: OK . phd d: but {pause} actually there is something important , is that {pause} um we made a lot of assumption concerning the on - line normalization and we just noticed {pause} uh recently that {pause} uh the {pause} approach that we were using {pause} was not {pause} uh {pause} leading to very good results {pause} when we {pause} used the straight features to HTK . Um {pause} {pause} Mmm . So basically d {pause} if you look at the {disfmarker} at the left of the table , {pause} the first uh row , {pause} with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian {pause} uh with {pause} straight {pause} mmm , PLP features {pause} using on - line normalization . professor b: Mm - hmm . phd d: Mmm . And the , mmm {disfmarker} what 's {pause} in the table , just {pause} at the left of the PLP twelve {pause} on - line normalization column , so , the numbers seventy - nine , fifty - four and {pause} uh forty - two {pause} are the results obtained by uh Pratibha with {pause} uh his on - line normalization {disfmarker} uh her on - line normalization approach . phd a: Where is that ? seventy - nine , fifty professor b: Uh , it 's just sort of sitting right on the uh {disfmarker} the column line . phd d: So . phd e: Fifty - one ? This {disfmarker} phd a: Oh I see , OK . professor b: Uh . {pause} Yeah . phd d: Just {disfmarker} uh Yeah . So these are the results of {pause} OGI with {pause} on - line normalization and straight features to HTK . And the previous result , eighty - six and so on , {pause} are with our {pause} features straight to HTK . professor b: Yes . Yes . phd d: So {pause} what we see that {disfmarker} is {disfmarker} there is that um {pause} uh the way we were doing this was not correct , but {pause} still {pause} the networks {pause} are very good . When we use the networks {pause} our number are better that {pause} uh Pratibha results . phd e: We improve . professor b: So , do you know what was wrong with the on - line normalization , or {disfmarker} ? phd d: Yeah . There were diff there were different things and {pause} basically , {pause} the first thing is the mmm , {pause} alpha uh {pause} value . So , the recursion {pause} uh {pause} part . um , {pause} I used point five percent , {pause} which was the default value in the {disfmarker} {pause} in the programs here . And Pratibha used five percent . professor b: Uh phd d: So it adapts more {pause} quickly professor b: Yes . Yeah . phd d: Um , but , yeah . I assume that this was not important because {pause} uh previous results from {disfmarker} from Dan and {disfmarker} show that basically {pause} the {pause} both {disfmarker} both values g give the same {disfmarker} same {pause} uh results . It was true on uh {pause} TI - digits but it 's not true on Italian . professor b: Mm - hmm . phd d: Uh , second thing is the initialization of the {pause} stuff . Actually , {pause} uh what we were doing is to start the recursion from the beginning of the {pause} utterance . And using initial values that are the global mean and variances {pause} measured across the whole database . professor b: Right . Right . phd d: And Pratibha did something different is that he {disfmarker} uh she initialed the um values of the mean and variance {pause} by computing {pause} this on the {pause} twenty - five first frames of each utterance . Mmm . There were other minor differences , the fact that {pause} she used fifteen dissities instead s instead of thirteen , and that she used C - zero instead of log energy . Uh , but the main differences concerns the recursion . So . {pause} Uh , I changed the code uh and now we have a baseline that 's similar to the OGI baseline . professor b: OK . phd d: We {disfmarker} It {disfmarker} it 's slightly {pause} uh different because {pause} I don't exactly initialize the same way she does . Actually I start , {pause} mmm , I don't wait to a fifteen {disfmarker} twenty - five {disfmarker} twenty - five frames {pause} before computing a mean and the variance {pause} to e to {disfmarker} to start the recursion . phd c: Mm - hmm . professor b: Yeah . phd d: I {disfmarker} I use the on - line scheme and only start the re recursion after the twenty - five {disfmarker} {pause} twenty - fifth frame . But , well it 's similar . So {pause} uh I retrained {pause} the networks with {pause} these {disfmarker} well , the {disfmarker} the {disfmarker} the networks are retaining with these new {pause} features . professor b: Mm - hmm . phd d: And , yeah . professor b: OK . phd d: So basically what I expect is that {pause} these numbers will a little bit go down but {pause} perhaps not {disfmarker} not so much professor b: Right . phd d: because {pause} I think the neural networks learn perhaps {pause} to {disfmarker} professor b: Right . phd d: even if the features are not {pause} normalized . It {disfmarker} it will learn how to normalize and {disfmarker} professor b: OK , but I think that {pause} given the pressure of time we probably want to draw {disfmarker} because of that {pause} especially , we wanna draw some conclusions from this , do some reductions {pause} in what we 're looking at , phd d: Yeah . professor b: and make some strong decisions for what we 're gonna do testing on before next week . So do you {disfmarker} are you {disfmarker} w did you have something going on , on the side , with uh multi - band {pause} or {disfmarker} on {disfmarker} on this , phd d: Yeah {vocalsound} I professor b: or {disfmarker} ? phd d: No , I {disfmarker} we plan to start this uh so , act actually we have discussed uh {pause} @ @ um , these {disfmarker} what we could do {pause} more as a {disfmarker} as a research and {disfmarker} {pause} and {pause} we were thinking perhaps that {pause} uh {pause} the way we use the tandem is not {disfmarker} Uh , well , there is basically perhaps a flaw in the {disfmarker} in the {disfmarker} the stuff because {pause} we {pause} trained the networks {disfmarker} If we trained the networks on the {disfmarker} on {pause} a language and a t or a specific {pause} task , professor b: Mm - hmm . phd d: um , what we ask is {disfmarker} to the network {disfmarker} is to put the bound the decision boundaries somewhere in the space . professor b: Mmm . phd d: And uh {pause} mmm and ask the network to put one , {pause} at one side of the {disfmarker} for {disfmarker} for a particular phoneme at one side of the boundary {disfmarker} decision boundary and one for another phoneme at the other side . And {pause} so there is kind of reduction of the information there that 's not correct because if we change task {pause} and if the phonemes are not in the same context in the new task , {pause} obviously the {pause} decision boundaries are not {disfmarker} {pause} should not be at the same {pause} place . professor b: I di phd d: But the way the feature gives {disfmarker} The {disfmarker} the way the network gives the features is that it reduce completely the {disfmarker} {pause} it removes completely the information {disfmarker} {pause} a lot of information from the {disfmarker} the features {pause} by uh {pause} uh {pause} placing the decision boundaries at {pause} optimal places for {pause} one kind of {pause} data but {pause} this is not the case for another kind of data . professor b: It 's a trade - off , phd d: So {disfmarker} professor b: right ? Any - anyway go ahead . phd d: Yeah . So uh what we were thinking about is perhaps {pause} um one way {pause} to solve this problem is increase the number of {pause} outputs of the neural networks . Doing something like , um {pause} um phonemes within context and , well , basically context dependent phonemes . professor b: Maybe . I mean , I {disfmarker} I think {pause} you could make {pause} the same argument , it 'd be just as legitimate , {pause} for hybrid systems {pause} as well . Right . phd d: Yeah but , we know that {disfmarker} professor b: And in fact , {pause} th things get better with context dependent {pause} versions . Right ? phd d: Ye - yeah but here it 's something different . We want to have features professor b: Yeah . phd d: uh well , {pause} um . professor b: Yeah , but it 's still true {pause} that what you 're doing {pause} is you 're ignoring {disfmarker} you 're {disfmarker} you 're coming up with something to represent , {pause} whether it 's a distribution , {pause} probability distribution or features , you 're coming up with a set of variables {pause} that are representing {pause} uh , {pause} things that vary w over context . phd d: Mm - hmm . professor b: Uh , and you 're {pause} putting it all together , ignoring the differences in context . That {disfmarker} that 's true {pause} for the hybrid system , it 's true for a tandem system . So , for that reason , when you {disfmarker} in {disfmarker} in {disfmarker} in a hybrid system , {pause} when you incorporate context one way or another , {pause} you do get better scores . phd d: Yeah . professor b: OK ? But I {disfmarker} it 's {disfmarker} it 's a big deal {pause} to get that . I {disfmarker} I 'm {disfmarker} I 'm sort of {disfmarker} And once you {disfmarker} the other thing is that once you represent {disfmarker} start representing more and more context {pause} it is {pause} uh {pause} much more {pause} um specific {pause} to a particular task in language . So um Uh , the {disfmarker} {pause} the acoustics associated with {pause} uh a particular context , for instance you may have some kinds of contexts that will never occur {pause} in one language and will occur frequently in the other , so the qu the issue of getting enough training {pause} for a particular kind of context becomes harder . We already actually don't have a huge amount of training data um phd d: Yeah , but {disfmarker} mmm , I mean , {pause} the {disfmarker} the way we {disfmarker} we do it now is that we have a neural network and {pause} basically {pause} the net network is trained almost to give binary decisions . professor b: Right . phd d: And {pause} uh {disfmarker} binary decisions about phonemes . Nnn {disfmarker} Uh It 's {disfmarker} professor b: Almost . But I mean it {disfmarker} it {disfmarker} it does give a distribution . phd d: Yeah . professor b: It 's {disfmarker} and {disfmarker} and {pause} it is true that if there 's two phones that are very similar , {pause} that {pause} uh {pause} the {disfmarker} {pause} i it may prefer one but it will {pause} give a reasonably high value to the other , too . phd d: Yeah . Yeah , sure but uh {pause} So basically it 's almost binary decisions and {pause} um the idea of using more {pause} classes is {pause} to {pause} get something that 's {pause} less binary decisions . professor b: Oh no , but it would still be even more of a binary decision . It {disfmarker} it 'd be even more of one . Because then you would say {pause} that in {disfmarker} that this phone in this context is a one , {pause} but the same phone in a slightly different context is a zero . phd d: But {disfmarker} yeah , but {disfmarker} professor b: That would be even {disfmarker} even more distinct of a binary decision . I actually would have thought you 'd wanna go the other way and have fewer classes . phd d: Yeah , but if {disfmarker} professor b: Uh , I mean for instance , the {disfmarker} the thing I was arguing for before , but again which I don't think we have time to try , {pause} is something in which you would modify the code so you could train to have several outputs on and use articulatory features phd d: Mmm . Mm - hmm . professor b: cuz then that would {disfmarker} that would go {disfmarker} {pause} that would be much broader and cover many different situations . But if you go to very very fine categories , it 's very {pause} binary . phd d: Mmm . Yeah , but I think {disfmarker} Yeah , perhaps you 're right , but you have more classes so {pause} you {disfmarker} you have more information in your features . So , {vocalsound} Um {pause} You have more information in the {pause} uh professor b: Mm - hmm . True . phd d: posteriors vector um which means that {disfmarker} But still the information is relevant professor b: Mm - hmm . phd d: because it 's {disfmarker} it 's information that helps to discriminate , professor b: Mm - hmm . phd d: if it 's possible to be able to discriminate {pause} among the phonemes in context . professor b: Well it 's {disfmarker} it 's {disfmarker} {pause} it 's an interesting thought . phd d: But the {disfmarker} professor b: I mean we {disfmarker} we could disagree about it at length phd d: Mmm . professor b: but the {disfmarker} the real thing is if you 're interested in it you 'll probably try it phd d: Mmm . professor b: and {disfmarker} {pause} and {pause} we 'll see . But {disfmarker} but what I 'm more concerned with now , as an operational level , is {pause} uh , you know , phd d: Mmm . professor b: what do we do in four or five days ? Uh , and {disfmarker} {pause} so we have {pause} to be concerned {pause} with Are we gonna look at any combinations of things , you know once the nets get retrained so you have this problem out of it . phd d: Mmm . professor b: Um , are we going to look at {pause} multi - band ? Are we gonna look at combinations of things ? Uh , what questions are we gonna ask , uh now that , I mean , {pause} we should probably turn shortly to this O G I note . Um , how are we going to {pause} combine {pause} with what they 've been focusing on ? Uh , {pause} Uh we haven't been doing any of the L D A RASTA sort of thing . phd d: Mm - hmm . professor b: And they , although they don't talk about it in this note , um , {pause} there 's um , {pause} the issue of the {pause} um Mu law {pause} business {pause} uh {pause} versus the logarithm , um , {pause} so . phd d: Mm - hmm . professor b: So what i what is going on right now ? What 's right {disfmarker} you 've got {pause} nets retraining , Are there {disfmarker} is there {disfmarker} are there any H T K {pause} trainings {disfmarker} testings going on ? phd d: N phd e: I {disfmarker} I {disfmarker} I 'm trying the HTK with eh , {pause} PLP twelve on - line delta - delta and MSG filter {pause} together . professor b: The combination , I see . phd e: The combination , yeah . But I haven't result {vocalsound} at this moment . professor b: MSG and {disfmarker} and PLP . phd e: Yeah .  professor b: And is this with the revised {pause} on - line normalization ? phd e: Ye - Uh , with the old {pause} older , phd d: Yeah . professor b: Old one . So it 's using all the nets for that phd e: yeah . professor b: but again we have the hope that it {disfmarker} {pause} We have the hope that it {disfmarker} {pause} maybe it 's not making too much difference , phd e: Yeah . But {pause} We can know soon . professor b: but {disfmarker} but phd e: Maybe . professor b: yeah . phd e: I don't know . phd d: Yeah . professor b: Uh , OK . phd d: Uh so there is this combination , yeah . Working on combination obviously . phd e: Mm - hmm . phd d: Um , I will start work on multi - band . And {pause} we {pause} plan to work also on the idea of using both {pause} features {pause} and net outputs . phd e:  phd d: Um . And {pause} we think that {pause} with this approach perhaps {pause} we could reduce the number of outputs of the neural network . Um , So , get simpler networks , because we still have the features . So we have um {pause} come up with um {pause} different kind of {pause} broad phonetic categories . And we have {disfmarker} Basically we have three {pause} types of broad phonetic classes . Well , something using place of articulation which {disfmarker} which leads to {pause} nine , I think , {pause} broad classes . Uh , another which is based on manner , which is {disfmarker} is also something like nine classes . And then , {pause} something that combine both , and we have {pause} twenty f {pause} twenty - five ? grad f: Twenty - seven . phd d: Twenty - seven broad classes . So like , uh , oh , I don't know , like back vowels , front vowels . professor b: So what you do {disfmarker} um I just wanna understand phd d: Um For the moments we do not {disfmarker} don't have nets , professor b: so {pause} You have two net or three nets ? Was this ? How many {disfmarker} how many nets do you have ? No nets . phd d: I mean , {pause} It 's just {disfmarker} Were we just changing {pause} the labels to retrain nets {pause} with fewer out outputs . phd e: Begin to work in this . We are @ @ . professor b: Right . But {disfmarker} but I didn't understand {disfmarker} phd d: And then {disfmarker} Mm - hmm . professor b: Uh . {pause} the software currently just has {disfmarker} uh a {disfmarker} allows for I think , the one {disfmarker} one hot output . So you 're having multiple nets and combining them , or {disfmarker} ? Uh , how are you {disfmarker} how are you coming up with {disfmarker} If you say {pause} uh {pause} If you have a place {pause} characteristic and a manner characteristic , how do you {disfmarker} phd d: It - It 's the single net , phd a: I think they have one output . phd d: yeah . professor b: Oh , it 's just one net . phd d: It 's one net with {pause} um {pause} twenty - seven outputs phd e: Yeah . grad f: mm - hmm phd d: if we have twenty - seven classes , professor b: I see . I see , OK . phd d: yeah . So it 's {disfmarker} Well , it 's basically a standard net with fewer {pause} classes . professor b: So you 're sort of going the other way of what you were saying a bit ago instead of {disfmarker} yeah . phd d: Yeah , but I think {disfmarker} Yeah . B b including the features , yeah . grad f: But including the features . phd e: Yeah . phd d: I don't think this {pause} will work {pause} alone . I think it will get worse because Well , I believe the effect that {disfmarker} of {disfmarker} of too reducing too much the information is {pause} basically {disfmarker} basically what happens professor b: Uh - huh . phd d: and {disfmarker} professor b: But you think if you include that {pause} plus the other features , phd d: but {disfmarker} Yeah , because {pause} there is perhaps one important thing that the net {pause} brings , and OGI show showed that , is {pause} the distinction between {pause} sp speech and silence Because these nets are trained on well - controlled condition . I mean the labels are obtained on clean speech , and we add noise after . So this is one thing And But perhaps , something intermediary using also {pause} some broad classes could {disfmarker} could bring so much more information . Uh . professor b: So {disfmarker} so again then we have these broad classes and {disfmarker} well , somewhat broad . I mean , it 's twenty - seven instead of sixty - four , {pause} basically . And you have the original features . phd d: Yeah . professor b: Which are PLP , or something . phd d: Yeah . professor b: And then uh , just to remind me , all of that goes {pause} into {disfmarker} uh , that all of that is transformed by uh , uh , K - KL or something , or {disfmarker} ? phd d: Mm - hmm . There will probably be , phd e: Mu . phd d: yeah , one single KL to transform everything professor b: Right . phd d: or {vocalsound} {pause} uh , phd e: No transform the PLP phd d: per phd e: and only transform the other I 'm not sure . professor b: Well no , phd d: This is {pause} still something {pause} that professor b: I think {disfmarker} I see . phd d: yeah , we {pause} don't know {disfmarker} professor b: So there 's a question of whether you would {disfmarker} phd e: Two e @ @ it 's one . phd d: Yeah . professor b: Right . Whether you would transform together or just one . Yeah . Might wanna try it both ways . But that 's interesting . So that 's something that you 're {disfmarker} you haven't trained yet but are preparing to train , and {disfmarker} phd d: Yeah . professor b: Yeah . Um {pause} {pause} Yeah , so I think Hynek will be here Monday . phd d: Mmm . professor b:  Monday or Tuesday . So phd d: Uh , yeah . professor b: So I think , you know , we need to {pause} choose the {disfmarker} choose the experiments carefully , so we can get uh key {disfmarker} {pause} key questions answered {pause} uh before then phd d: Mm - hmm . professor b: and {pause} leave other ones aside even if it {pause} leaves incomplete {pause} tables {vocalsound} {pause} someplace , uh {pause} uh , it 's {disfmarker} it 's really time to {disfmarker} {pause} time to choose . phd d: Mm - hmm . professor b: Um , let me pass this out , {pause} by the way . Um These are {disfmarker} Did {disfmarker} did {disfmarker} {pause} did I interrupt you ? phd e: Yeah , I have one . professor b: Were there other things that you wanted to {disfmarker} phd d: Uh , no . I don't think so . phd e:  phd d: Yeah , I have one . grad g: Oh , thanks . professor b: Ah ! {pause} OK . {pause} OK , we have {pause} lots of them . phd e: We have one .  professor b: OK , so {vocalsound} um , Something I asked {disfmarker} So they 're {disfmarker} they 're doing {pause} the {disfmarker} the VAD I guess they mean voice activity detection So again , it 's the silence {disfmarker} So they 've just trained up a net {pause} which has two outputs , I believe . Um {vocalsound} I asked uh {pause} Hynek whether {disfmarker} I haven't talked to Sunil {disfmarker} I asked Hynek whether {pause} they compared that to {pause} just taking the nets we already had {pause} and summing up the probabilities . phd d: Mm - hmm . professor b: Uh . {pause} To get the speech {disfmarker} voice activity detection , or else just using the silence , {pause} if there 's only one {pause} silence output . Um {pause} And , he didn't think they had , um . But on the other hand , maybe they can get by with a smaller net and {pause} maybe {pause} sometimes you don't run the other , maybe there 's a computational advantage to having a separate net , anyway . phd d: Mm - hmm . professor b: So um Their uh {disfmarker} {pause} the results look pretty good . Um , {pause} I mean , not uniformly . phd d: Yeah . professor b: I mean , there 's a {disfmarker} an example or two {pause} that you can find , where it made it slightly worse , but {pause} uh in {disfmarker} in all but a couple {pause} examples . phd d: Mmm . professor b: Uh . phd e: But they have a question of the result . Um how are trained the {disfmarker} the LDA filter ? How obtained the LDA filter ? phd d: Mmm . professor b: I I 'm sorry . I don't understand your question . phd e: Yes , um the LDA filter {pause} needs some {pause} training set {pause} to obtain the filter . Maybe I don't know exactly how {pause} they are obtained . professor b: It 's on {pause} training . phd e: Training , with the training test of each {disfmarker} You understand me ? professor b: No . phd e: Yeah , uh for example , {pause} LDA filter {pause} need a set of {disfmarker} {pause} a set of training {pause} to obtain the filter . professor b: Yes . phd e: And maybe {pause} for the Italian , for the TD {pause} TE on for Finnish , these filter are {disfmarker} are obtained with their own training set . professor b: Yes , I don't know . That 's {disfmarker} that 's {disfmarker} so that 's a {disfmarker} that 's a very good question , then {disfmarker} now that it {disfmarker} {pause} I understand it . It 's " yeah , where does the LDA come from ? " In the {disfmarker} In {pause} earlier experiments , they had taken LDA {pause} from a completely different database , right ? phd e: Yeah . Yeah , because maybe it the same situation that the neural network training with their own phd d: Mmm . phd e: set . professor b: So that 's a good question . Where does it come from ? Yeah , I don't know . Um , {pause} but uh to tell you the {pause} truth , I wasn't actually looking at the LDA so much when I {disfmarker} I was looking at it I was {pause} mostly thinking about the {disfmarker} {pause} the VAD . And um , it ap {pause} it ap Oh what does {disfmarker} what does ASP ? Oh that 's {disfmarker} phd d: The features , yeah . Yeah . phd e: I don't understand also professor b: It says " baseline ASP " . phd e: what is {disfmarker} {pause} what is the difference between ASP and uh baseline over ? phd c: ASP . phd d: Yeah , I don't know . phd e: This is {disfmarker} professor b: Anybody know {pause} any {disfmarker} phd c: Oh . There it is . professor b: Um Cuz there 's " baseline Aurora " {pause} above it . phd c: Mm - hmm . professor b: And it 's {disfmarker} This is mostly better than baseline , although in some cases it 's a little worse , in a couple cases . phd c: Well , it says baseline ASP is twenty - three mill {pause} minus thirteen . phd e: Yeah . professor b: Yeah , it says what it is . But I don't how that 's different {pause} from {disfmarker} phd c: From the baseline . {comment} OK . professor b: I think this was {disfmarker} {pause} I think this is the same point we were at when {disfmarker} when we were up in Oregon . phd e: Yeah . phd d: I think {disfmarker} {pause} I think it 's the C - zero {disfmarker} using C - zero instead of log energy . phd e: Ah , OK , mm - hmm . phd d: Yeah , it 's this . professor b: Oh . OK . phd e: yeah . phd d: It should be that , yeah . phd a: They s they say in here that the VAD is not used as an additional feature . professor b: Shouldn't it be {disfmarker} phd d: Because {disfmarker} phd a: Does {disfmarker} does anybody know how they 're using it ? professor b: Yeah . So {disfmarker} so what they 're doing here is , {pause} i phd d: Yeah . professor b: if you look down at the block diagram , {pause} um , {pause} they estimate {disfmarker} they get a {disfmarker} {pause} they get an estimate {pause} of whether it 's speech or silence , phd a: But that {disfmarker} professor b: and then they have a median filter of it . phd a: Mm - hmm . professor b: And so um , {pause} basically they 're trying to find stretches . The median filter is enforcing a {disfmarker} i it having some continuity . phd a: Mm - hmm . professor b: You find stretches where the {pause} combination of the {pause} frame wise VAD and the {disfmarker} {pause} the median filter say that there 's a stretch of silence . And then it 's going through and just throwing the data away . phd c: Hmm . professor b: Right ? So um {disfmarker} phd a: So it 's {disfmarker} it 's {disfmarker} I don't understand . You mean it 's throwing out frames ? Before {disfmarker} professor b: It 's throwing out chunks of frames , yeah . There 's {disfmarker} the {disfmarker} the median filter is enforcing that it 's not gonna be single cases of frames , or isolated frames . phd a: Yeah . professor b: So it 's throwing out frames and the thing is {pause} um , {pause} what I don't understand is how they 're doing this with H T phd a: Yeah , that 's what I was just gonna ask . professor b: This is {disfmarker} phd a: How can you just throw out frames ? professor b: Yeah . Well , you {disfmarker} you can , phd d: i professor b: right ? I mean y you {disfmarker} you {disfmarker} phd d: Yeah . professor b: it stretches again . For single frames I think it would be pretty hard . phd a: Yeah . professor b: But if you say speech starts here , speech ends there . phd a: Mm - hmm . professor b: Right ? phd c: Huh . phd d: Yeah . Yeah , you can basically remove the {disfmarker} the frames from the feature {disfmarker} feature files . professor b: Yeah . Yeah , so I mean in the {disfmarker} i i in the {disfmarker} in the decoding , you 're saying that we 're gonna decode from here to here . phd d: I t phd a: Mm - hmm . professor b: I think they 're {disfmarker} they 're {disfmarker} they 're treating it , {pause} you know , like uh {disfmarker} well , it 's not isolated word , but {disfmarker} but connected , you know , the {disfmarker} the {disfmarker} phd a: In the text they say that this {disfmarker} this is a tentative block diagram of a possible configuration we could think of . So that sort of sounds like they 're not doing that yet . professor b: Well . {pause} No they {disfmarker} they have numbers though , right ? So I think they 're {disfmarker} they 're doing something like that . I think that they 're {disfmarker} they 're {disfmarker} I think what I mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . In other words , it 's {disfmarker} uh {disfmarker} I mean from the point of view of {disfmarker} of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway . phd a: Yeah . Yeah . I 'm just wondering what exactly did they do up in this table if it wasn't this . professor b: Um . But it 's {disfmarker} the thing is it 's that {disfmarker} that {disfmarker} that 's {disfmarker} that 's I {disfmarker} I {disfmarker} Certainly it would be tricky about it intrans in transmitting voice , {pause} uh uh for listening to , is that these kinds of things {pause} uh cut {pause} speech off a lot . phd a: Mm - hmm . professor b: Right ? And so {pause} um phd a: Plus it 's gonna introduce delays . professor b: It does introduce delays but they 're claiming that it 's {disfmarker} it 's within the {disfmarker} {pause} the boundaries of it . phd a: Mmm . professor b: And the LDA introduces delays , and b {pause} what he 's suggesting this here is a parallel path so that it doesn't introduce {pause} uh , any more delay . I it introduces two hundred milliseconds of delay but at the same {pause} time the LDA {pause} down here {disfmarker} I don't know {disfmarker} Wh what 's the difference between TLDA and SLDA ? phd c: Temporal and spectral . professor b: Ah , thank you . phd e: Temporal LDA . professor b: Yeah , you would know that . phd c: Yeah professor b: So um . The temporal LDA does in fact include the same {disfmarker} so that {disfmarker} I think he {disfmarker} well , by {disfmarker} by saying this is a b a tentative block di diagram I think means {pause} if you construct it this way , this {disfmarker} this delay would work in that way phd a: Ah . professor b: and then it 'd be OK . They {disfmarker} they clearly did actually remove {pause} silent sections in order {disfmarker} because they {pause} got these {pause} word error rate {pause} results . So um I think that it 's {disfmarker} it 's nice to do that in this because in fact , it 's gonna give a better word error result and therefore will help within an evaluation . Whereas to whether this would actually be in a final standard , I don't know . Um . Uh , as you know , part of the problem with evaluation right now is that the {pause} word models are pretty bad and nobody wants {disfmarker} {pause} has {disfmarker} has approached improving them . So {pause} it 's possible that a lot of the problems {pause} with so many insertions and so forth would go away if they were better word models {pause} to begin with . So {pause} this might just be a temporary thing . But {disfmarker} But , on the other hand , and maybe {disfmarker} maybe it 's a decent idea . So um The question we 're gonna wanna go {pause} through next week when Hynek shows up I guess is given that we 've been {disfmarker} if you look at what we 've been trying , we 're uh looking at {pause} uh , by then I guess , combinations of features and multi - band Uh , and we 've been looking at {pause} cross - language , cross {pause} task {pause} issues . And they 've been not so much looking at {pause} the cross task uh multiple language issues . But they 've been looking at uh {disfmarker} {pause} at these issues . At the on - line normalization and the uh {pause} voice activity detection . And I guess when he comes here we 're gonna have to start deciding about {pause} um what do we choose {pause} from what we 've looked at {pause} to um blend with {pause} some group of things in what they 've looked at And once we choose that , {pause} how do we split up the {pause} effort ? Uh , because we still have {disfmarker} even once we choose , {pause} we 've still got {pause} uh another {pause} month or so , I mean there 's holidays in the way , but {disfmarker} but uh {pause} I think the evaluation data comes January thirty - first so there 's still a fair amount of time {pause} to do things together it 's just that they probably should be somewhat more coherent between the two sites {pause} in that {disfmarker} that amount of time . phd a: When they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's {disfmarker} {pause} knows when it 's time to back trace or something ? professor b: Well , see they , I {disfmarker} I think they 're Um . I don't know the {disfmarker} {pause} the specifics of how they 're doing it . They 're {disfmarker} {pause} they 're getting around the way the recognizer works because they 're not allowed to {pause} um , change the scripts {pause} for the recognizer , {pause} I believe . phd a: Oh , right . Maybe they 're just inserting some nummy frames or something ? professor b: So . Uh . Uh , you know that 's what I had thought . But I don't {disfmarker} I don't think they are . phd a: Hmm . professor b: I mean that 's {disfmarker} sort of what {disfmarker} the way I had imagined would happen is that on the other side , yeah you p put some low level noise or something . Probably don't want all zeros . phd a: Hmm . professor b: Most recognizers don't like zeros but {vocalsound} but {pause} you know , {pause} put some epsilon in or some rand phd a: Yeah . professor b: sorry epsilon random variable {pause} in or something . phd a: Some constant vector . I mean i w Or something {disfmarker} professor b: Maybe not a constant but it doesn't , uh {disfmarker} don't like to divide by the variance of that , but I mean it 's phd a: That 's right . But something that {disfmarker} what I mean is something that is {pause} very distinguishable from {pause} speech . professor b: Mm - hmm . phd a: So that the {disfmarker} the silence model in HTK will always pick it up . professor b: Yeah . So I {disfmarker} I {disfmarker} that 's what I thought they would do . or else , uh {pause} uh maybe there is some indicator to tell it to start and stop , I don't know . phd a: Hmm . professor b: But whatever they did , I mean they have to play within the rules of this specific evaluation . phd a: Yeah . professor b: We c we can find out . phd a: Cuz you gotta do something . Otherwise , if it 's just a bunch of speech , stuck together {disfmarker} professor b: No they 're {disfmarker} phd a: Yeah . professor b: It would do badly phd a: Yeah , right . professor b: and it didn't so badly , right ? So they did something . phd a: Yeah , yeah . professor b: Yeah . Uh . So , OK , So I think {pause} this brings me up to date a bit . It hopefully brings other {pause} people up to date a bit . And um Um {pause} I think {disfmarker} Uh , I wanna look at these numbers off - line a little bit and think about it and {disfmarker} {pause} and talk with everybody uh , {pause} outside of this meeting . Um , but uh No I mean it sounds like {disfmarker} I mean {pause} there {disfmarker} there {disfmarker} there are the usual number of {disfmarker} of {pause} little {disfmarker} little problems and bugs and so forth but it sounds like they 're getting ironed out . And now we 're {pause} seem to be kind of in a position to actually {pause} uh , {pause} look at stuff and {disfmarker} and {disfmarker} and compare things . So I think that 's {disfmarker} that 's pretty good . Um {pause} I don't know what the {disfmarker} One of the things I wonder about , {pause} coming back to the first results you talked about , is {disfmarker} is {pause} how much , {pause} uh {pause} things could be helped {pause} by more parameters . And uh {disfmarker} {pause} And uh how many more parameters we can afford to have , {vocalsound} {pause} in terms of the uh computational limits . Because anyway when we go to {pause} twice as much data {pause} and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , I wonder if having twice as many parameters would help . phd d: Mm - hmm . professor b: Uh , just have a bigger hidden layer . Uh But {disfmarker} I doubt it would {pause} help by forty per cent . But {vocalsound} {pause} but uh phd d: Yeah . professor b: Just curious . How are we doing on the {pause} resources ? Disk , and {disfmarker} phd d: I think we 're alright , professor b: OK . phd d: um , {pause} not much problems with that . professor b: Computation ? phd d: It 's OK . professor b: We {disfmarker} phd d: Well this table took uh {pause} more than five days to get back . professor b: Yeah . Yeah , well . phd d: But {disfmarker} Yeah . professor b: Are {disfmarker} were you folks using Gin ? That 's a {disfmarker} that just died , you know ? phd d: Mmm , no . You were using Gin {comment} perhaps , yeah ? No . phd e: No . professor b: No ? Oh , that 's good . grad f: It just died . professor b: OK . Yeah , {pause} we 're gonna get a replacement {pause} server that 'll be a faster server , {pause} actually . phd e: Yes . professor b: That 'll be {disfmarker} It 's a {pause} seven hundred fifty megahertz uh SUN phd d: Hmm . {comment} Mm - hmm . professor b: uh {pause} But it won't be installed for {pause} a little while . phd c: Tonic . professor b: U Go ahead . grad g: Do we {disfmarker} Do we have that big new IBM machine the , I think in th professor b: We have the {pause} little tiny IBM machine {vocalsound} {pause} that might someday grow up to be a big {pause} IBM machine . It 's got s slots for eight , uh IBM was donating five , I think we only got two so far , processors . We had originally hoped we were getting eight hundred megahertz processors . They ended up being five fifty . So instead of having eight processors that were eight hundred megahertz , we ended up with two {pause} that are five hundred and fifty megahertz . And more are supposed to come soon and there 's only a moderate amount of dat of memory . So I don't think {pause} anybody has been sufficiently excited by it to {pause} spend much time {pause} uh {pause} with it , but uh {vocalsound} Hopefully , {pause} they 'll get us some more {pause} parts , soon and {disfmarker} Uh , yeah , I think that 'll be {disfmarker} once we get it populated , {pause} that 'll be a nice machine . I mean we will ultimately get eight processors in there . And uh {disfmarker} and uh a nice amount of memory . Uh so it 'll be a pr pretty fast Linux machine . grad g: And if we can do things on Linux , {pause} some of the machines we have going already , like Swede ? professor b: Mm - hmm . grad g: Um It seems pretty fast . professor b: Mm - hmm . grad g: But {disfmarker} I think Fudge is pretty fast too . professor b: Yeah , I mean you can check with uh {pause} Dave Johnson . I mean , it {disfmarker} it 's {disfmarker} {pause} I think the machine is just sitting there . And it does have two processors , you know and {disfmarker} {pause} Somebody could do {disfmarker} {pause} you know , uh , check out {pause} uh the multi - threading {pause} libraries . And {pause} I mean i it 's possible that the {disfmarker} I mean , I guess the prudent thing to do would be for somebody to do the work on {disfmarker} {pause} on getting our code running {pause} on that machine with two processors {pause} even though there aren't five or eight . There 's {disfmarker} there 's {disfmarker} there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . But . {pause} Notice how I said somebody and {vocalsound} turned my head your direction . That 's one thing you don't get in these recordings . You don't get the {disfmarker} {pause} don't get the visuals but {disfmarker} grad g: I is it um {pause} mostly um the neural network trainings that are {pause} um slowing us down or the HTK runs that are slowing us down ? professor b: Uh , I think yes . Uh , {vocalsound} Isn't that right ? I mean I think you 're {disfmarker} you 're sort of held up by both , right ? If the {disfmarker} if the neural net trainings were a hundred times faster {pause} you still wouldn't {pause} be anything {disfmarker} running through these a hundred times faster because you 'd {pause} be stuck by the HTK trainings , phd d: Mmm . professor b: right ? phd d: Yeah . professor b: But if the HTK {disfmarker} I mean I think they 're both {disfmarker} It sounded like they were roughly equal ? Is that about right ? phd d: Yeah . professor b: Yeah . grad g: Because , um {pause} I think that 'll be running Linux , and Sw - Swede and Fudge are already running Linux so , {pause} um I could try to get {pause} um the train the neural network trainings or the HTK stuff running under Linux , and to start with I 'm {pause} wondering which one I should pick first . professor b: Uh , probably the neural net cuz it 's probably {disfmarker} it {disfmarker} it 's {disfmarker} {pause} it 's um {disfmarker} Well , I {disfmarker} I don't know . They both {disfmarker} HTK we use for {pause} um {pause} this Aurora stuff Um {pause} Um , I think {pause} It 's not clear yet what we 're gonna use {pause} for trainings uh {disfmarker} Well , {pause} there 's the trainings uh {disfmarker} is it the training that takes the time , or the decoding ? Uh , is it about equal {pause} between the two ? For {disfmarker} for Aurora ? phd d: For HTK ? professor b: For {disfmarker} Yeah . For the Aurora ? phd d: Uh Training is longer . professor b: OK . phd d: Yeah . professor b: OK . Well , I don't know how we can {disfmarker} I don't know how to {disfmarker} Do we have HTK source ? Is that {disfmarker} Yeah . phd d: Mmm . professor b: You would think that would fairly trivially {disfmarker} the training would , anyway , th the testing {pause} uh I don't {disfmarker} I don't {pause} think would {pause} parallelize all that well . But I think {pause} that {pause} you could {pause} certainly do d um , {pause} distributed , sort of {disfmarker} {pause} Ah , no , it 's the {disfmarker} {pause} each individual {pause} sentence is pretty tricky to parallelize . But you could split up the sentences in a test set . phd a: They have a {disfmarker} they have a thing for doing that and th they have for awhile , in H T And you can parallelize the training . professor b: Yeah ? phd a: And run it on several machines professor b: Aha ! phd a: and it just basically keeps counts . And there 's something {disfmarker} {pause} a final {pause} thing that you run and it accumulates all the counts together . professor b: I see . phd d: Mmm . phd a: I don't what their scripts are {pause} set up to do for the Aurora stuff , but {disfmarker} phd d: Yeah . professor b: Something that we haven't really settled on yet is other than {pause} this Aurora stuff , {pause} uh what do we do , large vocabulary {pause} training slash testing {pause} for uh tandem systems . Cuz we hadn't really done much with tandem systems for larger stuff . Cuz we had this one collaboration with CMU and we used SPHINX . Uh , we 're also gonna be collaborating with SRI and we have their {disfmarker} have theirs . Um {pause} So {pause} I don't know Um . So I {disfmarker} I think the {disfmarker} the advantage of going with the neural net thing is that we 're gonna use the neural net trainings , no matter what , for a lot of the things we 're doing , grad g: OK . professor b: whereas , w exactly which HMM {disfmarker} Gaussian - mixture - based HMM thing we use is gonna depend uh So with that , maybe we should uh {vocalsound} go to our {nonvocalsound} digit recitation task . And , it 's about eleven fifty . Canned . Uh , I can {disfmarker} I can start over here . Great , uh , could you give Adam a call . Tell him to He 's at two nine seven seven . grad f: Oh . professor b: OK . I think we can {vocalsound} @ @ You know Herve 's coming tomorrow , right ? Herve will be giving a talk , yeah , talk at eleven . Did uh , did everybody sign these consent Er everybody Has everyone signed a consent form before , on previous meetings ? You don't have to do it again each time Yes . microphones off