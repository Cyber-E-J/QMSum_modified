grad a: OK . We seem to be recording . professor g: Alright ! grad a: So , sorry about not {disfmarker} professor g: We 're not crashing . phd d: Number four . grad a: not pre - doing everything . The lunch went a little later than I was expecting , Chuck . phd e: Hmm ? professor g: OK . phd b: Chuck was telling too many jokes , or something ? grad a: Yep . Pretty much . phd e: Yeah . professor g: OK . {vocalsound} Does anybody have an agenda ? grad a: No . postdoc f: Well , I 'm {disfmarker} I sent a couple of items . They 're {disfmarker} they 're sort of practical . professor g: I thought {pause} somebody had . postdoc f: I don't know if you 're {disfmarker} professor g: Yeah , that 's right . postdoc f: if {disfmarker} if that 's too practical for what we 're {pause} focused on . grad a: I mean , we don't want anything too practical . professor g: Yeah , we only want th useless things . grad a: Yeah , that would be {disfmarker} professor g: Yeah . No , why don't we talk about practical things ? postdoc f: OK . professor g: Sure . postdoc f: Well , um , I can {pause} give you an update on the {pause} transcription effort . professor g: Great . postdoc f: Uh , maybe {nonvocalsound} raise the issue of microphone , uh , um procedures with reference to the {pause} cleanliness of the recordings . professor g: OK , transcription , uh , microphone issues {disfmarker} postdoc f: And then maybe {nonvocalsound} ask , th uh , these guys . The {disfmarker} we have great {disfmarker} great , uh , p steps forward in terms of the nonspeech - speech pre - segmenting of the signal . professor g: OK . grad a: Well , we have steps forward . phd c: Yeah . postdoc f: Well , it 's a {disfmarker} it 's a big improvement . phd c: I would prefer this . professor g: Yes . Yeah , well . OK . Uh {disfmarker} phd d: We talk about the {disfmarker} {vocalsound} the results of professor g: You have some {disfmarker} Yeah . grad a: I have a little bit of IRAM stuff professor g: OK . phd d: use {disfmarker} grad a: but {pause} I 'm not sure if that 's of general interest or not . professor g: Uh , bigram ? grad a: IRAM . phd d: IRAM . professor g: IRAM . grad a: IRAM , bigram , professor g: Well , m maybe . phd d: Bi - Bigram . grad a: you know . professor g: Yeah , let 's {disfmarker} let 's see where we are at three - thirty . phd b: Hmm . professor g: Um {disfmarker} phd b: Since , uh {disfmarker} since I have to leave as usual at three - thirty , can we do the interesting stuff first ? postdoc f: I beg your pardon ? professor g: Well {disfmarker} phd c: Which is {disfmarker} ? grad a: What 's the interesting stuff ? postdoc f: I beg your pardon ? phd d: Yeah . professor g: Yeah . Th - now you get to tell us what 's the interesting part . phd e: Please specify . professor g: But {disfmarker} phd b: Well , uh , I guess the work that 's been {pause} done on segmentation would be most {disfmarker} phd c: Yeah . postdoc f: I think that would be a good thing to start with . phd b: Yeah . professor g: OK . Um , and , um , {vocalsound} the other thing , uh , which I 'll just say very briefly that maybe relates to that a little bit , which is that , um , uh , one of the suggestions that came up in a brief meeting I had the other day when I was in Spain with , uh , Manolo Pardo and {vocalsound} Javier , uh , Ferreiros , who was {pause} here before , was , um , why not start with what they had before but add in the non - silence boundaries . So , in what Javier did before when they were doing , um {disfmarker} h he was looking for , uh , speaker change {pause} points . phd d: Mm - hmm . professor g: Um . As a simplification , he originally did this only using {pause} silence as , uh , a {pause} putative , uh , speaker change point . phd c: Yeah . professor g: And , uh , he did not , say , look at points where you were changing broad sp uh , phonetic class , for instance . And for Broadcast News , that was fine . Here obviously it 's not . phd d: Yeah . professor g: And , um , so one of the things that they were pushing in d in discussing with me is , um , w why are you spending so much time , uh , on the , uh , feature issue , uh , when perhaps if you sort of deal with what you were using before phd d: Uh - huh . professor g: and then just broadened it a bit , instead of just ta using silence as putative change point also {disfmarker} ? phd d: Nnn , yeah . professor g: So then you 've got {disfmarker} you already have the super - structure with Gaussians and H - you know , simple H M Ms and so forth . And you {disfmarker} you might {disfmarker} So there was a {disfmarker} there was a little bit of a {disfmarker} a {disfmarker} a {disfmarker} a difference of opinion because I {disfmarker} I thought that it was {disfmarker} it 's interesting to look at what features are useful . phd d: Yeah . professor g: But , uh , on the other hand I saw that the {disfmarker} they had a good point that , uh , if we had something that worked for many cases before , maybe starting from there a little bit {disfmarker} Because ultimately we 're gonna end up {vocalsound} with some s su kind of structure like that , phd d: Yeah . professor g: where you have some kind of simple HMM and you 're testing the hypothesis that , {vocalsound} uh , there is a change . phd d: Yeah . professor g: So {disfmarker} so anyway , I just {disfmarker} reporting that . phd d: OK . professor g: But , uh , uh {disfmarker} So . Yeah , why don't we do the speech - nonspeech discussion ? postdoc f: Yeah . Do {disfmarker} I {disfmarker} I hear {disfmarker} you {disfmarker} you didn't {disfmarker} phd c: Speech - nonspeech ? OK . postdoc f: Uh - huh . Yeah . phd c: Um , so , uh , what we basically did so far was using the mixed file to {disfmarker} to detect s speech or nonspeech {pause} portions in that . professor g: Mm - hmm . phd c: And what I did so far is I just used our old Munich system , which is an HMM - ba based system with Gaussian mixtures for s speech and nonspeech . And it was a system which used only one Gaussian for silence and one Gaussian for speech . And now I added , uh , multi - mixture possibility for {disfmarker} {vocalsound} for speech and nonspeech . professor g: Mm - hmm . Mm - hmm . phd c: And I did some training on {disfmarker} on one dialogue , which was transcribed by {disfmarker} Yeah . We {disfmarker} we did a nons s speech - nonspeech transcription . phd d: Jose . phd c: Adam , Dave , and I , we did , for that dialogue and I trained it on that . And I did some pre - segmentations for {disfmarker} for Jane . And I 'm not sure how good they are or what {disfmarker} what the transcribers say . They {disfmarker} they can use it or {disfmarker} ? postdoc f: Uh , they {disfmarker} they think it 's a terrific improvement . And , um , it real it just makes a {disfmarker} a world of difference . professor g: Hmm . postdoc f: And , um , y you also did some something in addition which was , um , for those in which there {nonvocalsound} was , uh , quiet speakers in the mix . phd c: Yeah . Uh , yeah . That {disfmarker} that was one {disfmarker} one {disfmarker} one thing , uh , why I added more mixtures for {disfmarker} for the speech . So I saw that there were loud {disfmarker} loudly speaking speakers and quietly speaking speakers . professor g: Mm - hmm . phd c: And so I did two mixtures , one for the loud speakers and one for the quiet speakers . grad a: And did you hand - label who was loud and who was quiet , or did you just {disfmarker} ? phd c: I did that for {disfmarker} for five minutes of one dialogue grad a: Right . phd c: and that was enough to {disfmarker} to train the system . phd b: W What {disfmarker} ? phd d: Yeah . phd c: And so it {disfmarker} it adapts , uh , on {disfmarker} while running . So . phd b: What kind of , uh , front - end processing did you do ? phd c: Hopefully . phd d: OK . phd c: It 's just our {disfmarker} our old Munich , uh , loudness - based spectrum on mel scale twenty {disfmarker} twenty critical bands and then loudness . phd b: Mm - hmm . phd c: And four additional features , which is energy , loudness , modified loudness , and zero crossing rate . So it 's twenty - four {disfmarker} twenty - four features . phd b: Mmm . professor g: Mm - hmm . postdoc f: And you also provided me with several different versions , phd c: Yeah . postdoc f: which I compared . phd c: Yeah . postdoc f: And so you change {nonvocalsound} parameters . What {disfmarker} do you wanna say something about the parameters {nonvocalsound} that you change ? phd c: Yeah . You can specify {vocalsound} the minimum length of speech or {disfmarker} and silence portions which you want . And so I did some {disfmarker} some modifications in those parameters , basically changing the minimum {disfmarker} minimum {pause} length for s for silence to have , er to have , um {disfmarker} yeah {disfmarker} to have more or less , uh , silence portions in inserted . So . grad a: Right . So this would work well for , uh , pauses and utterance boundaries and things like that . phd d: Yeah . phd c: Yeah . Yeah . grad a: But for overlap I imagine that doesn't work at all , phd c: Yeah . phd d: Yeah . grad a: that you 'll have plenty of s sections that are {disfmarker} phd c: Yeah . phd d: Yeah . phd c: That 's it . Yeah . postdoc f: Mm - hmm , mm - hmm . phd d: Yeah . grad a: But {disfmarker} postdoc f: That 's true . But {nonvocalsound} it {disfmarker} it saves so much time {disfmarker} the {disfmarker} the {nonvocalsound} transcribers professor g: Um {disfmarker} grad a: Yep . postdoc f: just enormous , enormous savings . Fantastic . professor g: That 's great . Um , just qu one quickly , uh , still on the features . So {vocalsound} you have these twenty - four features . phd c: Yeah . professor g: Uh , a lot of them are spectral features . Is there a {disfmarker} a transformation , uh , like principal components transformation or something ? phd c: No . grad a: Yeah . It was IS two . phd c: No . W w we {disfmarker} originally we did that professor g: Just {disfmarker} phd c: but we saw , uh , when we used it , uh , f for our close - talking microphone , which {disfmarker} yeah , for our {disfmarker} for our recognizer in Munich {disfmarker} we saw that w it 's {disfmarker} it 's not {disfmarker} it 's not so necessary . It {disfmarker} it works as well f with {disfmarker} with {disfmarker} without , uh , a LDA or something . professor g: OK . OK . No , I was j {pause} curious . phd c: Yeah . postdoc f: Mm - hmm . professor g: Yeah , I don't think it 's a big deal for this application , phd c: Yeah . phd d: Right . professor g: but {disfmarker} but {disfmarker} Yeah , it 's a {disfmarker} postdoc f: Mm - hmm . OK . But then there 's another thing that also Thilo 's involved with , which is , um {disfmarker} OK , and {disfmarker} and also Da - Dave Gelbart . So there 's this {disfmarker} this problem of {disfmarker} and w and {disfmarker} so we had this meeting . Th - the {nonvocalsound} {disfmarker} also Adam , before the {disfmarker} the {disfmarker} before you went away . Uh we , um {disfmarker} regarding the representation {nonvocalsound} of overlaps , because at present , {nonvocalsound} {vocalsound} um , because {nonvocalsound} of the limitations of {vocalsound} th the interface we 're using , overlaps are , uh , not being {nonvocalsound} encoded by {nonvocalsound} the transcribers in as complete {nonvocalsound} and , uh , detailed a way as it might be , and as might be desired {disfmarker} I think would be desired in the corpus ultimately . professor g: Mm - hmm . postdoc f: So we don't have start and end points {nonvocalsound} at each point where there 's an overlap . We just have the {disfmarker} the {nonvocalsound} overlaps {nonvocalsound} encoded in a simple bin . Well , OK . So {nonvocalsound} @ @ the limits of the {nonvocalsound} over of {disfmarker} of the interface are {vocalsound} such that we were {disfmarker} at this meeting we were entertaining how we might either expand {nonvocalsound} the {disfmarker} the {vocalsound} interface or find other tools which already {pause} do what would be useful . Because what would ultimately be , um , ideal in my {disfmarker} my view and I think {disfmarker} I mean , I had the sense that it was consensus , is that , um , a thorough - going musical score notation would be {nonvocalsound} the best way to go . Because {nonvocalsound} you can have multiple channels , there 's a single time - line , it 's very clear , flexible , and all those nice things . professor g: Mm - hmm . postdoc f: OK . So , um , um , I spoke {disfmarker} I had a meeting with Dave Gelbart on {disfmarker} on {disfmarker} and he had , uh , excellent ideas on how {pause} the interface could be {pause} modified to {disfmarker} to do this kind of representation . But , um , he {disfmarker} in the meantime you were checking into the existence of already , um , existing interfaces which might already have these properties . So , do you wanna say something about that ? phd c: Yes . Um , I {vocalsound} talked with , uh , Munich guys from {disfmarker} from Ludwi - Ludwig Maximilians University , who do a lot of transcribing and transliterations . professor g: Mm - hmm . phd c: And they basically said they have {disfmarker} they have , uh , a tool they developed {pause} themselves and they can't give away , uh , f it 's too error - prone , and had {disfmarker} it 's not supported , a a a and {disfmarker} professor g: Yeah . phd c: But , um , Susanne Bur - Burger , who is at se CMU , he wa who was formally at {disfmarker} in Munich and w and is now at {disfmarker} with CMU , she said she has something which she uses to do eight channels , uh , trans transliterations , eight channels simultaneously , professor g: Excuse me . phd c: but it 's running under Windows . postdoc f: Under Windows . phd c: So I 'm not sure if {disfmarker} if {disfmarker} if we can use it . postdoc f: Mm - hmm . phd c: She said she would give it to us . postdoc f: Mm - hmm . phd c: It wouldn't be a problem . And I 've got some {disfmarker} some kind of manual {pause} down in my office . grad a: Well , maybe we should get it and if it 's good enough we 'll arrange Windows machines to be available . phd c: Yeah . postdoc f: Mm - hmm . We could {disfmarker} uh , potentially {nonvocalsound} so . grad a: So . postdoc f: I also wanted to be sure {disfmarker} I mean , I 've {disfmarker} I 've seen the {disfmarker} this {disfmarker} this is called Praat , PRAAT , {nonvocalsound} which I guess means spee speech in Dutch or something . grad a: Yep . phd c: Yeah , but then I 'm not sure {pause} that 's the right thing for us . postdoc f: But {disfmarker} In terms {nonvocalsound} of it being {nonvocalsound} Windows {nonvocalsound} versus {disfmarker} professor g: Yeah . grad a: No , no . Praat isn't {disfmarker} Praat 's multi - platform . postdoc f: But I 'm just wondering , is {disfmarker} ? phd c: No . No , Praat {disfmarker} Yeah . Yeah . postdoc f: Oh ! I see . phd c: Yeah . postdoc f: Oh , I see . So Praat may not be {disfmarker} phd c: That 's not Praat . It 's called " trans transedit " {pause} I think . postdoc f: It 's a different one . phd c: The {disfmarker} the , uh {disfmarker} the tool from {disfmarker} from Susanne . postdoc f: I see . Oh , I see . OK . OK . Alright . professor g: The other thing , uh , to keep in mind , uh {disfmarker} I mean , we 've been very concerned to get all this rolling so that we would actually have data , postdoc f: Mmm , yeah . professor g: but , um , I think our outside sponsor is actually gonna kick in postdoc f: Mm - hmm . professor g: and ultimately that path will be smoothed out . So I don't know if we have a long - term need to do lots and lots of transcribing . I think we had a very quick need to get something out and we 'd like to be able to do some later because just it 's inter it 's interesting . But as far a you know , uh , with {disfmarker} with any luck we 'll be able to wind down the larger project . grad a: Oh . phd b: But you s grad a: What our decision was is that {pause} we 'll go ahead with what we have with a not very fine time scale on the overlaps . phd c: Yeah . professor g: Right . Yeah . grad a: And {disfmarker} and do what we can later {pause} to clean that up if we need to . postdoc f: Mm - hmm . professor g: Right . postdoc f: And {disfmarker} and I was just thinking that , um , {vocalsound} if it were possible to bring that in , like , {vocalsound} you know , this week , then {nonvocalsound} when they 're encoding the overlaps {nonvocalsound} it would be nice for them to be able to specify when {disfmarker} you know , the start points and end points of overlaps . professor g: Uh - huh . postdoc f: uh Th - they 're {nonvocalsound} making really quick progress . professor g: Yeah . That 's great . postdoc f: And , um , so my {disfmarker} my goal was {disfmarker} w m my charge was to get eleven hours by the end of the month . And it 'll be {disfmarker} I 'm {disfmarker} I 'm {disfmarker} I 'm clear that we 'll be able to do that . professor g: That 's great . grad a: And did you , uh , forward Morgan Brian 's {pause} thing ? professor g: Yeah . postdoc f: I sent {nonvocalsound} it to , um {disfmarker} who did I send that to ? I sent it to a list and I thought {nonvocalsound} I sent it to {nonvocalsound} the {nonvocalsound} {disfmarker} e to the local list . phd e: Meeting Recorder . grad a: Oh , you did ? OK . So you probably did get that . postdoc f: You saw that ? So Brian did tell {nonvocalsound} me that {nonvocalsound} in fact what you said , that , {nonvocalsound} uh {disfmarker} that {nonvocalsound} our {disfmarker} that they are {pause} making progress and that he 's going {disfmarker} that {nonvocalsound} they 're {nonvocalsound} going {disfmarker} he 's gonna check the f the output of the first transcription and {disfmarker} and {disfmarker} professor g: I mean , basically it 's {disfmarker} it 's all the difference in the world . I mean , basically he 's {disfmarker} he 's on it now . grad a: Yeah . postdoc f: Oh , that 's {disfmarker} this is a new development . professor g: So {disfmarker} so {disfmarker} so this is {disfmarker} so i it 'll happen . postdoc f: OK . Super . Super . OK . Great . professor g: Yeah . I mean , basically it 's just saying that one of our {disfmarker} one of our best people is on it , postdoc f: Yeah . professor g: you know , who just doesn't happen to be here anymore . Someone else pays him . So {disfmarker} phd b: But about the need for transcription , postdoc f: Isn't that great ? phd b: I mean , don't we {disfmarker} didn't we previously {vocalsound} decide that the {pause} IBM {pause} transcripts would have to be {pause} checked anyway and possibly augmented ? professor g: So . {vocalsound} Yeah . postdoc f: Yes . That 's true . phd b: So , I think having a good tool is worth something no matter what . postdoc f: Mm - hmm . professor g: Yeah . S OK . That 's {disfmarker} that 's a good point . grad a: Yeah , and Dave Gelbart did volunteer , postdoc f: Good . grad a: and since he 's not here , I 'll repeat it {disfmarker} to at least modify Transcriber , which , if we don't have something else that works , I think that 's a pretty good way of going . phd c: Mmm . postdoc f: Mm - hmm . grad a: And we discussed on some methods to do it . My approach originally , and I 've already hacked on it a little bit {disfmarker} it was too slow because I was trying to display all the waveforms . But he pointed out that you don't really have to . I think that 's a good point . postdoc f: Mm - hmm . professor g: Mm - hmm . grad a: That if you just display the mix waveform and then have a user interface for editing the different channels , that 's perfectly sufficient . professor g: Hmm . postdoc f: Yeah , exactly . And just keep those {nonvocalsound} things separate . And {disfmarker} and , um , Dan Ellis 's hack already allows them to be {nonvocalsound} able to display {vocalsound} different {nonvocalsound} waveforms to clarify overlaps and things , grad a: No . They can only display one , postdoc f: so that 's already {disfmarker} grad a: but they can listen to different ones . postdoc f: Oh , yes , but {disfmarker} Well , {vocalsound} uh , yes , but {nonvocalsound} what I mean is {pause} that , uh , from the transcriber 's {nonvocalsound} perspective , uh , those {nonvocalsound} two functions are separate . And Dan Ellis 's hack handles the , {vocalsound} um , choice {nonvocalsound} {disfmarker} the ability to choose different waveforms {vocalsound} from moment to moment . grad a: But only to listen to , not to look at . phd c: Yeah . postdoc f: Um {disfmarker} grad a: The waveform you 're looking at doesn't change . phd c: Yeah . postdoc f: That 's true . grad a: Yeah . postdoc f: Yeah , but {nonvocalsound} that 's {disfmarker} that 's OK , cuz they 're {disfmarker} they 're , you know , they 're focused on the ear anyway . grad a: Right . postdoc f: And then {disfmarker} and then professor g: Hmm . postdoc f: the hack to {vocalsound} preserve the overlaps {nonvocalsound} better would be one which creates different output files for each channel , grad a: Right . postdoc f: which then {nonvocalsound} would also serve Liz 's request {pause} of having , you know , a single channel , separable , uh , cleanly , easily separable , professor g: Mm - hmm . postdoc f: uh , transcript tied to a single channel , uh , audio . professor g: Mm - hmm . Have , uh , folks from NIST been in contact with you ? postdoc f: Not directly . I 'm trying to think if {disfmarker} if I could have gotten it over a list . professor g: OK . postdoc f: I don't {disfmarker} I don't think so . professor g: OK . Well , holidays may have interrupted things , cuz in {disfmarker} in {disfmarker} in {disfmarker} They {vocalsound} seem to want to {pause} get absolutely clear on standards for {disfmarker} transcription standards and so forth with {disfmarker} with us . postdoc f: Oh ! This was from before December . Yeah . professor g: Right . Because they 're {disfmarker} they 're presumably going to start recording next month . postdoc f: OK . OK . grad a: Oh , we should definitely get with them then , professor g: So . grad a: and agree upon a format . Though I don't remember email on that . So was I not in the loop on that ? professor g: Um . Yeah , I don't think I mailed anybody . I just think I told them to contact Jane {disfmarker} that , uh , if they had a {disfmarker} grad a: Oh , OK . postdoc f: That 's right . professor g: if , uh {disfmarker} that {disfmarker} that , uh , as the point person on it . grad a: Yeah , I think that 's right . professor g: But {disfmarker} grad a: Just , uh {disfmarker} professor g: So , yeah . Maybe I 'll , uh , ping them a little bit about it to {vocalsound} get that straight . postdoc f: OK . I 'm keeping the conventions {pause} absolutely {pause} as simple {nonvocalsound} as possible . professor g: Yeah . So is it {disfmarker} cuz with any luck there 'll actually be a {disfmarker} a {disfmarker} there 'll be collections at Columbia , collections at {disfmarker} at UW {disfmarker} I mean Dan {disfmarker} Dan is very interested in doing some other things , grad a: Right . postdoc f: Yeah . Yeah . grad a: Well , I think it 's important both for the notation and the machine representation to be the same . professor g: and collections at NIST . So {disfmarker} Yeah . grad a: So . postdoc f: N there was also this , {nonvocalsound} uh , email from Dan regarding the {pause} speech - non nonspeech segmentation thing . grad a: Yep . phd c: Yeah . phd d: Yeah . postdoc f: I don't know if , uh , uh , we wanna , uh {disfmarker} and Dan Gel - and Dave Gelbart is interested in pursuing the aspect {nonvocalsound} of using amplitude {nonvocalsound} as a {disfmarker} a {disfmarker} a {disfmarker} as a basis for the separation . grad a: Cross - correlation . professor g: Oh , yeah . He was talking {disfmarker} he was talking {disfmarker} I mean , uh , we {disfmarker} he had {disfmarker} postdoc f: Cross professor g: Yeah , cross - correlation . phd c: Cross professor g: I had mentioned this a couple times before , the c the commercial devices that do , uh , {vocalsound} uh , voice , uh {disfmarker} you know , active miking , postdoc f: Uh - huh . professor g: basically look at the amp at the energy at each of the mikes . And {disfmarker} and you basically compare the energy here to {vocalsound} some function of all of the mikes . phd c: Yeah . phd d: Yeah . postdoc f: OK . professor g: So , by doing that , you know , rather than setting any , uh , absolute threshold , you actually can do pretty good , uh , selection of who {disfmarker} who 's talking . postdoc f: OK . professor g: Uh {disfmarker} And those {disfmarker} those systems work very well , by the way , I mean , so people use them in {vocalsound} panel discussions and so forth with sound reinforcement differing in {disfmarker} in sort of , phd d: Uh - huh . professor g: uh {disfmarker} and , uh , those {disfmarker} if {disfmarker} Boy , the guy I knew who built them , built them like twenty {disfmarker} twenty years ago , grad a: Hmm . professor g: so they 're {disfmarker} {vocalsound} it 's {disfmarker} the {disfmarker} the techniques work pretty well . postdoc f: Fantastic . Cuz there is one thing that we don't have right now and that is the automatic , um , channel identifier . professor g: So . postdoc f: That {disfmarker} that , you know , that would g help in terms of encoding of overlaps . professor g: Mm - hmm . postdoc f: The {disfmarker} the transcribers would have less , uh , disentangling to do {pause} if that were available . professor g: Yeah . So I think , you know , basically you can look at some {disfmarker} p you have to play around a little bit , uh , to figure out what the right statistic is , postdoc f: But . phd d: Mm - hmm . postdoc f: Mm - hmm . professor g: but you compare each microphone to some statistic based on the {disfmarker} {vocalsound} on the overall {disfmarker} phd c: Yeah . phd d: Mm - hmm . postdoc f: OK . professor g: Uh , and we also have these {disfmarker} we have the advantage of having {pause} distant mikes too . So that , you cou yo grad a: Yeah , although the {disfmarker} the {disfmarker} using the close - talking I think would be much better . Wouldn't it ? postdoc f: Yeah . professor g: Um . I {disfmarker} I don't know . grad a: Yeah . professor g: I just {disfmarker} it 'd be {disfmarker} If I was actually working on it , I 'd sit there and {disfmarker} and play around with it , and {disfmarker} and get a feeling for it . I mean , the {disfmarker} the {disfmarker} the , uh {disfmarker} But , uh , you certainly wanna use the close - talking , as a {disfmarker} at least . grad a: Right . professor g: I don't know if the other would {disfmarker} would add some other helpful dimension or not . postdoc f: Mm - hmm . phd d: Mm - hmm . OK . What {disfmarker} what are the different , uh , classes to {disfmarker} to code , uh , the {disfmarker} the overlap , you will use ? postdoc f: Um , to code d phd d: What you {disfmarker} you {disfmarker} postdoc f: so types of overlap ? phd d: Yeah . postdoc f: Um , so {nonvocalsound} at a meeting that wasn't transcribed , we worked up a {disfmarker} a typology . phd d: Yeah . postdoc f: And , um {disfmarker} phd d: Look like , uh , you t you explaining in the blackboard ? The {disfmarker} ? Yeah ? Yeah . postdoc f: Yes , exactly . That hasn't changed . So it {nonvocalsound} i the {disfmarker} it 's basically a two - tiered structure where the first one is whether {nonvocalsound} the person who 's interrupted continues or not . And then below that there 're {nonvocalsound} subcategories , uh , that have more to do with , {nonvocalsound} you know , is it , {vocalsound} uh , simply {nonvocalsound} backchannel phd d: Mm - hmm . postdoc f: or is {nonvocalsound} it , um , someone completing someone else 's thought , or is it someone in introducing a new thought . grad a: Right . And I hope that if we do a forced alignment with the close - talking mike , that will be enough to recover at least some of the time the time information of when the overlap occurred . phd d: Huh . Yeah . Yeah . postdoc f: Mm - hmm . Well , {vocalsound} one would {disfmarker} phd d: We hope . grad a: Yeah . Who knows ? postdoc f: That 'd be {disfmarker} that 'd be nice . I mean , {vocalsound} I {disfmarker} I {disfmarker} I {disfmarker} I 've {disfmarker} phd b: So who 's gonna do that ? Who 's gonna do forced alignment ? grad a: Well , u uh , IBM was going to . Um {disfmarker} phd b: Oh , OK . phd d: Oh . grad a: and I imagine they still plan to but {disfmarker} but , you know , I haven't spoken with them about that recently . phd b: OK . phd d: Uh - huh . professor g: Well , uh , my suggestion now is {disfmarker} is on all of these things to , uh , contact Brian . grad a: OK . I 'll do that . phd d: Yeah . postdoc f: This is wonderful {nonvocalsound} to have a direct contact like that . professor g: Yeah . postdoc f: uh Well , th lemme ask {nonvocalsound} you this . professor g: Yeah . postdoc f: It occurs to me {disfmarker} {vocalsound} one of my transcribers t {nonvocalsound} told {nonvocalsound} me today that she 'll {nonvocalsound} be finished with one meeting , {vocalsound} um , by {disfmarker} professor g: Mm - hmm . postdoc f: well , she said tomorrow but then she said {nonvocalsound} {disfmarker} you know , but {nonvocalsound} {disfmarker} the , you know {disfmarker} let 's {disfmarker} let 's just , uh , say professor g: Mm - hmm . postdoc f: maybe the day after just to be s on the safe side . I could send Brian the , {nonvocalsound} um {disfmarker} the {nonvocalsound} transcript . I know these {nonvocalsound} are {disfmarker} er , uh , I could send him that {nonvocalsound} if {nonvocalsound} it would be possible , {nonvocalsound} or a good idea or not , to {nonvocalsound} try {nonvocalsound} to do a s forced alignment on what we 're {disfmarker} on the way we 're encoding overlaps now . professor g: Well , just talk to him about it . grad a: Yep . postdoc f: Good . professor g: I mean , you know , basically he 's {disfmarker} he just studies , he 's a colleague , a friend , and , postdoc f: Yeah ! professor g: uh , they {disfmarker} and {disfmarker} and , you know , the {disfmarker} the organization always did wanna help us . postdoc f: Super . Super . professor g: It was just a question of getting , you know , the right people connected in , who had the time . grad a: Right . postdoc f: Yeah , yeah . professor g: So , um , eh {disfmarker} grad a: Is he on the mailing list ? The Meeting Recorder mailing li ? postdoc f: Oh ! grad a: We should add him . postdoc f: Yeah . I {disfmarker} I {disfmarker} I don't know for sure . professor g: Yeah . phd e: Did something happen , Morgan , that he got put on this , or was he already on it , grad a: Add him . phd e: or {disfmarker} ? professor g: No , I , eh , eh , p It {disfmarker} it oc I {disfmarker} h it 's {disfmarker} Yeah , something happened . I don't know what . phd b: He asked for more work . phd e: Huh . professor g: But he 's on it now . postdoc f: That would be {nonvocalsound} like {disfmarker} that 'd be like him . He 's great . professor g: Right . So , uh , where are we ? Maybe , uh , uh , brief {disfmarker} Well , let 's {disfmarker} why don't we talk about microphone issues ? postdoc f: Yeah . That 'd be great . professor g: That was {disfmarker} that was a {disfmarker} grad a: Um , so one thing is that I did look on Sony 's for a replacement for the mikes {disfmarker} {vocalsound} for the head m head - worn ones cuz they 're so uncomfortable . But I think I need someone who knows more about mikes than I do , because I couldn't find a single other model that seemed like it would fit the connector , which seems really unlikely to me . Does anyone , like , know stores or {vocalsound} know about mikes who {disfmarker} who would know the right questions to ask ? professor g: Oh , I probably would . I mean , my knowledge is twenty years out of date but some of it 's still the same . grad a: Mm - hmm . professor g: So {disfmarker} Uh , so maybe we c we can take a look at that . phd e: You couldn't {disfmarker} you couldn't find the right connector to go into these things ? grad a: Yep . When I looked , i they listed one microphone and that 's it phd e: Huh ! grad a: as having that type of connector . But my guess is that Sony maybe uses a different number for their connector than everyone else does . And {disfmarker} and so {disfmarker} professor g: Mm - hmm . Well , let 's look at it together grad a: it seems {disfmarker} it seems really unlikely to me that there 's only one . professor g: and {disfmarker} postdoc f: And there 's no adaptor for it ? phd c: Yeah . postdoc f: Seems like there 'd be a {disfmarker} OK . grad a: As I said , who knows ? postdoc f: Mm - hmm . professor g: Who {disfmarker} who are we buying these from ? grad a: Um , professor g: That 'd be grad a: I have it downstairs . I don't remember off the top of my head . professor g: Yeah . OK . Yeah . We {disfmarker} we can try and look at that together . grad a: And then , uh {disfmarker} just in terms of how you wear them {disfmarker} I mean , I had thought about this before . I mean , when {disfmarker} when {disfmarker} when you use a product like DragonDictate , they have a very extensive description about how to wear the microphone and so on . postdoc f: Oh . grad a: But I felt that in a real situation we were very seldom gonna get people to really do it and maybe it wasn't worth concentrating on . But {disfmarker} professor g: Well , I think that that 's {disfmarker} that 's a good back - off position . That 's what I was saying {vocalsound} earlier , th that , you know , we are gonna get some {vocalsound} recordings that are imperfect and , hey , that 's life . But I {disfmarker} I think that it {disfmarker} it doesn't hurt , uh , the naturalness of the situation to try to have people {pause} wear the microphones properly , if possible , grad a: Mm - hmm . professor g: because , {vocalsound} um , the natural situation is really what we have with the microphones on the table . grad a: Oh . That 's true . professor g: I mean , I think , {vocalsound} you know , in the target applications that we 're talking about , people aren't gonna be wearing head - mounted mikes anyway . phd c: Yeah . phd d: Yeah . professor g: So this is just for u these head - mounted mikes are just for use with research . grad a: Mm - hmm . phd d: Yeah . professor g: And , uh , it 's gonna make {disfmarker} You know , if {disfmarker} if An - Andreas plays around with language modeling , he 's not gonna be m wanna be messed up by people breathing into the microphone . grad a: Right . professor g: So it 's {disfmarker} it 's , uh , uh {disfmarker} grad a: Well , I 'll dig through the documentation to DragonDictate and ste s see if they still have the little {pause} form . professor g: But it does happen . phd d: Yeah . professor g: Right ? I mean , and any {disfmarker} phd b: It 's interesting , uh , I talked to some IBM guys , uh , last January , I think , I was there . And {disfmarker} so people who were working on the {disfmarker} on their ViaVoice dictation product . professor g: Yeah . phd b: And they said , uh , the breathing is really a {disfmarker} a terrible problem {pause} for them , to {disfmarker} to not recognize breathing as speech . postdoc f: Wow . phd b: So , anything to reduce breathing is {disfmarker} is {disfmarker} is a good thing . professor g: Yeah . grad a: Well , that 's the {disfmarker} It seemed to me when I was using Dragon that it was really microphone placement helped an {disfmarker} in , uh {disfmarker} an enormous amount . phd b: Mm - hmm . grad a: So you want it enough to the side so that when you exhale through your nose , it doesn't {disfmarker} the wind doesn't hit the mike . phd b: Right . Mm - hmm . grad a: And then , uh {disfmarker} Everyone 's adjusting their microphones , of course . And then just close enough so that you get good volume . So you know , wearing it right about here seems to be about the right way to do it . phd d: Yeah . professor g: Yeah . postdoc f: Is {disfmarker} Uh - huh . professor g: I remember when I was {disfmarker} when I {disfmarker} I {disfmarker} I {disfmarker} I used , uh , um , {vocalsound} a prominent laboratory 's , uh , uh , speech recognizer about , {vocalsound} uh {disfmarker} This was , boy , this was a while ago , this was about twelve {disfmarker} twelve years ago or something . And , um , they were {disfmarker} they were perturbed with me because I was breathing in instead of breathing out . And they had models for {disfmarker} they {disfmarker} {vocalsound} they had Markov models for br breathing out but they didn't have them for breathing in . phd d: Yeah . professor g: Uh {disfmarker} postdoc f: That 's interesting . Well , what I wondered is whether it 's possible to have {disfmarker} {vocalsound} to maybe use the display at the beginning grad a: Yeah . postdoc f: to be able to {disfmarker} to judge how {disfmarker} how correctly {disfmarker} I mean , have someone do some routine whatever , and {disfmarker} and then see if when they 're breathing it 's showing . grad a: I mean , when {disfmarker} when it 's on , you can see it . postdoc f: I don't know if the {disfmarker} if it 's {disfmarker} professor g: I {disfmarker} grad a: You can definitely see it . postdoc f: Can you see the breathing ? grad a: Absolutely . postdoc f: Cuz I {disfmarker} grad a: Absolutely . postdoc f: Oh . professor g: Yeah . grad a: And so , you know , I 've {disfmarker} I 've sat here and watched sometimes the breathing , professor g: I grad a: and the bar going up and down , and I 'm thinking , I could say something , but professor g: I mean , I think {disfmarker} grad a: I don't want to make people self - conscious . Stop breathing ! professor g: It {disfmarker} it 's going to be imperfect . postdoc f: Yeah . Uh - huh . professor g: You 're not gonna get it perfect . And you can do some , uh , you know , first - order thing about it , which is to have people move it , uh , uh , a away from being just directly in front of the middle phd d: Yeah . postdoc f: Good . professor g: but not too far away . postdoc f: Yeah , i professor g: And then , you know , I think there 's not much {disfmarker} Because you can't al you know , interfere w you can't fine tune the meeting that much , I think . grad a: Right . phd d: Yeah . professor g: It 's sort of {disfmarker} postdoc f: That 's true . It just seems like i if something l simple like that can be tweaked {vocalsound} and the quality goes , you know , uh , dramatically up , then it might be worth {pause} doing . grad a: Yep . And then also {disfmarker} the position of the mike also . If it 's more directly , you 'll get better volume . So {disfmarker} so , like , yours is pretty far down {pause} below your mouth . Yeah . phd d: Yeah . postdoc f: But {disfmarker} Mm - hmm . My {disfmarker} my feedback from the transcribers is he is always close to crystal clear and {disfmarker} and just fan fantastic to {disfmarker} phd c: Yeah . phd d: Mmm , yeah . professor g: Mm - hmm . grad a: I don't know why that is . postdoc f: Well , I mean , you {disfmarker} Yeah , of course . You 're {disfmarker} you 're also {disfmarker} uh , your volume is {disfmarker} is greater . But {disfmarker} but still , I mean , they {disfmarker} they say {disfmarker} grad a: I 've been eating a lot . postdoc f: I it makes their {disfmarker} their job extremely easy . professor g: Uh . postdoc f: Yeah . professor g: And then there 's mass . postdoc f: Mm - hmm . professor g: Anyway . postdoc f: I could say something about {disfmarker} about the {disfmarker} Well , I don't know what you wanna do . Yeah . professor g: About what ? postdoc f: About the transcribers or anything or {disfmarker} ? I don't know . professor g: Well , the other {disfmarker} phd b: But , uh , just to {disfmarker} to , um {disfmarker} professor g: why don't we do that ? phd b: One more remark , uh , concerning the SRI recognizer . Um . It is useful to transcribe and then ultimately train models for things like breath , and also laughter is very , very frequent and important to {disfmarker} {vocalsound} to model . professor g: Mm - hmm . phd b: So , grad a: So , phd b: if you can in your transcripts mark {disfmarker} grad a: mark them ? phd b: mark very audible breaths and laughter especially , phd c: Mmm . phd b: um {disfmarker} postdoc f: They are . phd b: OK . postdoc f: They 're putting {disfmarker} Eh , so in curly brackets they put " inhale " or " breath " . grad a: Oh , great . phd b: Mm - hmm . postdoc f: It {disfmarker} they {disfmarker} and then in curly brackets they say " laughter " . Now they 're {disfmarker} {vocalsound} they 're not being {pause} awfully precise , uh , m So they 're two types of laughter that are not being distinguished . phd b: Mm - hmm . postdoc f: One is {vocalsound} when sometimes s someone will start laughing when they 're in the middle of a sentence . phd b: Mm - hmm . postdoc f: And {disfmarker} and then the other one is when they finish the sentence and then they laugh . So , um , I {disfmarker} I did s I did some double checking to look through {disfmarker} I mean , {vocalsound} you 'd need to have extra  e extra complications , like time tags indicating the beginning and ending of {disfmarker} {vocalsound} of the laughing through the utterance . phd b: It 's not so {disfmarker} I don't think it 's , um {disfmarker} postdoc f: And that {disfmarker} and what they 're doing is in both cases just saying " curly brackets laughing " a after the unit . phd b: As {disfmarker} as long as there is an indication that there was laughter somewhere between {pause} two words {vocalsound} I think that 's sufficient , phd c: Yeah . postdoc f: Good . Oh ! grad a: Against {disfmarker} they could do forced alignment . postdoc f: OK . phd b: because actually the recognition of laughter once you kn um {disfmarker} you know , is pretty good . phd c: Yeah . phd b: So as long as you can stick a {disfmarker} you know , a t a tag in there that {disfmarker} that indicates that there was laughter , grad a: Oh , I didn't know that . phd b: that would probably be , uh , sufficient to train models . postdoc f: OK . grad a: That would be a really interesting {pause} prosodic feature , postdoc f: Then {disfmarker} phd d: Yeah . postdoc f: And let me ask y and I gotta ask you one thing about that . grad a: when {disfmarker} phd b: Hmm . postdoc f: So , um , if they laugh between two words , you {disfmarker} you 'd get it in between the two words . phd b: Mm - hmm . Right . postdoc f: But if they laugh across three or four words you {disfmarker} you get it after those four words . Does that matter ? phd d: Yeah . phd b: Well , the thing that you {disfmarker} is hard to deal with is whe {vocalsound} when they speak while laughing . Um , and that 's , uh {disfmarker} I don't think that we can do very well with that . grad a: Right . phd b: So {disfmarker} phd d: Yeah . phd b: But , um , that 's not as frequent as just laughing between speaking , postdoc f: OK . grad a: So are {disfmarker} do you treat breath and laughter as phonetically , or as word models , or what ? phd b: so {disfmarker} professor g: Uh is it ? phd d: Huh . I {disfmarker} I think it 's frequent in {disfmarker} in the meeting . postdoc f: I think he 's right . Yeah . phd b: We tried both . Uh , currently , um , we use special words . There was a {disfmarker} there 's actually a word for {disfmarker} uh , it 's not just breathing but all kinds of mouth {disfmarker} grad a: Mm - hmm . Mouth stuff ? phd b: uh , mouth {disfmarker} mouth stuff . And then laughter is a {disfmarker} is a special word . grad a: How would we do that with the hybrid system ? professor g: Same thing . grad a: So train a phone {pause} in the neural net ? phd b: Same thing ? Yeah . Yeah . You ha Oh . And each of these words has a dedicated phone . professor g: No {disfmarker} grad a: Oh , it does ? phd b: So the {disfmarker} so the {disfmarker} the mouth noise , uh , word has just a single phone , um , that is for that . grad a: Right . So in the hybrid system we could train the net with a laughter phone and a breath sound phone . professor g: Yeah . phd b: Yeah . Yeah . professor g: I mean , it 's {disfmarker} it 's {disfmarker} it 's always the same thing . postdoc f: Mm - hmm . professor g: Right ? I mean , you could {disfmarker} you could say well , let {disfmarker}  we now think that laughter should have three sub sub {vocalsound} sub - units in the {disfmarker} the three states , uh {disfmarker} different states . phd c: Yeah . professor g: And then you would have three {disfmarker} I mean , you know , eh , eh , it 's u grad a: Do whatever you want . phd b: And the {disfmarker} the pronun the pronunciations {disfmarker} the pronunciations are l are somewhat non - standard . phd d: Yeah . professor g: Yeah , yeah . phd d: No . phd b: They actually are {disfmarker} uh , it 's just a single , s uh , you know , a single phone in the pronunciation , but it has a self - loop on it , so it can {disfmarker} grad a: To {pause} go on forever ? phd b: r can go on forever . grad a: And how do you handle it in the language model ? phd b: It 's just a {disfmarker} it 's just a word . grad a: It 's just a word in the language model . phd b: We train it like any other word . grad a: Cool . phd b: Yeah . We also tried , {vocalsound} um , absorbing these {disfmarker} uh , both laughter and {disfmarker} and actually also noise , and , um {disfmarker} phd d: Yeah . phd b: Yes . OK . Anyway . We also tried absorbing that into the pause model {disfmarker} I mean , the {disfmarker} the {disfmarker} the model that {disfmarker} that matches the stuff between words . professor g: Mm - hmm . phd b: And , um , it didn't work as well . So . grad a: Huh . OK . postdoc f: Mm - hmm . grad a: Can you hand me your digit form ? phd b: Sorry . grad a: I just wanna mark that you did not read digits . professor g: OK . Say hi for me . postdoc f: Good . You {disfmarker} you did get me to thinking about {disfmarker} I {disfmarker} I 'm not really sure which is more frequent , whether f f laughing {disfmarker} I think it may be an individual thing . Some people are more prone to laughing when they 're speaking . professor g: Yeah . grad a: I was noticing that with Dan in the one that we , uh {disfmarker} we hand tran hand - segmented , professor g: Yeah . I think {disfmarker} postdoc f: But I can't {disfmarker} phd d: Yeah . grad a: that {disfmarker} th he has these little chuckles as he talks . postdoc f: Yeah . OK . professor g: I 'm sure it 's very individual . And {disfmarker} and {disfmarker} one thing that c that we 're not doing , of course , is we 're not claiming to , uh , get {disfmarker} be getting a representation of mankind in these recordings . We have {vocalsound} this very , very tiny sample of {disfmarker} of {disfmarker} phd d: Yeah . postdoc f: Yeah . phd d: Yeah . grad a: Speech researchers ? professor g: Uh , yeah . And {disfmarker} {vocalsound} Yeah , r right . phd d: Speech research . professor g: So , uh , who knows . Uh {disfmarker} Yeah . Why don why don't we just {disfmarker} since we 're on this vein , why don't we just continue with , uh , what you were gonna say about the transcriptions postdoc f: OK . professor g: and {disfmarker} ? postdoc f: Um , um , the {disfmarker} I {disfmarker} I 'm really very for I 'm extremely fortunate with the people who , uh , applied and who are transcribing for us . They {vocalsound} are , um , um , uh really perceptive and very , um {disfmarker} and I 'm not just saying that cuz they might be hearing this . grad a: Cuz they 're gonna be transcribing it in a few days . postdoc f: No , they 're super . They 're {disfmarker} the they {disfmarker} very quick . phd e: OK . Turn the mikes off and let 's talk . postdoc f: Yeah , I know . I am {disfmarker} I 'm serious . They 're just super . So I , um , e you know , I {disfmarker} I brought them in and , um , trained them in pairs because I think people can raise questions {disfmarker} grad a: That 's a good idea . postdoc f: you know , i i the they think about different things and they think of different {disfmarker} and um , I trained them to , uh , f on about a minute or two of the one that was already transcribed . This also gives me a sense of {disfmarker} You know , I can {disfmarker} I can use that later , with reference to inter - coder reliability kind of issues . But the main thing was to get them used to the conventions and , {vocalsound} you know , the idea of the {disfmarker} th th the size of the unit versus how long it takes to play it back so these {disfmarker} th sort of calibration issues . And then , um , I just set them loose and they 're {disfmarker} they all have e a already background in using computers . They 're , um {disfmarker} they 're trained in linguistics . grad a: Good . Oh , no . Is that good or bad ? postdoc f: They got {disfmarker} professor g: Uh - huh . postdoc f: Well , they they 're very perce they 'll {disfmarker} So one of them said " well , you know , he really said " n " , not really " and " , phd d: Yeah . Yeah . postdoc f: so what {vocalsound} {disfmarker} what should I do with that ? " grad a: Yeah . postdoc f: And I said , " well for our purposes , professor g: Yeah . postdoc f: I do have a convention . If it 's an {disfmarker} a noncanonical p " That one , I think we {disfmarker} you know , with Eric 's work , I sort of figure we {disfmarker} we can just treat that as a variant . But I told them if {disfmarker} if there 's an obvious speech error , uh , like I said in one thing , professor g: OK . Yes . postdoc f: and I gave my {disfmarker} my example , like I said , " microfon " {pause} in instead of " microphone " . Didn't bother {disfmarker} I knew it when I said it . I remember s thinking " oh , that 's not correctly pronounced " . But it {disfmarker} but I thought {vocalsound} it 's not worth fixing cuz often when you 're speaking everybody knows what {disfmarker} what you mean . grad a: You 'll self - repair . Yeah . phd c: Yeah . postdoc f: But I have a convention that if it 's obviously a noncanonical pronunciation {disfmarker} a speech error with {disfmarker} you know , wi within the realm of resolution that you can tell in this native English {disfmarker} American English speaker , you know that I didn't mean to say " microfon . " Then you 'd put a little tick at the beginning of the word , professor g: Yeah . postdoc f: and that just signals that , um , this is not standard , and then in curly brackets " pron {nonvocalsound} error " . And , um , and other than that , it 's w word level . But , you know , the fact that they noticed , you know , the " nnn " . " He said " nnn " , not " and " . What shall I do with that ? " I mean , they 're very perceptive . And {disfmarker} and s several of them are trained in IPA . C they really could do phonetic transcription if {disfmarker} if we wanted them to . professor g: Mm - hmm . Right . Well {disfmarker} {vocalsound} Well , you know , it might be something we 'd wanna do with some , uh , s small subset {pause} of the whole thing . grad a: Hmm . Where were they when {pause} we needed them ? postdoc f: I think {disfmarker} professor g: We certainly wouldn't wanna do it with everything . postdoc f: And I 'm also thinking these people are a terrific pool . I mean , if , uh {disfmarker} so I {disfmarker} I told them that , um , we don't know if this will continue past the end of the month professor g: Uh - huh . postdoc f: and I also {disfmarker} m I think they know that the data p source is limited and I may not be able to keep them employed till the end of the month even , although I hope to . professor g: The other thing we could do , actually , uh , is , uh , use them for a more detailed analysis of the overlaps . postdoc f: And {disfmarker} Oh , that 'd be so super . They would be so {disfmarker} s so terrific . grad a: I mean , this was something that we were talking about . professor g: Right ? grad a: We could get a very detailed overlap if they were willing to transcribe each meeting four or five times . Right ? One for each participant . So they could by hand {disfmarker} professor g: Well , that 's one way to do it . grad a: Yeah . professor g: But I 've been saying the other thing is just go through it for the overlaps . grad a: Yeah . postdoc f: Mm - hmm , that 's right . professor g: Right ? postdoc f: And with the right in interface {disfmarker} professor g: Given that y and {disfmarker} and do {disfmarker} so instead of doing phonetic , uh , uh , transcription for the whole thing , phd d: Yeah . professor g: which {vocalsound} we know from the {disfmarker} Steve 's experience with the Switchboard transcription is , you know , very , very time - consuming . And {disfmarker} {vocalsound} and you know , it took them I don't know how many months to do {disfmarker} to get four hours . And so {vocalsound} that hasn't been really our focus . Uh , we can consider it . But , I mean , the other thing is since we 've been spending so much time thinking about overlaps is {disfmarker} is maybe get a much more detailed analysis of the overlaps . phd d: Yeah . postdoc f: Mm - hmm . professor g: But anyway , I 'm {disfmarker} I 'm open to c our consideration . postdoc f: That 'd be great . phd d: Hmm . professor g: I {disfmarker} I don't wanna say that by fiat . postdoc f: Yeah . professor g: I 'm open to every consideration of {vocalsound} what are some other kinds of detailed analysis that would be most useful . postdoc f: Mm - hmm . professor g: And , uh , uh , phd d: Hmm . professor g: I {disfmarker} I {disfmarker} I think {vocalsound} this year we {disfmarker} we actually , uh , can do it . postdoc f: Oh , wonderful . professor g: It 's a {disfmarker} we have {disfmarker} we have {disfmarker} due to @ @ {comment} variations in funding we have {disfmarker} we seem to be doing , uh , very well on m money for this {disfmarker} this year , and {vocalsound} next year we may have {disfmarker} have much less . grad a: Is {disfmarker} you mean two thousand one ? professor g: So I don't wanna hire a {disfmarker} grad a: Calendar year or {disfmarker} ? professor g: Uh , I mean , calendar year two thousand one . grad a: OK . professor g: Yeah . So it 's {disfmarker} uh , it 's {disfmarker} we don't wanna hire a bunch of people , a long - term staff , grad a: Full - time . Yeah . postdoc f: Mm - hmm . Yeah . professor g: because {vocalsound} the {disfmarker} the funding that we 've gotten is sort of a big chunk for this year . But {vocalsound} having {pause} temporary people doing some specific thing that we need is actually a perfect match to that kind of , uh , funding . postdoc f: Wonderful . phd d: Yeah . postdoc f: And then school will start in {disfmarker} in the sixt on the sixteenth . professor g: So . postdoc f: Some of them will have to cut back their hours at that point . professor g: Yeah . phd e: Are they working full - time now , or {disfmarker} ? postdoc f: But {disfmarker} {nonvocalsound} {vocalsound} Some of them are . grad a: Wow . postdoc f: Yeah . Well , why do I wouldn't say forty - hour weeks . No . But what I mean is {disfmarker} Oh , I shouldn't say it that way because {nonvocalsound} that does sound like forty - hour weeks . No . I th I {disfmarker} I would say they 're probably {nonvocalsound} {disfmarker} they don't have o they don't have other things that are taking away their time . grad a: I don't see how someone could do forty hours a week on transcription . phd e: Hmm . postdoc f: But {nonvocalsound} it 's {disfmarker} you can't . professor g: Yeah . Yeah . postdoc f: No . You 're right . It 's {disfmarker} i it would be too taxing . But , um , they 're putting {nonvocalsound} in a lot of {disfmarker} professor g: Yeah . postdoc f: And {disfmarker} and I checked them over . professor g: I {disfmarker} postdoc f: I {disfmarker} I {disfmarker} I haven't checked them all , but {pause} just spot - checking . They 're fantastic . grad a: I think it would be {disfmarker} professor g: I remember when we were transcribing BeRP , uh , uh , {vocalsound} uh , Ron Kay , uh , volunteered to {disfmarker} to do some of that . And , he was {disfmarker} the first {disfmarker} first stuff he did was transcribing Chuck . And he 's saying " You {disfmarker} you know , I always thought Chuck spoke really well . " postdoc f: Yeah . Yeah . Well , you know , and I also thought , y Liz has this , eh , you know , and I do also , this {disfmarker} this interest in the types of overlaps that are involved . These people would be {nonvocalsound} great choices for doing coding of that type if we wanted , grad a: We 'd have to mark them . postdoc f: or whatever . So , um . professor g: Mm - hmm . phd d: Mm - hmm . grad a: I think it would also be interesting to have , uh , a couple of the meetings have more than one transcriber do , professor g: Yeah . grad a: cuz I 'm curious about inter - annotator agreement . postdoc f: Mm - hmm . phd d: Yeah . postdoc f: OK . Yeah . Th - that 'd be {disfmarker} I think that 's a {disfmarker} a good idea . professor g: Yeah . postdoc f: You know , there 's also , the e In my mind , I think A An - Andreas was {pause} leading to this topic , the idea that , um , {vocalsound} we haven't yet seen the {disfmarker} the type of transcript that we get from IBM , and it may just be , you know , pristine . But on the other hand , given the lesser interface {disfmarker} Cuz this is , you know {disfmarker} we 've got a good interface , we 've got great headphones , m um {disfmarker} professor g: It could be that they will uh {disfmarker} theirs will end up being a kind of fir first pass or something . postdoc f: Something like that . professor g: Maybe an elaborate one , cuz again they probably are gonna do these alignments , which will also clear things up . postdoc f: That 's {disfmarker} that 's true . Al - although you have to s Don't you have to start with a close enough approximation {nonvocalsound} of the {disfmarker} of the verbal part {nonvocalsound} to be able to {disfmarker} ? professor g: Well , tha that 's {disfmarker} that 's debatable . postdoc f: OK . professor g: Right ? I mean , so the {disfmarker} so the argument is that if your statistical system is good {vocalsound} it will in fact , uh , clean things up . postdoc f: OK . professor g: Right ? So it it 's got its own objective criterion . phd d: Yeah . professor g: And , uh , so in principle you could start up with something that was kind of rough {disfmarker} I mean , to give an example of , um , something we used to do , uh , at one point , uh , back {disfmarker} back when Chuck was here in early times , is we would take , um , {vocalsound} da take a word and , uh , have a canonical pronunciation and , uh , if there was five phones in a word , {vocalsound} you 'd break up the word , {vocalsound} uh , into five equal - length pieces which is completely gross . grad a: Wrong . phd d: Yeah . professor g: Right ? I mean , th the timing is off {pause} all over the place in just about any word . postdoc f: Mm - hmm . OK . professor g: But it 's O K . You start off with that and the statistical system then aligns things , and eventually you get something that doesn't really look too bad . postdoc f: Oh , excellent . OK . professor g: So {disfmarker} so I think using a {disfmarker} a good {pause} aligner , um , actually can {disfmarker} can help a lot . Um . {vocalsound} But , uh , you know , they both help each other . If you have a {disfmarker} if you have a better starting point , then it helps the aligner . If you have a good alignment , it helps the , uh , th the human in {disfmarker} in taking less time to correct things . postdoc f: OK . professor g: So {disfmarker} so {disfmarker} postdoc f: Excellent . I guess there 's another aspect , too , and I don't know {disfmarker} uh , this {disfmarker} this is {disfmarker} very possibly a different , uh , topic . But , {nonvocalsound} uh , just let me say {pause} with reference to this idea of , um , {vocalsound} higher - order organization within meetings . So like in a {disfmarker} you know , the topics that are covered during a meeting with reference to the other , uh , uses of the data , professor g: Mm - hmm . postdoc f: so being able to {pause} find where so - and - so talked about such - and - such , then , um , um {disfmarker} e I mean , I {disfmarker} I {disfmarker} I did sort of a {disfmarker} {vocalsound} a rough {pause} pass {nonvocalsound} on encoding , like , episode - like level things on the , uh , transcribed meeting {disfmarker} professor g: Mm - hmm . postdoc f: already transcribed meeting . And I don't know if , um {disfmarker} professor g: Mm - hmm . postdoc f: where {nonvocalsound} that {disfmarker} i if that 's something that we wanna do with each meeting , sort of like a , um {disfmarker} it 's like a manifest , when you get a box full of stuff , or {disfmarker} or if that 's , um {disfmarker} professor g: Mm - hmm . postdoc f: I mean , i I {disfmarker} I don't know what uh , level of detail would be most useful . I don't know i if that 's something that {pause} I should do when I look over it , or if we want someone else to do , or whatever . professor g: Mm - hmm . postdoc f: But this issue of the contents of the meeting in an outline form . OK . professor g: Yeah . Meaning really isn't my thing . Um {disfmarker} grad a: I think it just {disfmarker} whoever is interested can do that . I mean , so if someone wants to use that data {disfmarker} postdoc f: OK . professor g: We 're running a little short here . postdoc f: That 's fine . professor g: We , uh , uh , cou trying to {disfmarker} postdoc f: I 'm finished . professor g: eh , was {disfmarker} p Well , you know , the thing I 'm concerned about is we wanted to do these digits postdoc f: Oh , yeah . professor g: and {disfmarker} and I haven't heard , uh , from Jose yet . postdoc f: Oh , yes . phd d: OK . What do you want ? postdoc f: Mm - hmm . professor g: So {disfmarker} grad a: We could skip the digits . professor g: Uh {disfmarker} grad a: We don't have to read digits each time . professor g: Uh {disfmarker} I {disfmarker} I {disfmarker} I think it {disfmarker} you know , another {disfmarker} another bunch of digits . More data is good . grad a: OK . phd d: Yeah . Sure . professor g: So {disfmarker} so I 'd like to do that . But I think , do you , maybe , eh {disfmarker} ? Did you prepare some whole thing you wanted us just to see ? phd d: Yeah . It 's {disfmarker} it 's prepared . professor g: Or what was that ? Yeah . postdoc f: Oh , k Sorry . professor g: Uh , how long a {disfmarker} ? phd d: I {disfmarker} I think it 's {disfmarker} it 's fast , because , uh , I have the results , eh , of the study of different energy without the law length . Eh , um , eh , in the {disfmarker} in the measurement , uh , the average , uh , dividing by the {disfmarker} by the , um , variance . Um , I {disfmarker} th i professor g: Yeah . phd d: the other , uh {disfmarker} the {disfmarker} the last w uh , meeting {disfmarker} eh , I don't know if you remain we have problem to {disfmarker} with the {disfmarker} {vocalsound} with {disfmarker} with the parameter {disfmarker} with the representations of parameter , because the {disfmarker} the valleys and the peaks in the signal , eh , look like , eh , it doesn't follow to the {disfmarker} to the energy in the signal . professor g: Yes . Right . phd d: And it was a problem , uh , with the scale . grad a: With what ? phd d: Eh , the scale . postdoc f: Scale . grad a: Scale . phd d: Eh , and I {disfmarker} I change the scale and we can see the {disfmarker} the variance . professor g: OK . But the bottom line is it 's still not , uh , separating out very well . phd d: Yeah . Yeah . professor g: Right ? phd d: The distribution {disfmarker} the distribution is {disfmarker} is similar . professor g: OK . So that 's {disfmarker} that 's {disfmarker} that 's enough then . OK . phd d: Yeah . professor g: No , I mean , that there 's no point in going through all of that if that 's the bottom line , really . phd d: Yeah . postdoc f: Mm - hmm . phd d: Yeah . professor g: So , I {disfmarker} I think we have to start {disfmarker} Uh , I mean , there there 's two suggestions , really , which is , uh {disfmarker} what we said before is that , phd d: Mmm , yeah . professor g: um , it looks like , at least that you haven't found an obvious way to normalize so that the energy is anything like a reliable , uh , indicator of the overlap . phd d: Yeah . Yeah . professor g: Um , I {disfmarker} I 'm {disfmarker} I 'm still {pause} a little f think that 's a little funny . These things l @ @ seems like there should be , phd d: Yeah . professor g: but {disfmarker} {vocalsound} but you don't want to keep , uh {disfmarker} keep knocking at it if it 's {disfmarker} if you 're not getting any {disfmarker} any result with that . But , I mean , the other things that we talked about is , uh , {vocalsound} pitch - related things and harmonicity - related things , phd d: Yeah . professor g: so {disfmarker} which we thought also should be some kind of a reasonable indicator . Um {disfmarker} But , uh , a completely different tack on it wou is the one that was suggested , uh , by your colleagues in Spain , phd d: Yeah . professor g: which is to say , don't worry so much about the , uh , features . phd d: Yeah . professor g: That is to say , use , you know , as {disfmarker} as you 're doing with the speech , uh , nonspeech , use some very general features . phd c: Yeah . phd d: Yeah . professor g: And , uh , then , uh , look at it more from the aspect of modeling . phd d: Yeah . professor g: You know , have a {disfmarker} have a couple Markov models and {disfmarker} and , uh , try to indi try to determine , you know , w when is th when are you in an overlap , when are you not in an overlap . phd d: Hmm . professor g: And let the , uh , uh , statistical system {pause} determine what 's the right way to look at the data . phd d: Yeah . professor g: I {disfmarker} I , um , I think it would be interesting to find individual features and put them together . I think that you 'd end up with a better system overall . phd d: Yeah . professor g: But given the limitation in time {vocalsound} and given the fact that Javier 's system already exists {pause} doing this sort of thing , phd d: Yeah . professor g: uh , but , uh , its main limitation is that , again , it 's only looking at silences which would {disfmarker} phd d: Yeah . Yeah . professor g: maybe that 's a better place to go . phd d: Yeah . postdoc f: Mm - hmm . professor g: So . phd d: I {disfmarker} I {disfmarker} I think that , eh , the possibility , eh , can be that , eh , Thilo , eh , working , eh , with a new class , not only , eh , nonspeech and speech , but , eh , in {disfmarker} in {disfmarker} in the speech class , professor g: Mm - hmm . Mm - hmm . phd d: dividing , eh , speech , eh , of {disfmarker} from a speaker and overlapping , to try {disfmarker} to {disfmarker} to do , eh , eh , a fast {disfmarker} a fast , eh , {vocalsound} experiment to {disfmarker} to prove that , nnn , this fea eh , general feature , {vocalsound} eh , can solve the {disfmarker} the {disfmarker} the problem , professor g: Yeah . phd d: and wh what {disfmarker} nnn , how far is {disfmarker} professor g: Maybe . Yeah . phd d: And , I {disfmarker} I have prepared the {disfmarker} the pitch tracker now . grad a: Mm - hmm . phd d: And I hope the {disfmarker} the next week I will have , eh , some results and we {disfmarker} we will show {disfmarker} we will see , eh , the {disfmarker} the parameter {disfmarker} the pitch , {vocalsound} eh , tracking in {disfmarker} with the program . professor g: I see . phd d: And , nnn , nnn {disfmarker} professor g: Ha - h have you ever looked at the , uh , uh {disfmarker} Javier 's , uh , speech segmenter ? phd c: No . No . phd d: No . professor g: Oh . Maybe m you could , you kn uh show Thilo that . phd d: Yeah . phd c: Yeah . Sure . phd d: Yeah . professor g: Cuz again the idea is there {disfmarker} the limitation there again was that he was {disfmarker} he was only using it to look at silence as a {disfmarker} as a {disfmarker} as a {disfmarker} as a p putative split point between speakers . phd d: Yeah . professor g: But if you included , uh , broadened classes then {pause} in principle maybe you can {pause} cover the overlap cases . phd c: OK . phd d: Yeah . phd c: Yeah , but I 'm not too sure if {disfmarker} if we can {pause} really represent {vocalsound} overlap with {disfmarker} with the s {pause} detector I {disfmarker} I {disfmarker} I used up to now , phd d: Mmm , yeah . professor g: Uh {disfmarker} postdoc f: Mm - hmm . grad a: I think with {disfmarker} phd c: the {disfmarker} to speech - nonspeech as {disfmarker} grad a: That 's right . But I think Javier 's {disfmarker} phd c: it 's only speech or it 's {disfmarker} it 's {disfmarker} it 's nonspeech . phd d: Ah . Yeah . postdoc f: Mm - hmm . grad a: I think Javier 's might be able to . phd c: So . professor g: N n grad a: It doesn't have the same Gaus - uh , H M M modeling , phd c: Yeah . grad a: which is I think a drawback . phd c: OK . grad a: But , uh {disfmarker} professor g: Well , it 's {disfmarker} sort of has a simple one . phd d: Mmm , yeah . grad a: Does it ? professor g: Right ? It 's {disfmarker} it 's just {disfmarker} it 's just a {disfmarker} isn't it just a Gaussian phd d: Yeah . professor g: for each {disfmarker} ? grad a: Yeah . And then {pause} he ch you choose optimal splitting . phd d: Hmm . postdoc f: Mm - hmm . professor g: Yeah . Oh , it doesn't have {disfmarker} it doesn't have any temporal , uh {disfmarker} ? grad a: Maybe I 'm misremembering , but I did not think it had a Markov {disfmarker} professor g: I thought it {disfmarker} Yeah . I gues I guess I don't remember either . Uh . It 's been a while . phd c: Yeah . Uh , I could have a look at it . phd d: Javier {disfmarker} professor g: Uh . phd c: So . phd d: You mean Ja - eh , eh , Javier program ? grad a: Mm - hmm . phd d: No , Javier di doesn't worked with , uh , a Markov {disfmarker} grad a: Yeah , I didn't think so . phd d: He on only train {disfmarker} professor g: Oh , OK . So he 's just {disfmarker} he just computes a Gaussian over potential {disfmarker} grad a: Yep . phd d: Yeah . It was only Gaussian . professor g: Oh , I see . I see . grad a: And so I {disfmarker} I think it would work fine for detecting overlap . phd d: This is the idea . professor g: And {disfmarker} and {disfmarker} grad a: It 's just , uh , that i it {disfmarker} he has the two - pass issue that {disfmarker} What he does is , as a first pass he {disfmarker} he {disfmarker} p he does , um , a guess at where the divisions might be and he overestimates . And that 's just a data reduction step , so that you 're not trying at every time interval . phd c: OK . grad a: And so those are the putative {pause} places where he tries . phd d: Yeah . phd c: Yeah . OK . grad a: And right now he 's doing that with silence and that doesn't work with the Meeting Recorder . So if we used another method to get the first pass , I think it would probably work . phd c: Yeah . Yeah . Sure . Yeah . Yeah , OK . grad a: It 's a good method . As long as the len as long the segments are long enough . phd d: Yeah . grad a: That 's the other problem . phd c: So {disfmarker} professor g: O - k OK . So let me go back to what you had , though . phd c: Yeah . professor g: Um . phd d: Mm - hmm . professor g: The other thing one could do is {disfmarker} Couldn't {disfmarker} I mean , it 's {disfmarker} So you have two categories phd c: Yeah . professor g: and you have Markov models for each . Couldn't you have a third category ? So you have , uh {disfmarker} you have , {vocalsound} uh , nonspeech , single - person speech , and multiple - person speech ? postdoc f: He has this on his board actually . Don't you have , like those {disfmarker} those several different {vocalsound} categories on the board ? professor g: Right ? And then you have a Markov model for each ? phd c: Um {disfmarker} I 'm not sure . I {disfmarker} I thought about , uh , adding , uh , uh , another class too . But it 's not too easy , I think , the {disfmarker} the transition between the different class , to model them in {disfmarker} in the system I have now . But it {disfmarker} it {disfmarker} it could be possible , I think , professor g: I see . I see . phd c: in principle . professor g: Yeah , I mean , I {disfmarker} This is all pretty gross . phd d: Yeah . professor g: I mean , the {disfmarker} th the reason why , uh , I was suggesting originally that we look at features is because I thought , well , we 're doing something we haven't done before , phd c: Yeah . professor g: we should at least look at the space and understand {disfmarker} phd c: Yeah . phd d: Yeah . professor g: It seems like if two people {disfmarker} two or more people talk at once , it should get louder , phd c: Yeah . professor g: uh , and , uh , uh , there should be some discontinuity in pitch contours , phd c: I had the impression . phd d: Yeah . phd c: Yeah . professor g: and , uh , there should overall be a , um , smaller proportion of the total energy that is explained by any particular harmonic {pause} sequence in the spectrum . grad a: Right . phd c: Yeah . professor g: So those are all things that should be there . phd c: Yeah . phd d: Mm - hmm . professor g: So far , um , uh , Jose has {disfmarker} has been {disfmarker} By the way , I was told I should be calling you Pepe , but {disfmarker} phd d: Yeah . professor g: by your friends , but Anyway , phd d: Yeah . professor g: um , uh , the {disfmarker} has {disfmarker} has , uh , been exploring , uh , e largely the energy issue and , um , as with a lot of things , it is not {disfmarker} uh , like this , it 's not as simple as it sounds . phd c: Yeah . professor g: And then there 's , you know {disfmarker} Is it energy ? Is it log energy ? Is it LPC residual energy ? Is it {disfmarker} is it {disfmarker} {vocalsound} is it , uh , delta of those things ? Uh , what is it no Obviously , just a simple number {disfmarker} {vocalsound} absolute number isn't gonna work . So {vocalsound} it should be with {disfmarker} compared to what ? Should there be a long window for the {vocalsound} normalizing factor and a short window for what you 're looking at ? phd c: Yeah . professor g: Or , you know , how b short should they be ? So , phd d: Hmm . professor g: th he 's been playing around with a lot of these different things and {disfmarker} and so far at least has not come up with {vocalsound} any combination that really gave you an indicator . phd d: Yeah . professor g: So I {disfmarker} I still have a hunch that there 's {disfmarker} it 's in there some place , but it may be {disfmarker} given that you have a limited time here , it {disfmarker} it just may not be the best thing to {disfmarker} {vocalsound} to {disfmarker} to focus on for the remaining of it . phd d: Yeah . To overrule , yeah . professor g: So pitch - related and harmonic - related , I 'm {disfmarker} I 'm {pause} somewhat more hopeful for it . phd d: Yeah . Yeah . professor g: But it seems like if we just wanna get something to work , phd c: Yeah . phd d: Yeah . professor g: that , uh , their suggestion of {disfmarker} of {disfmarker} Th - they were suggesting going to Markov models , uh , but in addition there 's an expansion of what Javier did . And one of those things , looking at the statistical component , phd d: One . phd c: Yeah . professor g: even if the features that you give it are maybe not ideal for it , it 's just sort of this general filter bank phd c: Yeah . professor g: or {disfmarker} {vocalsound} or cepstrum or something , um {disfmarker} Eee {vocalsound} it 's in there somewhere probably . phd d: But , eh , what did you think about the possibility of using the Javier software ? Eh , I mean , the , uh {disfmarker} the , uh {disfmarker} the BIC criterion , the {disfmarker} the {disfmarker} t to train the {disfmarker} the Gaussian , eh , using the {disfmarker} the mark , eh , by hand , eh , eh , to distinguish be mmm , to train overlapping zone and speech zone . I mean , eh , {vocalsound} I {disfmarker} I {disfmarker} I think that an interesting , eh , experiment , eh , could be , th eh , to prove that , mmm , if s we suppose that , eh , the {disfmarker} the first step {disfmarker} {vocalsound} I mean , the {disfmarker} the classifier what were the classifier from Javier or classifier from Thilo ? W What happen with the second step ? I {disfmarker} I mean , what {disfmarker} what happen with the , eh {disfmarker} the , uh , clu the , uh {disfmarker} the clu the clustering process ? grad a: Mm - hmm . phd d: Using the {disfmarker} the Gaussian . grad a: You mean Javier 's ? phd d: Yeah . grad a: What do you mean ? phd d: I {disfmarker} I mean , that is {disfmarker} is enough {disfmarker} is enough , eh , to work well , eh , to , eh , separate or to distinguish , eh , between overlapping zone and , eh , speaker zone ? Because th {vocalsound} if {disfmarker} if we {disfmarker} if we , eh , nnn , develop an classifier {disfmarker} and the second step doesn't work {pause} well , eh , we have {pause} another problem . grad a: I {disfmarker} Yeah . I had tried doing it by hand at one point with a very short sample , phd d: N grad a: and it worked pretty well , but I haven't worked with it a lot . So what I d I d I took a hand - segmented sample phd d: Nnn , yeah . grad a: and I added ten times the amount of numbers at random , phd d: Yeah . grad a: and it did pick out pretty good boundaries . phd d: Oh . Yeah . But is {disfmarker} is {disfmarker} if {disfmarker} grad a: But this was just very anecdotal sort of thing . phd d: But it 's possible with my segmentation by hand {pause} that we have information about the {disfmarker} the overlapping , grad a: Right . So if we {disfmarker} if we fed the hand - segmentation to Javier 's and it doesn't work , then we know something 's wrong . phd d: uh {disfmarker} Yeah . The {disfmarker} N n Yeah . No . The demonstration by hand . Segmentation by hand I {disfmarker} I {disfmarker} I think is the fast experiment . grad a: Yeah . I think that 's probably worthwhile doing . phd d: Uh , we can prove that the {disfmarker} professor g: Uh - huh . grad a: Whether it 'll work or not . phd d: this kind o emph emphasises parameter and Gaussian {disfmarker} grad a: Yeah . professor g: Yeah . grad a: Yep . Y do you know where his software is ? Have you used it at all ? phd d: I yeah have . I have . grad a: OK . phd d:  grad a: So . I {disfmarker} I have as well , so if you need {disfmarker} need help let me know . phd d: OK . professor g: Let 's read some digits . grad a: OK . uuh postdoc f: Mm - hmm . grad a: And we are {disfmarker}