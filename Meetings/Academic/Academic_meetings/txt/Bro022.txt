professor b: I think for two years we were two months , uh , away from being done . phd a: And what was that , Morgan ? What project ? professor b: Uh , the , uh , TORRENT chip . phd a: Oh . professor b: Yeah . We were two {disfmarker} we were {disfmarker} phd c: Yeah . professor b: Uh , uh , we went through it {disfmarker} Jim and I went through old emails at one point and {disfmarker} and for two years there was this thing saying , yeah , we 're {disfmarker} we 're two months away from being done . It was very {disfmarker} very believable schedules , too . I mean , we went through and {disfmarker} with the schedules {disfmarker} and we {disfmarker} phd a: It was true for two years . professor b: Yeah . Oh , yeah . It was very true . phd a: So , should we just do the same kind of deal where we {pause} go around and do , uh , status report {pause} kind of things ? OK . And I guess when Sunil gets here he can do his last or something . So . professor b: Yeah . So we {pause} probably should wait for him to come before we do his . phd c: Mm - hmm . phd a: OK . That 's a good idea . professor b: Yeah . grad f: OK . professor b: Yeah . phd a: Any objection ? Do y OK , M professor b: All in favor phd a: Do you want to start , Morgan ? Do you have anything , or {disfmarker} ? professor b: Uh , I don't do anything . I {disfmarker} No , I mean , I {disfmarker} I 'm involved in discussions with {disfmarker} with people about what they 're doing , but I think they 're {disfmarker} since they 're here , they can talk about it themselves . grad f: OK . So should I go so that , uh , phd a: Yeah . Why don't you go ahead , Barry ? grad f: you 're gonna talk about Aurora stuff , per se ? phd a: OK . grad f: OK . Um . Well , this past week I 've just been , uh , getting down and dirty into writing my {disfmarker} my proposal . So , um {disfmarker} Mmm . I just finished a section on , uh {disfmarker} on talking about these intermediate categories that I want to classify , um , as a {disfmarker} as a middle step . And , um , I hope to {disfmarker} hope to get this , um {disfmarker} a full rough draft done by , uh , Monday so I can give it to Morgan . phd a: When is your , uh , meeting ? grad f: Um , my meeting phd a: Yeah . grad f: with , uh {disfmarker} ? Oh , oh , you mean the {disfmarker} the quals . phd a: The quals . Yeah . grad f: Uh , the quals are happening in July twenty - fifth . phd a: Oh . Soon . grad f: Yeah . phd a: Uh - huh . grad f: D - Day . phd a: Yeah . grad f: Uh - huh . phd a: So , is the idea you 're going to do this paper and then you pass it out to everybody ahead of time and {disfmarker} ? grad f: Right , right . So , y you write up a proposal , and give it to people ahead of time , and you have a short presentation . And , um , and then , um {disfmarker} then everybody asks you questions . phd a: Hmm . grad f: Yeah . phd a: I remember now . grad f: Yep . So , um . phd a: Have you d ? I was just gonna ask , do you want to say any {disfmarker} a little bit about it , grad f: Y s phd a: or {disfmarker} ? Mmm . grad f: Oh . Uh , a little bit about {disfmarker} ? phd a: Wh - what you 're {disfmarker} what you 're gonna {disfmarker} You said {disfmarker} you were talking about the , uh , particular features that you were looking at , grad f: Oh , the {disfmarker} the {disfmarker} phd a: or {disfmarker} grad f: Right . Well , I was , um , I think one of the perplexing problems is , um , for a while I was thinking that I had to come up with a complete set of intermediate features {disfmarker} in intermediate categories to {disfmarker} to classify right away . But what I 'm thinking now is , I would start with {disfmarker} with a reasonable set . Something {disfmarker} something like , um , um {disfmarker} like , uh , re regular phonetic features , just to {disfmarker} just to start off that way . And do some phone recognition . Um , build a system that , uh , classifies these , um {disfmarker} these feat uh , these intermediate categories using , uh , multi - band techniques . Combine them and do phon phoneme recognition . Look at {disfmarker} then I would look at the errors produced in the phoneme recognition and say , OK , well , I could probably reduce the errors if I included this extra feature or this extra intermediate category . That would {disfmarker} that would reduce certain confusions over other confusions . And then {disfmarker} and then {vocalsound} reiterate . Um , build the intermediate classifiers . Uh , do phoneme recognition . Look at the errors . And then postulate new {disfmarker} or remove , um , intermediate categories . And then do it again . phd a: So you 're gonna use TIMIT ? grad f: Um , for that {disfmarker} for that part of the {disfmarker} the process , yeah , I would use TIMIT . phd a: Mm - hmm . grad f: And , um , then {disfmarker} after {disfmarker} after , uh , um , doing TIMIT . Right ? phd a: Mm - hmm . grad f: Um , that 's {disfmarker} {vocalsound} that 's , um {disfmarker} that 's just the ph the phone recognition task . phd a: Yeah . grad f: Uh , I wanted to take a look at , um , things that I could model within word . So , I would mov I would then shift the focus to , um , something like Schw - Switchboard , uh , where I 'd {disfmarker} I would be able to , um {disfmarker} to model , um , intermediate categories that span across phonemes , phd a: Mm - hmm . grad f: not just within the phonemes , themselves , um , and then do the same process there , um , on {disfmarker} on a large vocabulary task like Switchboard . Uh , and for that {disfmarker} for that part I would {disfmarker} I 'd use the SRI recognizer since it 's already set up for {disfmarker} for Switchboard . And I 'd run some {disfmarker} some sort of tandem - style processing with , uh , my intermediate classifiers . phd a: Oh . So that 's why you were interested in getting your own features into the SRI files . grad f: Yeah . That 's why I {disfmarker} I was asking about that . phd a: Yeah . Yeah . grad f: Yeah . Um , and I guess that 's {disfmarker} that 's it . Any {disfmarker} any questions ? phd a: Sounds good . So you just have a few more weeks , huh ? grad f: Um , yeah . A few more . phd a: It 's about a month from now ? grad f: It 's a {disfmarker} it 's a month and {disfmarker} and a week . phd a: Yeah . grad f: Yeah . phd a: So , uh , you want to go next , Dave ? And we 'll do {disfmarker} grad e: Oh . OK , sure . So , um , last week I finally got results from the SRI system about this mean subtraction approach . And , um , we {disfmarker} we got an improvement , uh , in word error rate , training on the TI - digits data set and testing on Meeting Recorder digits of , um , {vocalsound} six percent to four point five percent , um , on the n on the far - mike data using PZM F , but , um , the near - mike performance worsened , um , from one point two percent to two point four percent . And , um , wh why would that be , um , {vocalsound} considering that we actually got an improvement in near - mike performance using HTK ? And so , uh , with some input from , uh , Andreas , I have a theory in two parts . Um , first of all HTK {disfmarker} sorry , SR - the SRI system is doing channel adaptation , and so HTK wasn't . Um , so this , um {disfmarker} This mean subtraction approach will do a kind of channel {pause} normalization and so that might have given the HTK use of it a boost that wouldn't have been applied in the SRI case . And also , um , the {disfmarker} Andreas pointed out the SRI system is using more parameters . It 's got finer - grained acoustic models . So those finer - grained acoustic models could be more sensitive to the artifacts {pause} in the re - synthesized audio . Um . And me and Barry were listening to the re - synthesized audio and sometimes it seems like you get of a bit of an echo of speech in the background . And so that seems like it could be difficult for training , cuz you could have {pause} different phones {pause} lined up with a different foreground phone , {vocalsound} um , {vocalsound} depending on {pause} the timing of the echo . So , um , I 'm gonna try training on a larger data set , and then , eh , the system will have seen more examples o of these artifacts and hopefully will be more robust to them . So I 'm planning to use the Macrophone set of , um , read speech , and , um {disfmarker} Hmm . professor b: I had another thought just now , which is , uh , remember we were talking before about {disfmarker} we were talking in our meeting about , uh , this stuff that {disfmarker} some of the other stuff that Avendano did , where they were , um , getting rid of low - energy {pause} sections ? Um , uh , if you {disfmarker} if you did a high - pass filtering , as Hirsch did in {pause} late eighties to reduce some of the effects of reverberation , uh , uh , Avendano and Hermansky were arguing that , uh , perhaps one of the reasons for that working was ma may not have even been the filtering so much but the fact that when you filter a {disfmarker} an all - positive power spectrum you get some negative values , and you gotta figure out what to do with them if you 're gonna continue treating this as a power spectrum . So , what {disfmarker} what Hirsch did was , uh , set them to zero {disfmarker} set the negative values to zero . So if you imagine a {disfmarker} a waveform that 's all positive , which is the time trajectory of energy , um , and , uh , shifting it downwards , and then getting rid of the negative parts , that 's essentially throwing away the low - energy things . And it 's the low - energy parts of the speech where the reverberation is most audible . You know , you have the reverberation from higher - energy things showing up in {disfmarker} So in this case you have some artificially imposed {pause} reverberation - like thing . I mean , you 're getting rid of some of the other effects of reverberation , but because you have these non - causal windows , you 're getting these funny things coming in , uh , at n And , um , what if you did {disfmarker} ? I mean , there 's nothing to say that the {disfmarker} the processing for this re - synthesis has to be restricted to trying to get it back to the original , according to some equation . I mean , you also could , uh , just try to make it nicer . grad e: Uh - huh . professor b: And one of the things you could do is , you could do some sort of VAD - like thing grad e: Mm - hmm . professor b: and you actually could take very low - energy sections and set them to some {disfmarker} some , uh , very low or {disfmarker} or near zero {pause} value . I mean , uh , I 'm just saying if in fact it turns out that {disfmarker} that these echoes that you 're hearing are , uh {disfmarker} grad e: Uh - huh . professor b: or pre - echoes , whichever they are {disfmarker} are {disfmarker} are , uh , part of what 's causing the problem , you actually could get rid of them . grad e: Uh - huh . professor b: Be pretty simple . I mean , you do it in a pretty conservative way grad e: OK . professor b: so that if you made a mistake you were more likely to {pause} keep in an echo than to throw out speech . grad e: Hmm . phd g: Um , what is the reverberation time {pause} like {pause} there ? grad e: In thi in this room ? Uh {disfmarker} phd g: On , uh , the {disfmarker} the one what {disfmarker} the s in the speech that you are {disfmarker} you are using like ? grad e: Y Yeah . I {disfmarker} I {disfmarker} I {disfmarker} I don't know . professor b: So , it 's this room . phd g: It 's , uh {disfmarker} professor b: It 's {disfmarker} it 's this room . phd g: Oh , this room ? professor b: So {disfmarker} phd g: OK . professor b: so it 's {disfmarker} these are just microphone {disfmarker} this micro close microphone and a distant microphone , he 's doing these different tests on . grad f: Oh . professor b: Uh , we should do a measurement in here . I g think we never have . I think it 's {disfmarker} I would guess , uh , point seven , point eight seconds f uh , R T grad f: Hmm ! professor b: something like that ? But it 's {disfmarker} you know , it 's this room . phd g: Mm - hmm . professor b: So . phd g: OK . Mm - hmm . professor b: Uh . But the other thing is , he 's putting in {disfmarker} w I was using the word " reverberation " in two ways . He 's also putting in , uh , a {disfmarker} he 's taking out some reverberation , but he 's putting in something , because he has {pause} averages over multiple windows stretching out to twelve seconds , which are then being subtracted from the speech . And since , you know , what you subtract , sometimes you 'll be {disfmarker} you 'll be subtracting from some larger number and sometimes you won't . And {disfmarker} phd g: Mm - hmm . Mm - hmm . professor b: So you can end up with some components in it that are affected by things that are seconds away . Uh , and if it 's a low {pause} energy compo portion , you might actually hear some {pause} funny things . phd g: Yeah . grad e: O o one thing , um , I noticed is that , um , the mean subtraction seems to make the PZM signals louder after they 've been re - synthesized . So I was wondering , is it possible that one reason it helped with the Aurora baseline system is {pause} just as a kind of gain control ? Cuz some of the PZM signals sound pretty quiet if you don't amplify them . phd c: Mm - hmm . I don't see why {disfmarker} why your signal is louder after processing , because yo grad e: Yeah . I don't know why - y , uh , either . phd c: Yeah . professor b: I don't think just multiplying the signal by two would have any effect . phd c: Mm - hmm . grad e: Oh , OK . professor b: Yeah . I mean , I think if you really have louder signals , what you mean is that you have {pause} better signal - to - noise ratio . phd c: Well , well {disfmarker} professor b: So if what you 're doing is improving the signal - to - noise ratio , then it would be better . phd c: Mm - hmm . professor b: But just it being bigger if {disfmarker} with the same signal - to - noise ratio {disfmarker} grad e: It w i i it wouldn't affect things . professor b: No . phd c: Yeah . grad e: OK . phd c: Well , the system is {disfmarker} use {pause} the absolute energy , so it 's a little bit dependent on {disfmarker} on the {pause} signal level . But , not so much , I guess . professor b: Well , yeah . But it 's trained and tested on the same thing . phd c: Mmm . professor b: So if the {disfmarker} if the {disfmarker} if you change {vocalsound} in both training and test , the absolute level by a factor of two , it will n have no effect . phd c: Mm - hmm . Yeah . phd a: Did you add {pause} this data to the training set , for the Aurora ? Or you just tested on this ? grad e: Uh {disfmarker} Um . Did I w what ? phd a: Well , Morgan was just saying that , uh , as long as you do it in both training and testing , it shouldn't have any effect . grad e: Sorry ? Yeah . phd a: But I {disfmarker} I was {pause} sort of under the impression that you just tested with this data . grad e: I {disfmarker} I b phd a: You didn't {pause} train it also . grad e: I {disfmarker} Right . I trained on clean TI - digits . I {disfmarker} I did the mean subtraction on clean TI - digits . But I didn't {disfmarker} I 'm not sure if it made the clean ti TI - digits any louder . professor b: Oh , I see . grad e: I only remember noticing it made the , um , PZM signal louder . professor b: OK . Well , I don't understand then . Yeah . grad e: Huh . I don't know . If it 's {disfmarker} if it 's {disfmarker} like , if it 's trying to find a {disfmarker} a reverberation filter , it could be that this reverberation filter is making things quieter . And then if you take it out {disfmarker} that taking it out makes things louder . I mean . professor b: Uh , no . I mean , {vocalsound} uh , there 's {disfmarker} there 's nothing inherent about removing {disfmarker} if you 're really removing , grad e: Nuh - huh . professor b: uh , r uh , then I don't {pause} see how that would make it louder . grad e: The mean . OK . Yeah , I see . professor b: So it might be just some {disfmarker} grad e: Yeah . OK . So I should maybe listen to that stuff again . professor b: Yeah . It might just be some artifact of the processing that {disfmarker} that , uh , if you 're {disfmarker} Uh , yeah . I don't know . grad e: Oh . OK . phd a: I wonder if there could be something like , uh {disfmarker} for s for the PZM data , phd c: Eh phd a: uh , you know , if occasionally , uh , somebody hits the table or something , you could get a spike . Uh . I 'm just wondering if there 's something about the , um {disfmarker} you know , doing the mean normalization where , uh , it {disfmarker} it could cause {pause} you to have better signal - to - noise ratio . Um . professor b: Well , you know , there is this . Wait a minute . It {disfmarker} it {disfmarker} i maybe {disfmarker} i If , um {disfmarker} Subtracting the {disfmarker} the mean log spectrum is {disfmarker} is {disfmarker} is like dividing by the spectrum . So , depending what you divide by , if your {disfmarker} if s your estimate is off and sometimes you 're {disfmarker} you 're {disfmarker} you 're getting a small number , you could make it bigger . phd a: Mm - hmm . grad e: Mm - hmm . professor b: So , it 's {disfmarker} it 's just a {disfmarker} a question of {disfmarker} there 's {disfmarker} It {disfmarker} it could be that there 's some normalization that 's missing , or something to make it {disfmarker} grad e: Mm - hmm . professor b: Uh , y you 'd think it shouldn't be larger , but maybe in practice it is . That 's something to think about . grad e: Hmm . professor b: I don't know . phd c: I had a question about the system {disfmarker} the SRI system . So , {vocalsound} you trained it on TI - digits ? But except this , it 's exactly the same system as the one that was tested before and that was trained on {pause} Macrophone . Right ? So on TI - digits it gives you one point two percent error rate and on Macrophone it 's still O point eight . Uh , but is it {pause} exactly the same system ? grad e: Uh . I think so . phd c: Hmm . grad e: If you 're talking about the Macrophone results that Andreas had about , um , a week and a half ago , I think it 's the same system . phd c: Mm - hmm . So you use VTL - uh , vocal tract length normalization and , um , like MLLR transformations also , grad e: Mm - hmm . phd c: and {disfmarker} professor b: I 'm sorry , was his point eight percent , er , a {disfmarker} a result on testing on Macrophone or {disfmarker} or training ? phd c: all that stuff . grad e: That 's {disfmarker} phd c: It was {pause} training on Macrophone and testing {disfmarker} yeah , on {disfmarker} on meeting digits . professor b: Oh . So that was done already . So we were {disfmarker} Uh , and it 's point eight ? OK . phd c: Mm - hmm . professor b: OK . phd c: Yeah . I {disfmarker} I 've just been text {comment} testing the new {pause} Aurora front - end with {disfmarker} well , Aurora system actually {disfmarker} so front - end and HTK , um , acoustic models on the meeting digits and it 's a little bit better than the previous system . We have {disfmarker} I have two point seven percent error rate . And before with the system that was proposed , it 's what ? It was three point nine . So . professor b: Oh , that 's a lot better . phd c: We are getting better . professor b: So , what {disfmarker} w ? phd c: And {disfmarker} phd g: With the {disfmarker} with the HTK back - end ? What we have for Aurora ? phd c: Yeah . Two point seven . phd g: I know in the meeting , like {disfmarker} phd c: On the meeting we have two point seven . phd g: Right . Oh . grad f: That 's with the new IIR filters ? phd c: Uh . Yeah , yeah . So , yeah , grad f: OK . phd c: we have {pause} the new LDA filters , and {disfmarker} I think , maybe {disfmarker} I didn't look , but one thing that makes a difference is this DC offset compensation . Uh , eh {disfmarker} Do y did you have a look at {disfmarker} at the meet uh , meeting digits , if they have a DC component , or {disfmarker} ? grad e: I {disfmarker} I didn't . No . phd c: Oh . professor b: Hmm . phd g: No . The DC component could be negligible . I mean , if you are {pause} recording it through a mike . I mean , any {disfmarker} all of the mikes have the DC removal {disfmarker} some capacitor sitting right in {pause} that bias it . professor b: Yeah . But this {disfmarker} uh , uh , uh , no . Because , uh , there 's a sample and hold in the A - toD. And these period these typically do have a DC offset . phd g: Oh , OK . professor b: And {disfmarker} and they can be surprisingly large . It depends on the electronics . phd g: Oh , so it is the digital {disfmarker} OK . It 's the A - toD that introduces the DC in . professor b: Yeah . The microphone isn't gonna pass any DC . phd g: Yeah . Yeah . Yeah . professor b: But {disfmarker} but , phd g: OK . professor b: typi you know , unless {disfmarker} Actually , there are {pause} instrumentation mikes that {disfmarker} that do pass {disfmarker} go down to DC . But {disfmarker} but , phd g: Mm - hmm . professor b: uh , no , it 's the electronics . And they {disfmarker} and {disfmarker} phd g: Mm - hmm . professor b: then there 's amplification afterwards . And you can get , I think it was {disfmarker} I think it was in the {pause} Wall Street Journal data that {disfmarker} that {disfmarker} I can't remember , one of the DARPA things . There was this big DC - DC offset phd a: Mm - hmm . professor b: we didn't {disfmarker} we didn't know about for a while , while we were {pause} messing with it . And we were getting these terrible results . And then we were talking to somebody and they said , " Oh , yeah . Didn't you know ? Everybody knows that . There 's all this DC offset in th " So , yes . You can have DC offset in the data . phd g: Oh , OK . professor b: Yeah . phd g: OK . phd a: So was that {disfmarker} was that everything , Dave ? grad e: Oh . And I also , um , did some experiments {pause} about normalizing the phase . Um . So I c I came up with a web page that people can take a look at . And , um , the interesting thing that I tried was , um , Adam and Morgan had this idea , um , since my original attempts to , um , take the mean of the phase spectra over time and normalize using that , by subtracting that off , didn't work . Um , so , well , that we thought that might be due to , um , problems with , um , the arithmetic of phases . They {disfmarker} they add in this modulo two pi way and , um , there 's reason to believe that that approach of taking the mean of the phase spectrum wasn't really {pause} mathematically correct . So , {vocalsound} what I did instead is I {vocalsound} took the mean of the FFT spectrum without taking the log or anything , and then I took the phase of that , and I subtracted that phase {pause} off to normalize . But that , um , didn't work either . professor b: See , we have a different interpretation of this . He says it doesn't work . I said , I think it works magnificently , but just not for the task we intended . Uh , it gets rid of the speech . phd a: What does it leave ? grad f: Uh , gets rid of the speech . professor b: Uh , it leaves {disfmarker} you know , it leaves the junk . I mean , I {disfmarker} I think it 's {disfmarker} it 's tremendous . grad f: Oh , wow . professor b: You see , all he has to do is go back and reverse what he did before , and he 's really got something . phd a: Well , could you take what was left over and then subtract that ? professor b: Ex - exactly . Yeah , you got it . grad f: Yeah . phd g: Yeah . professor b: So , it 's {disfmarker} it 's a general rule . phd g: Oh , it 's {disfmarker} professor b: Just listen very carefully to what I say and do the opposite . Including what I just said . grad e: And , yeah , that 's everything . phd a: All set ? Do you want to go , Stephane ? phd c: Um . Yeah . Maybe , concerning these d still , these meeting digits . I 'm more interested in trying to figure out what 's still the difference between the SRI system and the Aurora system . And {disfmarker} Um . Yeah . So , I think I will maybe train , like , gender - dependent models , because {pause} this is also one big difference between {pause} the two systems . Um , the other differences were {pause} the fact that maybe the acoustic models of the SRI are more {disfmarker} SRI system are more complex . But , uh , Chuck , you did some experiments with this and phd a: It didn't seem to help in the HTK system . phd c: it was hard t to {disfmarker} to have some exper some improvement with this . Um . professor b: Well , it sounds like they also have {disfmarker} he {disfmarker} he 's saying they have all these , uh , uh , different kinds of adaptation . phd c: Mm - hmm . professor b: You know , they have channel adaptation . They have speaker adaptation . phd c: Yeah . Right . phd a: Well , there 's also the normalization . professor b: Yeah . Yeah . phd c: Yeah . grad f: Yeah . phd a: Like they do , um {disfmarker} I 'm not sure how they would do it when they 're working with the digits , phd c: The vocal tr phd a: but , like , in the Switchboard data , there 's , um {disfmarker} conversation - side normalization for the {pause} non - C - zero components , phd c: Yeah . Yeah . This is another difference . Their normalization works like on {disfmarker} on the utterance levels . phd a: Mm - hmm . phd c: But we have to do it {disfmarker} We have a system that does it on - line . phd a: Right . phd c: So , it might be {disfmarker} it might be better with {disfmarker} it might be worse if the {pause} channel is constant , phd a: Yeah . phd c: or {disfmarker} Nnn . phd g: And the acoustic models are like - k triphone models or {disfmarker} or is it the whole word ? phd c: SRI {disfmarker} it 's {disfmarker} it 's tr grad f: SRI . phd g: Yeah . phd c: Yeah . I guess it 's triphones . phd g: It 's triphone . professor b: I think it 's probably more than that . phd c: Huh . professor b: I mean , so they {disfmarker} they have {disfmarker} I {disfmarker} I thin think they use these , uh , uh , genone things . So there 's {disfmarker} there 's these kind of , uh , uh , pooled models and {disfmarker} and they can go out to all sorts of dependencies . phd g: Oh . It 's like the tied state . professor b: So . phd a: Mm - hmm . professor b: They have tied states and I think {disfmarker} I {disfmarker} I {disfmarker} I don't real I 'm talk I 'm just guessing here . But I think {disfmarker} I think they {disfmarker} they don't just have triphones . phd g: OK . professor b: I think they have a range of {disfmarker} of , uh , dependencies . phd c: Mm - hmm . phd g: Mm - hmm . phd c: Mm - hmm . grad f: Hmm . phd c: And {disfmarker} Yeah . Well . Um . Well , the first thing I {disfmarker} that I want to do is just maybe these gender things . Uh . And maybe see with {pause} Andreas if {disfmarker} Well , I {disfmarker} I don't know {pause} how much it helps , what 's the model . phd a: So {disfmarker} so the n stuff on the numbers you got , the two point seven , is that using the same training data that the SRI system used and got one point two ? phd c: That 's right . So it 's the clean {pause} TI - digits training set . phd a: So exact same training data ? phd c: Right . phd a: OK . phd c: Mm - hmm . I guess you used the clean training set . grad e: Right . phd c: Mm - hmm . grad e: For {disfmarker} with the SRI system {disfmarker} phd c: Well . grad e: You know , the {disfmarker} the Aurora baseline is set up with these , um {disfmarker} {vocalsound} this version of the clean training set that 's been filtered with this G - seven - one - two filter , and , um , to train the SRI system on digits S - Andreas used the original TI - digits , um , under U doctor - speech data TI - digits , which don't have this filter . But I don't think there 's any other difference . phd c: Mm - hmm . Mm - hmm . Yeah . professor b: So is that {disfmarker} ? Uh , are {disfmarker} are these results comparable ? So you {disfmarker} you were getting with the , uh , Aurora baseline something like two point four percent {pause} on clean TI - digits , when , uh , training the SRI system with clean TR digits {disfmarker} {comment} TI - digits . Right ? And {disfmarker} grad e: Um . Uh - huh . professor b: Yeah . And , so , is your two point seven comparable , where you 're , uh , uh , using , uh , the submitted system ? phd c: Yeah . I think so . professor b: OK . phd c: Yeah . professor b: So it 's {pause} about the same , phd c: Mm - hmm . professor b: maybe a little worse . grad e: W w it was one {disfmarker} one point two phd c: Ye grad e: with the SRI system , professor b: I 'm sorry . phd c: Yeah . grad e: I {disfmarker} phd c: The complete SRI system is one point two . professor b: You {disfmarker} you were HTK . phd c: Yeah . professor b: Right ? OK . That 's right . So {disfmarker} phd c: Mm - hmm . professor b: OK , so {pause} the comparable number then , uh {pause} for what you were talking about then , since it was HTK , would be the {pause} um , two point f phd c: It was four point something . Right ? The HTK system with , uh , b grad e: D d professor b: Oh , right , right , right , right . phd c: MFCC features {disfmarker} grad e: Do you mean the b ? The baseline Aurora - two system , trained on TI - digits , tested on Meeting Recorder near , I think we saw in it today , and it was about six point six percent . professor b: Right . Right , right , right . phd c: Oh . professor b: OK . Alright . So {disfmarker} He 's doing some {pause} different things . phd c: So {disfmarker} Yeah . The only difference is the features , right now , between this and {disfmarker} professor b: Yes . OK , good . So they are helping . phd c: Mm - hmm . professor b: That 's good to hear . Yeah . phd c: They are helping . Yeah . Um . Yeah . And another thing I {disfmarker} I maybe would like to do is to {pause} just test the SRI system that 's trained on Macrophone {disfmarker} test it on , uh , the noisy TI - digits , professor b: Yeah . phd c: cuz I 'm still wondering {pause} where this {pause} improvement comes from . When you train on Macrophone , it seems better on meeting digits . But I wonder if it 's just because maybe {pause} Macrophone is acoustically closer to the meeting digits than {disfmarker} than TI - digit is , which is {disfmarker} TI - digits are very {pause} clean recorded digits professor b: Mm - hmm . phd c: and {disfmarker} phd a: You know , it would also be interesting to see , uh {disfmarker} to do the regular Aurora test , phd c: Uh , f s phd a: um , but use the SRI system instead of HTK . phd c: That 's {disfmarker} Yeah . That 's what {pause} I wanted , just , uh {disfmarker} Yeah . So , just using the SRI system , test it on {disfmarker} and test it on {pause} Aurora TI - digits . Right . phd a: Why not the full Aurora , uh , test ? phd c: Um . Yeah . There is this problem of multilinguality yet . phd a: Mm - hmm . phd c: So we don't {disfmarker} professor b: You 'd have to train the SRI system with {disfmarker} with all the different languages . phd c: i i phd a: Right . phd c: We would have to train on {disfmarker} phd a: Yeah . That 's what I mean . phd c: Yeah . phd a: So , like , comple professor b: It 'd be a {pause} lot of work . That 's the only thing . phd c: Yeah . phd a: Mmm . phd c: It 's {disfmarker} phd a: Well , I mean , phd c: Mmm . phd a: uh , uh , I guess the work would be into getting the {disfmarker} the files in the right formats , or something . Right ? I mean {disfmarker} phd c: Mm - hmm . phd a: Because when you train up the Aurora system , you 're , uh {disfmarker} you 're also training on all the data . phd c: That 's right . phd a: I mean , it 's {disfmarker} phd c: Yeah . Yeah . I see . Oh , so , OK . Right . I see what you mean . professor b: That 's true , but I think that also when we 've had these meetings week after week , oftentimes people have not done the full arrange of things phd a: Mm - hmm . professor b: because {disfmarker} on {disfmarker} on whatever it is they 're trying , because it 's a lot of work , even just with the HTK . phd a: Mm - hmm . professor b: So , it 's {disfmarker} it 's a good idea , but it seems like {pause} it makes sense to do some pruning phd a: Mm - hmm . professor b: first with a {disfmarker} a test or two that makes sense for you , phd a: Yeah . professor b: and then {pause} take the likely candidates and go further . phd a: Yeah . phd c: Mm - hmm . Yeah . But , just testing on TI - digits would already give us some information {pause} about what 's going on . And {disfmarker} mm - hmm . Uh , yeah . OK . Uh , the next thing is this {disfmarker} this VAD problem that , um , um {disfmarker} So , I 'm just talking about the {disfmarker} the curves that I {disfmarker} I sent {disfmarker} {vocalsound} I sent you {disfmarker} so , whi that shows that {vocalsound} when the SNR decrease , {vocalsound} uh , the current {pause} VAD approach doesn't drop much frames {pause} for some particular noises , uh , which might be then noises that are closer to speech , uh , acoustically . professor b: I i Just to clarify something for me . I They were supp Supposedly , in the next evaluation , they 're going to be supplying us with boundaries . phd c: Mm - hmm . professor b: So does any of this matter ? I mean , other than our interest in it . Uh {disfmarker} phd c: Uh {disfmarker} Well . First of all , the boundaries might be , uh {disfmarker} like we would have t two hundred milliseconds or {disfmarker} before and after speech . Uh . So removing more than that might still make {pause} a difference {pause} in the results . professor b: Do we {disfmarker} ? I mean , is there some reason that we think that 's the case ? phd c: And {disfmarker} No . Because we don't {disfmarker} didn't looked {pause} that much at that . professor b: Yeah . phd c: But , {vocalsound} still , I think it 's an interesting problem . professor b: Oh , yeah . phd c: And {disfmarker} Um . Yeah . professor b: But maybe we 'll get some insight on that when {disfmarker} when , uh , the gang gets back from Crete . Because {pause} there 's lots of interesting problems , of course . phd c: Mm - hmm . professor b: And then the thing is if {disfmarker} if they really are going to have some means of giving us {pause} fairly tight , uh , boundaries , then that won't be so much the issue . phd c: Yeah , yeah . Mm - hmm . Mm - hmm . professor b: Um But {vocalsound} I don't know . phd g: Because w we were wondering whether that {pause} VAD is going to be , like , a realistic one or is it going to be some manual segmentation . And then , like , if {disfmarker} if that VAD is going to be a realistic one , then we can actually use their markers to shift the point around , I mean , the way we want professor b: Mm - hmm . phd g: to find a {disfmarker} I mean , rather than keeping the twenty frames , we can actually move the marker to a point which we find more {pause} suitable for us . professor b: Right . phd g: But if that is going to be something like a manual , uh , segmenter , then we can't {pause} use that information anymore , phd c: Mm - hmm . phd g: because that 's not going to be the one that is used in the final evaluation . professor b: Right . phd g: So . We don't know what is the type of {pause} {vocalsound} {pause} VAD which they 're going to provide . professor b: Yeah . phd c: Yeah . And actually there 's {disfmarker} Yeah . There 's an {disfmarker} uh , I think it 's still for {disfmarker} even for the evaluation , uh , it might still be interesting to {vocalsound} work on this because {pause} the boundaries apparently that they would provide is just , {vocalsound} um , starting of speech and end of speech {pause} uh , at the utterance level . And {disfmarker} Um . phd g: With some {disfmarker} some gap . phd c: So {disfmarker} phd g: I mean , with some pauses in the center , provided they meet that {disfmarker} whatever the hang - over time which they are talking . phd c: Yeah . But when you have like , uh , five or six frames , both {disfmarker} phd g: Yeah . Then the they will just fill {disfmarker} fill it up . phd c: it {disfmarker} it {disfmarker} with {disfmarker} phd g: I mean , th {disfmarker} Yeah . phd c: Yeah . professor b: So if you could get at some of that , uh {disfmarker} phd c: So {disfmarker} professor b: although that 'd be hard . phd c: Yeah . It might be useful for , like , noise estimation , and a lot of other {pause} things that we want to work on . professor b: But {disfmarker} but {disfmarker} Yeah . phd g: Yeah . professor b: Right . OK . phd c: But {disfmarker} Mmm . Yeah . So I did {disfmarker} I just {pause} started to test {pause} putting together two VAD which was {disfmarker} was not much work actually . Um , I im re - implemented a VAD that 's very close to the , {vocalsound} um , energy - based VAD {vocalsound} that , uh , the other Aurora guys use . Um . So , which is just putting a threshold on {pause} the noise energy , professor b: Mm - hmm . phd c: and , detect detecting the first {pause} group of four frames {pause} that have a energy that 's above this threshold , and , uh , from this point , uh , tagging the frames there as speech . So it removes {vocalsound} the first silent portion {disfmarker} portion of each utterance . And it really removes it , um , still o on the noises where {pause} our MLP VAD doesn't {pause} work a lot . professor b: Mmm . phd c: Uh , professor b: Cuz I would have thought that having some kind of spectral {pause} information , phd c: and {disfmarker} professor b: uh {disfmarker} uh , you know , in the old days people would use energy and zero crossings , for instance {disfmarker} uh , would give you some {pause} better performance . Right ? Cuz you might have low - energy fricatives or {disfmarker} or , uh {pause} stop consonants , or something like that . phd c: Mm - hmm . professor b: Uh . phd c: Yeah . So , your point is {disfmarker} will be to u use whatever {disfmarker} professor b: Oh , that if you d if you use purely energy and don't look at anything spectral , then you don't have a good way of distinguishing between low - energy speech components and {pause} nonspeech . And , um , phd c: Mm - hmm . professor b: just as a gross generalization , most nonsp many nonspeech noises have a low - pass kind of characteristic , some sort of slope . And {disfmarker} and most , um , low - energy speech components that are unvoiced have a {disfmarker} a high - pass kind of characteristic {disfmarker} phd c: Mm - hmm . professor b: an upward slope . So having some kind of a {disfmarker} phd c: Yeah . professor b: uh , you know , at the beginning of a {disfmarker} of a {disfmarker} of an S sound for instance , just starting in , it might be pretty low - energy , phd c: Mm - hmm . professor b: but it will tend to have this high - frequency component . Whereas , {vocalsound} a {disfmarker} a lot of rumble , and background noises , and so forth will be predominantly low - frequency . Uh , you know , by itself it 's not enough to tell you , but it plus energy is sort of {disfmarker} phd c: Yeah . professor b: it plus energy plus timing information is sort of {disfmarker} phd c: Mm - hmm . professor b: I mean , if you look up in Rabiner and Schafer from like twenty - five years ago or something , that 's sort of {pause} what they were using then . phd c: Mm - hmm . professor b: So it 's {disfmarker} it 's not a {disfmarker} phd c: Mm - hmm . grad f: Hmm . phd c: So , yeah . It {disfmarker} it might be that what I did is {disfmarker} so , removes like {vocalsound} low , um , {vocalsound} uh {disfmarker} low - energy , uh , speech frames . Because {pause} the way I do it is I just {disfmarker} I just combine the two decisions {disfmarker} so , the one from the MLP and the one from the energy - based {disfmarker} with the {disfmarker} with the and {pause} operator . So , I only {pause} keep the frames where the two agree {pause} that it 's speech . So if the energy - based dropped {disfmarker} dropped low - energy speech , mmm , they {disfmarker} they are {disfmarker} they are lost . Mmm . professor b: Mm - hmm . phd c: But s still , the way it 's done right now it {disfmarker} it helps on {disfmarker} on the noises where {disfmarker} it seems to help on the noises where {vocalsound} our VAD was not very {pause} good . professor b: Well , I guess {disfmarker} I mean , one could imagine combining them in different ways . But {disfmarker} but , I guess what you 're saying is that the {disfmarker} the MLP - based one has the spectral information . So . phd c: Yeah . But {disfmarker} Yeah . But the way it 's combined wi is maybe done {disfmarker} Well , yeah . professor b: Well , you can imagine {disfmarker} phd c: The way I use a an a " AND " operator is {disfmarker} So , it {disfmarker} I , uh {disfmarker} professor b: Is {disfmarker} ? phd c: The frames that are dropped by the energy - based system are {disfmarker} are , uh , dropped , even if the , um , MLP decides to keep them . professor b: Right . Right . And that might not be optimal , phd c: But , yeah . professor b: but {disfmarker} phd c: Mm - hmm . phd a: No professor b: but {disfmarker} I mean , I guess in principle what you 'd want to do is have a {disfmarker} {vocalsound} uh , a probability estimated by each one and {disfmarker} and put them together . phd c: Yeah . Mmm . M Yeah . phd a: Something that {disfmarker} that I 've used in the past is , um {disfmarker} when just looking at the energy , is to look at the derivative . And you {pause} make your decision when the derivative is increasing for {pause} so many frames . Then you say that 's beginning of speech . phd c: Uh - huh . phd a: But , I 'm {disfmarker} I 'm trying to remember if that requires that you keep some amount of speech in a buffer . I guess it depends on how you do it . But {pause} I mean , that 's {disfmarker} that 's been a useful thing . professor b: Yeah . phd c: Mm - hmm . grad f: Mm - hmm . phd g: Yeah . Well , every everywhere has a delay associated with it . I mean , you still have to k always keep a buffer , phd a: Mm - hmm . phd g: then only make a decision because {pause} you still need to smooth the {pause} decision further . phd a: Right . Right . phd g: So that 's always there . phd a: Yeah . OK . phd c: Well , actually if I don't {disfmarker} maybe don't want to work too much of {disfmarker} on it right now . I just wanted to {disfmarker} to see if it 's {disfmarker} {vocalsound} what I observed was the re was caused by this {disfmarker} this VAD problem . professor b: Mm - hmm . phd c: And it seems to be the case . Um . Uh , the second thing is the {disfmarker} this spectral subtraction . Um . Um , which I 've just started yesterday to launch a bunch of , uh , {nonvocalsound} twenty - five experiments , uh , with different , uh , values for the parameters that are used . So , it 's the Makhoul - type spectral subtraction which use {pause} an over - estimation factor . So , we substr I subtract more , {vocalsound} {vocalsound} um , {nonvocalsound} {vocalsound} noise than the noise spectra that {pause} is estimated {pause} on the noise portion of the s uh , the utterances . So I tried several , uh , over - estimation factors . And after subtraction , I also add {pause} a constant noise , and I also try different , uh , {vocalsound} noise , uh , values and we 'll see what happen . professor b: Hmm . OK . phd c: Mm - hmm . Mm - hmm . But st still when we look at the , um {disfmarker} Well , it depends on the parameters that you use , but for moderate over - estimation factors and moderate noise level that you add , you st have a lot of musical noise . Um . On the other hand , when you {pause} subtract more and when you add more noise , you get rid of this musical noise but {pause} maybe you distort a lot of speech . So . Well . Mmm . Well , it {disfmarker} until now , it doesn't seem to help . But We 'll see . So the next thing , maybe I {disfmarker} what I will {pause} try to {disfmarker} to do is just {pause} to try to smooth mmm , {vocalsound} the , um {disfmarker} to smooth the d the result of the subtraction , to get rid of the musical noise , using some kind of filter , or {disfmarker} phd g: Can smooth the SNR estimate , also . phd c: Yeah . Right . Mmm . phd g: Your filter is a function of SNR . Hmm ? phd c: Yeah . So , to get something that 's {disfmarker} would be closer to {pause} what you tried to do with Wiener filtering . phd g: Yeah . phd c: And {disfmarker} Mm - hmm . Yeah . phd g: Actually , it 's , uh {disfmarker} Uh . I don't know , it 's {disfmarker} go ahead . phd c: It {disfmarker} phd g: And it 's {disfmarker} phd c: Maybe you can {disfmarker} phd g: go ahead . phd c: I think it 's {disfmarker} That 's it for me . phd g: OK . So , uh {disfmarker} u th I 've been playing with this Wiener filter , like . And there are {disfmarker} there were some bugs in the program , so I was p initially trying to clear them up . Because one of the bug was {disfmarker} I was assuming that always the VAD {disfmarker} uh , the initial frames were silence . It always started in the silence state , but it wasn't for some utterances . So the {disfmarker} it wasn't estimating the noise initially , and then it never estimated , because I assumed that it was always silence . phd c: Mm - hmm . So this is on SpeechDat - Car Italian ? phd g: Yeah . phd c: So , in some cases s there are also {disfmarker} phd g: SpeechDat - Car Italian . Yeah . There 're a few cases , actually , which I found later , that there are . phd c: o Uh - huh . phd g: So that was one of the {pause} bugs that was there in estimating the noise . And , uh , so once it was cleared , uh , I ran a few experiments with {pause} different ways of smoothing the estimated clean speech and how t estimated the noise and , eh , smoothing the SNR also . And so the {disfmarker} the trend seems to be like , {vocalsound} uh , smoothing the {pause} current estimate of the clean speech for deriving the SNR , which is like {pause} deriving the Wiener filter , seems to be helping . Then updating it quite fast using a very small time constant . So we 'll have , like , a few results where the {disfmarker} estimating the {disfmarker} the {disfmarker} More smoothing is helping . But still it 's like {disfmarker} it 's still comparable to the baseline . I haven't got anything beyond the baseline . But that 's , like , not using any Wiener filter . And , uh , so I 'm {disfmarker} I 'm trying a few more experiments with different time constants for smoothing the noise spectrum , and smoothing the clean speech , and smoothing SNR . So there are three time constants that I have . So , I 'm just playing around . So , one is fixed in the line , like {pause} Smoothing the clean speech is {disfmarker} is helping , so I 'm not going to change it that much . But , the way I 'm estimating the noise and the way I 'm estimating the SNR , I 'm just trying {disfmarker} trying a little bit . So , that h And the other thing is , like , putting a floor on the , uh , SNR , because that {disfmarker} if some {disfmarker} In some cases the clean speech is , like {disfmarker} when it 's estimated , it goes to very low values , so the SNR is , like , very low . And so that actually creates a lot of variance in the low - energy region of the speech . So , I 'm thinking of , like , putting a floor also for the SNR so that it doesn't {pause} vary a lot in the low - energy regions . And , uh . So . The results are , like {disfmarker} So far I 've been testing only with the {pause} baseline , which is {disfmarker} which doesn't have any LDA filtering and on - line normalization . I just want to separate the {disfmarker} the contributions out . So it 's just VAD , plus the Wiener filter , plus the baseline system , which is , uh , just the spectral {disfmarker} I mean , the mel sp mel , uh , frequency coefficients . Um . And the other thing that I tried was {disfmarker} but I just {vocalsound} took of those , uh , {pause} {vocalsound} Carlos filters , which Hynek had , to see whether it really h helps or not . I mean , it was just a {disfmarker} a run to see whether it really degrades or it helps . And it 's {disfmarker} it seems to be like it 's not {vocalsound} hurting a lot by just blindly picking up one filter which is nothing but a {pause} four hertz {disfmarker} a band - pass m m filter on the cubic root of the power spectrum . So , that was the filter that Hy - uh , Carlos had . And so {disfmarker} Yeah . Just {disfmarker} just to see whether it really {disfmarker} it 's {disfmarker} it 's {disfmarker} is it worth trying or not . So , it doesn't seems to be degrading a lot on that . So there must be something that I can {disfmarker} that can be done with that type of noise compensation also , which {disfmarker} {vocalsound} I guess I would ask Carlos about that . I mean , how {disfmarker} how he derived those filters and {disfmarker} and where d if he has any filters which are derived on OGI stories , added with some type of noise which {disfmarker} what we are using currently , or something like that . So maybe I 'll {disfmarker} professor b: This is cubic root of power spectra ? phd g: Yeah . Cubic root of power spectrum . professor b: So , if you have this band - pass filter , you probably get n you get negative values . Right ? phd g: Yeah . And I 'm , like , floating it to z zeros right now . professor b: OK . phd g: So it has , like {disfmarker} the spectrogram has , like {disfmarker} Uh , it actually , uh , enhances the onset and offset of {disfmarker} I mean , the {disfmarker} the begin and the end of the speech . So it 's {disfmarker} there seems to be , like , deep valleys in the begin and the end of , like , high - energy regions , professor b: Mm - hmm . phd g: because the filter has , like , a sort of Mexican - hat type structure . professor b: Mm - hmm . phd g: So , those are the regions where there are , like {disfmarker} when I look at the spectrogram , there are those deep valleys on the begin and the end of the speech . But the rest of it seems to be , like , pretty nice . professor b: Mm - hmm . phd g: So . That 's {pause} something I observe using that filter . And {disfmarker} Yeah . There are a few {disfmarker} very {disfmarker} not a lot of {disfmarker} because the filter doesn't have a {disfmarker} really a deep negative portion , so that it 's not really creating a lot of negative values in the cubic root . So , I 'll {disfmarker} I 'll s may continue with that for some w I 'll {disfmarker} I 'll {disfmarker} Maybe I 'll ask Carlos a little more about how to play with those filters , and {disfmarker} but while {pause} making this Wiener filter better . So . Yeah . That {disfmarker} that 's it , Morgan . professor b: Uh , last week you were also talking about building up the subspace {pause} stuff ? phd g: Yeah . I {disfmarker} I {disfmarker} I would actually m m didn't get enough time to work on the subspace last week . It was mostly about {pause} finding those bugs and professor b: OK . phd g: th you know , things , and I didn't work much on that . phd a: How about you , Carmen ? phd d: Well , I am still working with , eh , VTS . And , one of the things that last week , eh , say here is that maybe the problem was with the diff because the signal have different level of energy . professor b: Hmm ? phd d: And , maybe , talking with Stephane and with Sunil , we decide that maybe it was interesting to {disfmarker} to apply on - line normalization before applying VTS . But then {vocalsound} we decided that that 's {disfmarker} it doesn't work absolutely , because we modified also the noise . And {disfmarker} Well , thinking about that , we {disfmarker} we then {disfmarker} we decide that maybe is a good idea . We don't know . I don't hav I don't {disfmarker} this is {disfmarker} I didn't {pause} do the experiment yet {disfmarker} to apply VTS in cepstral domain . professor b: The other thing {pause} is {disfmarker} So {disfmarker} so , in {disfmarker} i i and {disfmarker} Not {disfmarker} and C - zero would be a different {disfmarker} So you could do a different normalization for C - zero than for other things anyway . I mean , the other thing I was gonna suggest is that you could have {pause} two kinds of normalization with {disfmarker} with , uh , different time constants . So , uh , you could do some normalization {vocalsound} s uh , before the VTS , and then do some other normalization after . I don't know . But {disfmarker} but C - zero certainly acts differently than the others do , phd d: Uh . professor b: so that 's {disfmarker} phd c: Mm - hmm . phd d: Well , we s decide to m to {disfmarker} to obtain the new expression if we work in the cepstral domain . And {disfmarker} Well . I am working in that now , professor b: Uh - huh . phd d: but {vocalsound} I 'm not sure if that will be usefu useful . I don't know . It 's k it 's k It 's quite a lot {disfmarker} It 's a lot of work . professor b: Uh - huh . phd d: Well , it 's not too much , but this {disfmarker} it 's work . professor b: Yeah . phd d: And I want to know if {disfmarker} if we have some {pause} feeling that {pause} the result {disfmarker} I {disfmarker} I would like to know if {disfmarker} I don't have any feeling if this will work better than apply VTS aft in cepstral domain will work better than apply in m mel {disfmarker} in filter bank domain . I r I 'm not sure . I don't {disfmarker} I don't know absolutely nothing . phd c: Mm - hmm . professor b: Yeah . Well , you 're {disfmarker} I think you 're the first one here to work with VTS , so , uh , maybe we could call someone else up who has , ask them their opinion . Uh , phd c: Mm - hmm . professor b: I don't {disfmarker} I don't have a good feeling for it . Um . phd g: Pratibha . phd c: Actually , the VTS that you tested before was in the log domain and so {pause} the codebook is e e kind of dependent on the {pause} level of the speech signal . phd d: Yeah ? phd c: And {disfmarker} So I expect it {disfmarker} If {disfmarker} if you have something that 's independent of this , I expect it to {disfmarker} it {disfmarker} to , uh , be a better model of speech . phd d: To have better {disfmarker} phd c: And . Well . professor b: You {disfmarker} you wouldn't even need to switch to cepstra . Right ? I mean , you can just sort of normalize the {disfmarker} phd c: No . We could normali norm I mean , remove the median . professor b: Yeah . Yeah . And then you have {pause} one number which is very dependent on the level cuz it is the level , phd d: Mm - hmm . professor b: and the other which isn't . phd c: Mm - hmm . Yeah . But here also we would have to be careful about removing the mean {pause} of speech and not of noise . phd d: Ye phd c: Because it 's like {pause} first doing general normalization phd d: Yea phd c: and then noise removal , which is {disfmarker} phd d: Yeah . We {disfmarker} I was thinking to {disfmarker} to {disfmarker} to estimate the noise {pause} with the first frames and then apply the VAD , professor b: Mm - hmm . phd c: Mm - hmm . phd d: before the on - line normalization . phd c: Mm - hmm . phd d: We {disfmarker} we see {disfmarker} Well , I am thinking {vocalsound} about that and working about that , professor b: Yeah . phd d: but I don't have result this week . professor b: Sure . I mean , one of the things we 've talked about {disfmarker} maybe it might be star time to start thinking about pretty soon , is as we look at the pros and cons of these different methods , how do they fit in with one another ? Because {pause} we 've talked about potentially doing some combination of a couple of them . Maybe {disfmarker} maybe pretty soon we 'll have some sense of what their {pause} characteristics are , phd d: Mm - hmm . professor b: so we can see what should be combined . phd c: Mm - hmm . phd a: Is that it ? OK ? professor b: OK . Why don't we read some digits ? phd a: Yep . Want to go ahead , Morgan ? professor b: Sure . phd a: Transcript L dash two one five . professor b: O K .