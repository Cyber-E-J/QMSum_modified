grad a: OK , we 're recording . professor f: We can say the word " zero " all we want , phd g: I 'm doing some professor f: but just {disfmarker} phd g: square brackets , coffee sipping , square brackets . phd b: That 's not allowed , I think . postdoc c: Cur - curly brackets . grad e: Is that voiced or unvoiced ? grad a: Curly brackets . phd b: Curly brackets . professor f: Curly brackets . grad a: Right . phd b: Oops . professor f: Well , correction for transcribers . phd g: Mmm ! {comment} {vocalsound} Gar - darn ! professor f: Yeah . postdoc c: Channel two . grad a: Do we use square brackets for anything ? postdoc c: Yeah . Uh {disfmarker} grad e: These poor transcribers . professor f: u postdoc c: Not ri not right now . I mean {disfmarker} No . phd d: There 's gonna be some zeros from this morning 's meeting because I noticed that professor f: u phd d: Barry , I think maybe you turned your mike off before the digits were {disfmarker} Oh , was it during digits ? Oh , so it doesn't matter . professor f: Yeah . grad a: It 's still not a good idea . phd b: So it 's not {disfmarker} it 's not that bad if it 's at the end , but it 's {disfmarker} in the beginning , it 's {pause} bad . phd d: Yeah . Yeah . grad a: Yeah , you wanna {disfmarker} you wanna keep them on so you get {pause} good noise {disfmarker} noise floors , through the whole meeting . postdoc c: That 's interesting . Hmm . professor f: Uh , I probably just should have left it on . Yeah I did have to run , but {disfmarker} grad e: Is there any way to change that in the software ? grad a: Change what in the software ? grad e: Where like you just don't {disfmarker} like if you {disfmarker} if it starts catching zeros , like in the driver or something {disfmarker} in the card , or somewhere in the hardware {disfmarker} Where if you start seeing zeros on w across one channel , you just add some {vocalsound} random , @ @ {comment} noise floor {disfmarker} like a small noise floor . grad a: I mean certainly we could do that , but I don't think that 's a good idea . We can do that in post - processing if {disfmarker} if the application needs it . grad e: Yeah . phd b: Manual post - processing . professor f: Well , I {disfmarker} u I actually don't know what the default {comment} is anymore as to how we 're using the {disfmarker} the front - end stuff but {disfmarker} for {disfmarker} for {disfmarker} when we use the ICSI front - end , grad a: As an argument . professor f: but um , there is an {disfmarker} there is an o an option in {disfmarker} in RASTA , which , um , {vocalsound} in when I first put it in , uh , back in the days when I actually wrote things , uh , {vocalsound} I {pause} did actually put in a random bit or so that was in it , grad e: OK . professor f: but {vocalsound} then I realized that putting in a random bit was equivalent to adding uh {disfmarker} adding flat spectrum , grad e: Right . professor f: and it was a lot faster to just add a constant to the {disfmarker} {vocalsound} to the spectrum . So then I just started doing that grad e: Mmm . OK . professor f: instead of calling " rand " {comment} or something , grad e: Right . professor f: so . So it d it does that . Gee ! Here we all are ! grad a: Uh , so the only agenda items were Jane {disfmarker} was Jane wanted to talk about some of the IBM transcription process . professor f: There 's an agenda ? grad a: I sort of {vocalsound} condensed the three things you said into that . And then just {disfmarker} I only have like , this afternoon and maybe tomorrow morning to get anything done before I go to Japan for ten days . So if there 's anything that n absolutely , desperately needs to be done , you should let me know now . professor f: Uh , and you just sent off a Eurospeech paper , so . phd g: Right . I hope they accept it . professor f: Right . phd g: I mean , I {disfmarker} both actu as {disfmarker} as a submission and {disfmarker} {vocalsound} you know , as a paper . Um {disfmarker} but {disfmarker} grad a: Well yeah , you sent it in {pause} late . professor f: Yeah , I guess you {disfmarker} first you have to do the first one , grad a: Yeah . professor f: and then {disfmarker} Yeah . phd g: We actually exceeded the delayed deadline by o another day , so . phd b: Oops . professor f: Oh they {disfmarker} they had some extension that they announced or something ? phd g: Well yeah . Liz had sent them a note saying " could we please {pause} have another " {comment} {pause} I don't know , " three days " or something , and they said yes . phd d: And then she said " Did I say three ? grad a: Oh , phd d: I meant four . " grad a: that was the other thing uh , phd g: But u grad a: uh , Dave Gelbart sent me email , I think he sent it to you too , {comment} that um , there 's a special topic , section in si in Eurospeech on new , corp corpors corpora . And it 's not due until like May fifteenth . professor f: Oh this isn't the Aurora one ? grad a: No . professor f: It 's another one ? grad a: It 's a different one . phd b: No it 's {disfmarker} Yeah . Yeah . grad e: Huh ! grad a: And uh , professor f: Oh ! phd b: I got this mail from {disfmarker} grad a: I s forwarded it to Jane as I thought being the most relevant person . Um {disfmarker} So , I thought it was highly relevant {disfmarker} postdoc c: Yeah I 'm {disfmarker} professor f: That 's {disfmarker} grad a: have you {disfmarker} did you look at the URL ? postdoc c: Yeah . I think so too . Um , I haven't gotten over to there yet , grad a: Mm - hmm . postdoc c: but what {disfmarker} our discussion yesterday , I really {disfmarker} I {disfmarker} I wanna submit one . phd b: Was this {pause} SmartKom message ? I think {pause} Christoph Draxler sent this , postdoc c: Yeah . And , you offered to {disfmarker} to join me , if you want me to . grad a: I 'll help , phd b: yeah . grad a: but obviously I can't , really do , most of it , postdoc c: Yeah . Yeah , that 's right . phd g: I think several people {disfmarker} sent this , grad a: so . phd b: Yeah . postdoc c: Uh - huh . phd g: yeah . grad a: But any {disfmarker} any help you need I can certainly provide . professor f: Well , phd g: Yeah . professor f: that 's {disfmarker} that 's a great idea . phd g: Well {disfmarker} there {disfmarker} there were some interesting results in this paper , though . For instance that Morgan {disfmarker} uh , accounted for fifty - six percent of the Robustness meetings in terms of number of words . grad a: Wow . postdoc c: In {disfmarker} in terms of what ? In term phd g: Number of words . postdoc c: One ? Wow ! OK . grad a: That 's just cuz he talks really fast . postdoc c: Do you mean , professor f: n No . grad a: I know phd b: Oh . Short words . postdoc c: because {disfmarker} is it partly , eh , c correctly identified words ? Or is it {disfmarker} or just overall volume ? phd g: No . Well , according to the transcripts . grad a: But re well regardless . I think it 's {disfmarker} he 's {disfmarker} he 's in all of them , postdoc c: Oh . OK . professor f: Yeah . phd g: I mean , we didn't mention Morgan by name grad a: and he talks a lot . phd g: we just {disfmarker} grad a: One participant . professor f: Well {disfmarker} we have now , but {disfmarker} phd g: We {disfmarker} we {disfmarker} we {disfmarker} something about {disfmarker} grad a: Did you identify him as a senior {pause} member ? phd g: No , we as identify him as the person dominating the conversation . professor f: Well . grad a: Yeah . postdoc c: OK . professor f: I mean I get these AARP things , but I 'm not se really senior yet , but {disfmarker} phd g: Right professor f: Um , phd g: Hmm . professor f: but uh , other than that delightful result , what was the rest of the paper about ? phd g: Um , well it was about {disfmarker} it had three sections professor f: You sent it to me but I haven't seen it yet . phd g: uh {disfmarker} three kinds of uh results , if you will . Uh , the one was that the {disfmarker} just the {disfmarker} the amount of overlap grad a: The good , the bad , and the ugly . phd g: um , s in terms of {disfmarker} in terms of number of words and also we computed something called a " spurt " , which is essentially a stretch of speech with uh , no pauses exceeding five hundred milliseconds . Um , and we computed how many overlapped i uh spurts there were and how many overlapped words there were . {vocalsound} Um , for four different {pause} corpora , the Meeting Recorder meetings , the Robustness meetings Switchboard and CallHome , and , found {disfmarker} and sort of compared the numbers . Um , and found that the , uh , you know , as you might expect the Meeting Recorder {pause} meetings had the most overlap uh , but next were Switchboard and CallHome , which both had roughly the same , almost identical in fact , and the Robustness meetings were {disfmarker} had the least , so {disfmarker} One sort of unexpected result there is that uh two - party telephone conversations have {vocalsound} about the same amount of overlap , grad a: I 'm surprised . phd g: sort of in gen you know {disfmarker} order of magnitude - wise as , uh {disfmarker} as face - to - face meetings with multiple {disfmarker} grad a: I have {disfmarker} I had better start changing all my slides ! phd g: Yeah . Also , I {disfmarker} in the Levinson , the pragmatics book , {comment} in you know , uh , textbook , {vocalsound} there 's {disfmarker} I found this great quote where he says {vocalsound} you know {disfmarker} you know , how people {disfmarker} it talks about how uh {disfmarker} how {disfmarker} how people are so good at turn taking , postdoc c: Mm - hmm . Yeah . Yeah . phd g: and {vocalsound} so {disfmarker} they 're so good that {vocalsound} generally , u the overlapped speech does not {disfmarker} is less than five percent . postdoc c: Oh , that 's interesting . Yeah . phd g: So , this is way more than five percent . grad e: Did he mean face {disfmarker} like face - to - face ? Or {disfmarker} ? phd g: Well , in real conversations , grad e: Hmm . phd g: everyday conversations . postdoc c: Mm - hmm . phd g: It 's s what these conversation analysts have been studying for years and years there . postdoc c: Mm - hmm . phd b: But {disfmarker} postdoc c: Well , of course , no , it doesn't necessarily go against what he said , cuz he said " generally speaking " . In order to {disfmarker} to go against that kind of a claim you 'd have to big canvassing . grad a: Hmm . phd b: And in f phd g: Well , he {disfmarker} he made a claim {disfmarker} grad a: Well {disfmarker} phd g: Well {disfmarker} grad a:  phd b: But {disfmarker} professor f: Yeah , we {disfmarker} we have pretty limited sample here . phd b: Five percent of time or five percent of what ? grad a: Yeah , I was gonna ask that too . postdoc c: Yeah . phd b: Yeah . postdoc c: Exactly . phd g: Well it 's time . phd b: Yeah , so {disfmarker} postdoc c: It 's {disfmarker} i it 's not against his conclusion , phd g: So {disfmarker} {vocalsound} but still {disfmarker} but still {disfmarker} u postdoc c: it just says that it 's a bi bell curve , and that , {vocalsound} you have something that has a nice range , in your sampling . phd g: Yeah . So there are slight {disfmarker} There are differences in how you measure it , but still it 's {disfmarker} {vocalsound} You know , the difference between um {disfmarker} between that number and what we have in meetings , which is more like , {vocalsound} you know , close to {disfmarker} in meetings like these , uh {disfmarker} you know , close to twenty percent . postdoc c: Mm - hmm . Mm - hmm . professor f: But what was it like , say , in the Robustness meeting , for instance ? phd g: That {disfmarker} grad a: But {disfmarker} phd g: Robustness meeting ? It was {vocalsound} about half of the r So , {vocalsound} in terms of number of words , it 's like seventeen or eigh eighteen percent for the Meeting Recorder meetings and {vocalsound} about half that for , {vocalsound} uh , the Robustness . professor f: Maybe ten percent ? grad a: But I don't know if that 's really a fair way of comparing between , multi - party , conversations and two - party conversations . Yeah . I {disfmarker} I {disfmarker} I don't know . phd b: Then {disfmarker} then {disfmarker} then you have to {disfmarker} grad a: I mean that 's just something {disfmarker} phd d: Yeah , I just wonder if you have to normalize by the numbers of speakers or something . postdoc c: Yeah . phd b: Then {disfmarker} Yeah , then normalize by {disfmarker} by something like that , postdoc c: Yeah , that 's a good point . phd g: Well , we didn't get to look at that , phd b: yeah . postdoc c: Yeah . phd g: but this obvious thing to see if {disfmarker} if there 's a dependence on the number of uh {disfmarker} participants . postdoc c: Good idea . grad a: I mean {disfmarker} I bet there 's a weak dependence . I 'm sure it 's {disfmarker} it 's not a real strong one . phd b: Yeah . phd g: Right . grad a: Right ? Because you phd d: Cuz not everybody talks . grad a: Right . phd g: Right . phd d: Yeah . grad a: You have a lot of {disfmarker} a lot of two - party , subsets within the meeting . phd g: Right . postdoc c: Uh - huh . grad a: Well regardless {disfmarker} it 's an interesting result regardless . phd g: So {disfmarker} Right . postdoc c: Yes , that 's right . phd g: And {disfmarker} and {disfmarker} and then {disfmarker} and we also d computed this both with and without backchannels , postdoc c: Mm - hmm . phd g: so you might think that backchannels have a special status because they 're essentially just {disfmarker} grad a: Uh - huh . So , did {disfmarker} we all said " uh - huh " and nodded at the same time , phd g: R right . grad a: so . phd g: But , even if you take out all the backchannels {disfmarker} so basically you treat backchannels l as nonspeech , as pauses , grad a: Mm - hmm . professor f: Mm - hmm . phd g: you still have significant overlap . You know , it goes down from maybe {disfmarker} For Switchboard it goes down from {disfmarker} I don't know {disfmarker} f um {disfmarker} {comment} I don't know {disfmarker} f fourteen percent of the words to maybe {vocalsound} uh I don't know , eleven percent or something {disfmarker} it 's {disfmarker} it 's not a dramatic change , grad a: Mm - hmm . phd g: so it 's {disfmarker} Anyway , so it 's uh {disfmarker} That was {disfmarker} that was one set of {pause} results , and then the second one was just basically the {disfmarker} {vocalsound} the stuff we had in the {disfmarker} in the HLT paper on how overlaps effect the {pause} recognition performance . postdoc c: Hmm . grad a: Nope . Right . professor f: Mm - hmm . phd g: And we rescored things um , a little bit more carefully . We also fixed the transcripts in {disfmarker} in numerous ways . Uh , but mostly we added one {disfmarker} one number , which was what if you {pause} uh , basically score ignoring all {disfmarker} So {disfmarker} so the {disfmarker} the conjecture from the HLT results was that {vocalsound} most of the added recognition error is from insertions {vocalsound} due to background speech . So , we scored {vocalsound} all the recognition results , {vocalsound} uh , in such a way that the uh {disfmarker} grad a: Oh by the way , who 's on channel four ? You 're getting a lot of breath . phd b: Yeah . I j was just wondering . grad e: That 's {disfmarker} phd b: Yeah . grad e: That 's me . phd g: uh , well Don 's been working hard . grad e: That 's right . phd g: OK , so {disfmarker} {vocalsound} so if you have the foreground speaker speaking here , and then there 's some background speech , may be overlapping it somehow , um , and this is the time bin that we used , then of course you 're gonna get insertion errors here and here . grad a: Right . phd g: Right ? So we scored everything , and I must say the NIST scoring tools are pretty nice for this , where you just basically ignore everything outside of the , {vocalsound} uh , region that was deemed to be foreground speech . And where that was we had to use the t forced alignment , uh , results from s for {disfmarker} so {disfmarker} That 's somewhat {disfmarker} that 's somewhat subject to error , but still we {disfmarker} we {disfmarker} {vocalsound} Uh , Don did some ha hand - checking and {disfmarker} and we think that {disfmarker} based on that , we think that the results are you know , valid , although of course , some error is gonna be in there . But basically what we found is after we take out these regions {disfmarker} so we only score the regions that were certified as foreground speech , {comment} {vocalsound} the recognition error went down to almost {vocalsound} uh , the {pause} level of the non - overlapped {pause} speech . So that means that {vocalsound} even if you do have background speech , if you can somehow separate out or find where it is , {vocalsound} uh , the recognizer does a good job , grad a: That 's great . phd b: Yeah . phd g: even though there is this back grad a: Yeah , I guess that doesn't surprise me , because , with the close - talking mikes , the {disfmarker} the signal will be so much stronger . phd g: Right . Right . professor f: Mm - hmm . phd g: Mm - hmm . Um , grad a: What {disfmarker} what sort of normalization do you do ? phd g: so {disfmarker} Uh , well , we just {disfmarker} @ @ {comment} we do {disfmarker} u you know , vit grad a: I mean in you recognizer , in the SRI recognizer . phd g: Well , we do uh , VTL {disfmarker} {vocalsound} vocal tract length normalization , w and we uh {disfmarker} you know , we {disfmarker} we uh , {vocalsound} make all the features have zero mean and unit variance . grad a: Over an entire utterance ? professor f: And {disfmarker} grad a: Or windowed ? phd g: Over {disfmarker} over the entire c over the entire channel . phd b: Don't {pause} train {disfmarker} phd g: Over the {disfmarker} grad a: Hmm . phd g: but you know . Um , now we didn't re - align the recognizer for this . We just took the old {disfmarker} So this is actually a sub - optimal way of doing it , grad a: Right . professor f: Right . phd g: right ? So we took the old recognition output and we just scored it differently . So the recognizer didn't have the benefit of knowing where the foreground speech {disfmarker} a start professor f: Were you including the {disfmarker} the lapel {pause} in this ? phd g: Yes . professor f: And did the {disfmarker} did {disfmarker} did the la did the {disfmarker} the problems with the lapel go away also ? Or {disfmarker} phd g: Um , it {disfmarker} Yeah . professor f: fray for {disfmarker} for insertions ? phd g: It u not per {disfmarker} I mean , not completely , but yes , professor f: Less so . phd g: dramatically . So we have to um {disfmarker} professor f: I mean , you still {disfmarker} phd g: Well I should bring the {disfmarker} should bring the table with results . Maybe we can look at it {pause} Monday . professor f: I would presume that you still would have somewhat higher error with the lapel for insertions than {disfmarker} phd g: Yes . It 's {disfmarker} It 's {disfmarker} professor f: Yeah . phd g: Yes . Yeah . professor f: Cuz again , looking forward to the non - close miked case , I think that we s still {disfmarker} phd g: Mm - hmm . grad a: I 'm not looking forward to it . professor f: i it 's the high signal - to - noise ratio phd g: Right . professor f: here that {disfmarker} that helps you . phd g: u s Right . So {disfmarker} so that was number {disfmarker} that was the second set of {disfmarker} uh , the second section . And then , {vocalsound} the third thing was , we looked at , {vocalsound} {vocalsound} uh , what we call " interrupts " , although that 's {disfmarker} that may be {vocalsound} a misnomer , but basically {vocalsound} we looked at cases where {disfmarker} Uh , so we {disfmarker} we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences . So , you know {disfmarker} postdoc c: Di - did you use upper - lower case also , or not ? phd g: Um {disfmarker} postdoc c: U upper lower case or no ? phd g: Hmm ? postdoc c: OK . phd g: No , we only used , you know , uh periods , uh , question marks and {pause} exclamation . And we know that there 's th that 's not a very g I mean , we miss a lot of them , postdoc c: Yeah . That 's OK but {disfmarker} phd g: but {disfmarker} but it 's f i i postdoc c: Comma also or not ? phd g: No commas . No . And then {vocalsound} we looked at locations where , uh , if you have overlapping speech and someone else starts a sentence , you know , where do these {disfmarker} where do other people start their {vocalsound} turns {disfmarker} not turns really , but you know , sentences , phd b: Ah . phd g: um {disfmarker} So we only looked at cases where there was a foreground speaker and then at the to at the {disfmarker} so the {disfmarker} the foreground speaker started into their sentence and then someone else started later . phd b: Somewhere in between the start and the end ? phd g: OK ? And so what {disfmarker} phd b: OK . phd g: Sorry ? phd b: Somewhere in between the start and the end of the foreground ? phd g: Yes . Uh , so that such that there was overlap between the two sentences . phd b: Yeah . phd g: So , the {disfmarker} the question was how can we {disfmarker} what can we say about the places where the second or {disfmarker} or actually , several second speakers , {vocalsound} um {pause} start their {pause} " interrupts " , as we call them . phd d: Three words from the end . grad a: At pause boundaries . phd g: w And we looked at this in terms of um {disfmarker} grad a: On T - closures , only . phd g: So {disfmarker} so we had {disfmarker} {vocalsound} we had um u to {disfmarker} for {disfmarker} for the purposes of this analysis , we tagged the word sequences , and {disfmarker} and we time - aligned them . Um , and we considered it interrupt {disfmarker} if it occurred in the middle of a word , we basically {disfmarker} you know , considered that to be a interrupt as if it were at {disfmarker} at the beginning of the word . So that , {vocalsound} if any part of the word was overlapped , it was considered an interrupted {pause} word . professor f: Mm - hmm . phd g: And then we looked at the {disfmarker} the locatio the , {vocalsound} um , you know , the features that {disfmarker} the tags because we had tagged these word strings , {comment} {vocalsound} um , that {disfmarker} that occurred right before these {disfmarker} these uh , interrupt locations . phd b: Tag by uh phd g: And the tags we looked at are {vocalsound} the spurt tag , which basically says {disfmarker} or actually {disfmarker} Sorry . End of spurt . So {disfmarker} {vocalsound} whether there was a pause essentially here , because spurts are a {disfmarker} defined as being you know , five hundred milliseconds or longer pauses , and then we had things like discourse markers , uh , backchannels , uh , disfluencies . um , uh , filled pauses {disfmarker} So disfluen the D 's are for , {vocalsound} um , {vocalsound} the interruption points of a disfluency , so , where you hesitate , or where you start the repair there . Uh , what else do we had . Uh , repeated {disfmarker} you know , repeated words is another of that kind of disfluencies and so forth . So we had both the beginnings and ends of these {disfmarker} uh so , the end of a filled pause and the end of a discourse marker . And we just eyeballed {disfmarker} I mean {vocalsound} we didn't really hand - tag all of these things . We just {pause} looked at the distribution of words , and so every {vocalsound} " so yeah " , and " OK " , uh , and " uh - huh " were {disfmarker} were the {disfmarker} were deemed to be backchannels and {vocalsound} " wow " and " so " and {vocalsound} uh " right " , uh were um {disfmarker} {pause} Not " right " . " Right " is a backchannel . But so , we sort of {disfmarker} just based on the lexical {disfmarker} {vocalsound} um , identity of the words , we {disfmarker} we tagged them as one of these things . And of course the d the interruption points we got from the original transcripts . So , and then we looked at the disti so we looked at the {pause} distribution of these different kinds of tags , overall uh , and {disfmarker} and {disfmarker} and particularly at the interruption points . And uh , we found that there is a marked difference so that for instance after {disfmarker} so at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted {vocalsound} than before . OK ? And also of course after spurt ends , which means basically in p inside pauses . So pauses are always an opportunity for {disfmarker} So we have this little histogram which shows these distributions and , {vocalsound} um , phd d: I wonder {disfmarker} phd g: you know , it 's {disfmarker} it 's {disfmarker} it 's not {disfmarker} No big surprises , but it is {pause} sort of interesting from {disfmarker} grad a: It 's nice to actually measure it though . phd g: Yeah . phd d: I wonder about the cause and effect there . In other words uh {pause} if you weren't going to pause you {disfmarker} you will because you 're g being interrupted . phd g: Well we 're ne phd d: Uh {disfmarker} phd g: Right . There 's no statement about cause and effect . phd d: Yeah , right . No , no , no . phd g: This is just a statistical correlation , phd d: Right , I {disfmarker} I see . Yeah . phd g: yeah . professor f: But he {disfmarker} yeah , he 's {disfmarker} he 's right , y I mean maybe you weren't intending to pause at all , but {disfmarker} {vocalsound} You were intending to stop for fifty - seven milliseconds , phd g: Right . professor f: but then Chuck came in phd g: Right . phd d: Yeah . professor f: and so you {vocalsound} paused for a second phd g: Right . Anyway . {comment} So , professor f: or more . phd g: uh , and that was basically it . And {disfmarker} and we {disfmarker} so we wrote this and then , {vocalsound} we found we were at six pages , and then we started {vocalsound} cutting furiously phd b: Oops . phd g: and {vocalsound} threw out half of the {vocalsound} material again , and uh played with the LaTeX stuff and {disfmarker} grad a: Made the font smaller and the narrows longer . phd g: uh , and {disfmarker} until it fi phd b: Font smaller , yeah . phd g: No , no . W well , d you couldn't really make everything smaller phd b: Put the abstract end . phd g: but we s we put {disfmarker} Oh , I {disfmarker} I {disfmarker} grad a: Took out white space . phd g: you know the {disfmarker} the gap between the two columns is like ten millimeters , phd b: Yeah . phd g: so I d shrunk it to eight millimeters and that helped some . And stuff like that . phd d: Wasn't there {disfmarker} wasn't there some result , Andreas {disfmarker} professor f: Yeah {disfmarker} phd d: I {disfmarker} I thought maybe Liz presented this at some conference a while ago about {vocalsound} uh , backchannels phd g: Mm - hmm . Mm - hmm . phd d: uh , and that they tend to happen when uh {pause} the pitch drops . You know you get a falling pitch . And so that 's when people tend to backchannel . phd g: Yeah . Well {disfmarker} phd d: Uh - i i do you rem phd g: y We didn't talk about , uh , prosodic , uh , properties at all , phd d: Right . Right . But {disfmarker} phd g: although that 's {disfmarker} I {disfmarker} I take it that 's something that uh Don will {disfmarker} will look at grad e: Yeah , we 're gonna be looking at that . phd g: now that we have the data and we have the alignment , so . This is purely based on you know the words phd d: Mm - hmm . phd g: and {disfmarker} postdoc c: I have a reference for that though . Uh - huh . phd d: Oh you do . phd g: Yeah . phd d: So am I recalling correctly ? phd g: Anyway , so . postdoc c: Well , I didn't know about Liz 's finding on that , phd d: About {disfmarker} postdoc c: but I know of another paper that talks about something phd d: Uh - huh . postdoc c: that {disfmarker} phd d: Hmm . grad e: I 'd like to see that reference too . postdoc c: OK . phd d: It made me think about a cool little device that could be built to uh {disfmarker} to handle those people that call you on the phone and just like to talk and talk and talk . And you just have this little detector that listens for these {vocalsound} drops in pitch and gives them the backchannel . And so then you {vocalsound} hook that to the phone and go off grad a: Yeah . Uh - huh . phd d: and do the {vocalsound} {disfmarker} do whatever you r wanna do , phd g: Oh yeah . Well {disfmarker} phd d: while that thing keeps them busy . phd g: There 's actually {disfmarker} uh there 's this a former student of here from Berkeley , Nigel {disfmarker} Nigel Ward . phd d: Uh - huh . Sure . phd g: Do you know him ? phd d: Yeah . phd g: He did a system uh , in {disfmarker} he {disfmarker} he lives in Japan now , and he did this backchanneling , automatic backchanneling system . professor f: Right . phd g: It 's a very {disfmarker} phd d: Oh ! phd g: So , exactly what you describe , phd d: Huh . phd g: but for Japanese . And it 's apparently {disfmarker} for Japa - in Japanese it 's really important that you backchannel . It 's really impolite if you don't , and {disfmarker} So . professor f: Huh . Actually for a lot of these people I think you could just sort of backchannel continuously and it would {pause} pretty much be fine . phd d: It wouldn't matter ? Yeah . grad e: Yeah . That 's w That 's what I do . phd d: Random intervals . grad a: There was {disfmarker} there was of course a Monty Python sketch with that . Where the barber who was afraid of scissors was playing a {disfmarker} a tape of clipping sounds , and saying " uh - huh " , " yeah " , " how about them sports teams ? " phd g: Anyway . So the paper 's on - line and y I {disfmarker} I think I uh {disfmarker} I CC ' ed a message to Meeting Recorder with the URL so you can get it . grad a: Yep . professor f: Yeah . grad a: Printed it out , haven't read it yet . professor f: Yeah . phd g: Um , uh one more thing . So I {disfmarker} I 'm actually {disfmarker} {vocalsound} about to send Brian Kingbury an email saying where he can find the {disfmarker} the s the m the material he wanted for the s for the speech recognition experiment , so {disfmarker} but I haven't sent it out yet because actually my desktop locked up , like I can't type anything . Uh b so if there 's any suggestions you have for that I was just gonna send him the {disfmarker} phd d: Is it the same directory that you had suggested ? phd g: I made a directory . I called it um {disfmarker} postdoc c: He still has his Unix account here , you know . phd g: Well this isn't {disfmarker} postdoc c: Yeah . phd g: He does ? postdoc c: And he {disfmarker} and he 's {disfmarker} phd g: Yeah but {disfmarker} but {disfmarker} but he has to {disfmarker} postdoc c: I 'd hafta add him to Meeting Recorder , I guess , phd g: he prefe he said he would prefer FTP postdoc c: but {disfmarker} OK . phd g: and also , um , the other person that wants it {disfmarker} There is one person at SRI who wants to look at the {vocalsound} um , you know , the uh {disfmarker} the data we have so far , postdoc c: OK . phd g: and so I figured that FTP is the best {pause} approach . So what I did is I um {disfmarker} {vocalsound} {vocalsound} @ @ {comment} I made a n new directory after Chuck said that would c that was gonna be a good thing . Uh , so it 's " FTP {vocalsound} {pause} pub grad a: Pub real . phd g: real " {disfmarker} Exactly . MTGC {disfmarker} What is it again ? CR {disfmarker} grad a: Ask Dan Ellis . professor f: u R D {disfmarker} RDR , yeah . phd g: Or {disfmarker} Yeah . Right ? The same {disfmarker} the same as the mailing list , professor f: Yeah , phd g: and {disfmarker} professor f: the {disfmarker} {pause} No vowels . phd g: Yeah . Um , professor f: Yeah phd g: and then under there {disfmarker} Um actually {disfmarker} Oh and this directory , {vocalsound} is not readable . It 's only uh , accessible . So , {vocalsound} in other words , to access anything under there , you have to {vocalsound} be told what the name is . grad a: Right . phd g: So that 's sort of a g {vocalsound} quick and dirty way of doing access control . professor f: Mm - hmm . phd g: So {disfmarker} uh , and the directory for this I call it I " ASR zero point one " because it 's sort of meant for recognition . professor f: So anyone who hears this meeting now knows the {disfmarker} grad a: Beta ? phd g: And then {disfmarker} then in there I have a file that lists all the other {vocalsound} files , so that someone can get that file and then know the file names and therefore download them . If you don't know the file names you can't {disfmarker} professor f: Is that a dash or a dot in there ? phd g: I mean you can {disfmarker} grad a: Don't {disfmarker} don't {disfmarker} don't say . phd g: Dash . Anyway . So all I {disfmarker} all I was gonna do there was stick the {disfmarker} the transcripts after we {disfmarker} the way that we munged them for scoring , because that 's what he cares about , and {disfmarker} um , and also {disfmarker} and then the {disfmarker} the {pause} waveforms that Don segmented . I mean , just basically tar them all up f I mean {disfmarker} w for each meeting I tar them all into one tar file and G - zip them and stick them there . grad a: I uh , put digits in my own home directory {disfmarker} home FTP directory , phd g: And so . grad a: but I 'll probably move them there as well . phd g: Oh , OK . phd d: So we could point Mari to this also for her {vocalsound} March O - one request ? phd g: OK . Yeah . March O - one . phd d: Or {disfmarker} phd g: Oh ! phd d: You n Remember she was {disfmarker} phd g: Oh she wanted that also ? phd d: Well she was saying that it would be nice if we had {disfmarker} they had a {disfmarker} Or was she talking {disfmarker} Yeah . She was saying it would be nice if they had eh {pause} the same set , so that when they did experiments they could compare . phd g: Right , but they don't have a recognizer even . phd d: Yeah . grad e: Um {disfmarker} I phd g: But yeah , we can send {disfmarker} I can CC Mari on this so that she knows {disfmarker} phd d: Yeah . So , for the thing that {disfmarker} postdoc c: That 's good . phd d: We need to give Brian the beeps file , phd g: Right . phd d: so I was gonna probably put it {disfmarker} grad a: We can put it in the same place . Just put in another directory . phd d: Yeah , it I 'll make another directory . phd g: Well , make ano make another directory . phd d: Yeah . Exactly . phd g: You don't n m phd d: Yeah . phd g: Yeah . grad e: And , Andreas , um , sampled ? phd g: Yeah . They are ? grad e: I think so . Yeah . Um , so either we should regenerate the original {vocalsound} versions , {comment} {pause} or um , we should just make a note of it . phd g: OK . Oh . Beca - Well {disfmarker} OK , because in one directory there 's two versions . grad e: Yeah , that 's the first meeting I cut both versions . Just to check which w if there is a significant difference . phd g: OK . And so I {disfmarker} but {disfmarker} OK so {disfmarker} but for the other meetings it 's the downsampled version that you have . grad e: They 're all downsampled , yeah . phd g: Oh , OK . Oh that 's th important to know , OK so we should probably {disfmarker} uh {pause} give them the non - downsampled versions . grad e: Yeah . So {disfmarker} phd g: OK . Alright , then I 'll hold off on that and I 'll wait for you um {disfmarker} grad e: Probably by tomorrow phd g: gen grad e: I can {disfmarker} I 'll send you an email . phd g: OK . Alright . OK . Yeah , definitely they should have the full bandwidth version , grad e: Yeah , because I mean {disfmarker} I I think Liz decided to go ahead with the {pause} downsampled versions cuz we can {disfmarker} There was no s like , r significant difference . phd g: yeah . OK . Well , it takes {disfmarker} it takes up less disk space , for one thing . grad e: It does take up less disk space , and apparently it did even better {pause} than the original {disfmarker} than the original versions , phd g: Yeah . Yeah . grad e: which you know , is just , probably random . phd g: Right . Yeah , it was a small difference grad e: But , um {pause} they probably w want the originals . phd g: but yeah . Yeah . OK . OK , good . Good that {disfmarker} Well , it 's a good thing that {disfmarker} grad a: OK , I think we 're losing , Don and Andreas at three - thirty , right ? OK . grad e: Hey mon hafta booga . phd g: Yeah . professor f: So , that 's why it was good to have Andreas , say these things but {disfmarker} So , we should probably talk about the IBM transcription process stuff that {disfmarker} postdoc c: OK . So , um you know that Adam created um , a b a script to generate the beep file ? professor f: Hmm . postdoc c: To then create something to send to IBM . And , um , you {disfmarker} you should probably talk about that . But {disfmarker} but you were gonna to use the {pause} originally transcribed file because I tightened the time bins and that 's also the one that they had already {vocalsound} in trying to debug the first stage of this . And uh , my understanding was that , um {disfmarker} I haven't {disfmarker} {vocalsound} I haven't listened to it yet , grad a: Mm - hmm . postdoc c: but it sounded very good and {disfmarker} and I understand that you guys {vocalsound} were going to have a meeting today , before this meeting . grad a: It was just to talk about how to generate it . Um , just so that while I 'm gone , you can regenerate it if you decide to do it a different way . So uh , Chuck and Thilo should , now more or less know how to generate the file postdoc c: Excellent . OK . grad a: and , {vocalsound} the other thing Chuck pointed out is that , um , {vocalsound} since this one is hand - marked , {vocalsound} there are discourse boundaries . Right ? So {disfmarker} so when one person is speaking , there 's breaks . postdoc c: Mm - hmm . grad a: Whereas Thilo 's won't have that . So what {disfmarker} what we 're probably gonna do is just write a script , that if two , chunks are very close to each other on the same channel we 'll just merge them . postdoc c: Oh ! OK . Ah , interesting . Yeah . Yeah . Oh , sure . Yeah , sure . Makes sense . grad a: So , uh , and that will get around the problem of , the , {vocalsound} you know " one word beep , one word beep , one word beep , one word beep " . postdoc c: Yeah . Ah ! Clever . Yes . Clever . Yeah . Excellent . phd d: Yeah , in fact after our meeting uh , this morning Thilo came in and said that {vocalsound} um , there could be {pause} other differences between {vocalsound} the uh {pause} already transcribed meeting with the beeps in it and one that has {pause} just r been run through his process . postdoc c: And that 's the purpose . Yeah . phd d: So tomorrow , {vocalsound} when we go to make the um {pause} uh , chunked file {vocalsound} for IBM , we 're going to actually compare the two . So he 's gonna run his process on that same meeting , postdoc c: Great idea ! phd d: and then we 're gonna do the beep - ify on both , and listen to them and see if we notice any real differences . phd g: Beep - ify ! postdoc c: OK , now one thing that prevented us from apply you {disfmarker} you from applying {disfmarker} Exactly . The training {disfmarker} So that is the training meeting . OK . phd d: Yeah , w and we know that . Wel - uh we just wanna if {disfmarker} if there 're any major differences between {vocalsound} doing it on the hand postdoc c: Uh - huh . Oh , interesting . Ah ! grad a: Hmm . postdoc c: OK . Interesting idea . Great . phd g: So this training meeting , uh w un is that uh {pause} some data where we have uh very um , {vocalsound} you know , accurate {pause} time marks ? for {disfmarker} postdoc c: I went back and hand - marked the {pause} ba the bins , I ment I mentioned that last week . phd g: OK , yeah . phd d: But the {disfmarker} but there 's {disfmarker} yeah , but there is this one issue with them in that there 're {disfmarker} {vocalsound} there are time boundaries in there that occur in the middle of speech . phd g: Because {disfmarker} phd d: So {disfmarker} Like when we went t to um {disfmarker} When I was listening to the original file that Adam had , it 's like you {disfmarker} you hear a word then you hear a beep {vocalsound} and then you hear the continuation of what is the same sentence . grad a: That 's on the other channel . That 's because of channel overlap . phd d: Well , and {disfmarker} and so the {disfmarker} th postdoc c: Hmm . grad a: It 's {disfmarker} i phd d: So there are these chunks that look like uh {disfmarker} {vocalsound} that have uh {disfmarker} grad a: I mean that 's not gonna be true of the foreground speaker . That 'll only be if it 's the background speaker . phd d: Right . So you 'll {disfmarker} you 'll have a chunk of , you know , channel {vocalsound} A which starts at zero and ends at ten , and then the same channel starting at eleven , ending at fifteen , and then again , starting at sixteen , ending at twenty . Right , so that 's three chunks where {vocalsound} actually we w can just make one chunk out of that which is A , zero , twenty . phd g: Mm - hmm . postdoc c: Yeah . grad a: That 's what I just said , postdoc c: Sure . Sure . grad a: yeah . phd d: Yeah . So I just wanted to make sure that it was clear . postdoc c: Yeah , I thought that was {disfmarker} phd d: So {vocalsound} if you were to use these , you have to be careful not to pull out these individual {disfmarker} postdoc c: Yeah . phd g: Oh ! I mean it {disfmarker} Right , I mean w I mean what I would {disfmarker} I was interested in is having {disfmarker} {vocalsound} a se having time marks for the beginnings and ends of speech by each speaker . grad a: Well , that 's definitely a problem . phd g: Uh , because we could use that to fine tune our alignment process grad a: Battery . phd d: Yeah . phd g: to make it more accurate . phd b: Battery ? phd d: Mm - hmm . phd g: So {disfmarker} uh , it {disfmarker} I don't care that you know , there 's actually abutting segments that we have to join together . That 's fine . phd d: OK . phd g: But what we do care about is that {vocalsound} the beginnings and ends um {pause} are actually close to the speech {vocalsound} inside of that phd d: Yeah , I think Jane tightened these up by hand . phd g: uh {disfmarker} phd b: OK . postdoc c: Yeah . phd g: OK , so what is the {disfmarker} sort of how tight are they ? professor f: Uh , it looks much better . phd b: Yeah . Looks good . postdoc c: They were , um , reasonably tight , but not excruciatingly tight . phd g: Oh . postdoc c: That would 've taken more time . I just wanted to get it so tha So that if you have like " yeah " {comment} in a {disfmarker} swimming in a big bin , then it 's {disfmarker} phd g: No , no ! I don grad a: Let me make a note on yours . phd g: actually I {disfmarker} I {disfmarker} phd b: Yeah . phd g: I {disfmarker} it 's f That 's fine because we don't want to {disfmarker} th that 's perfectly fine . In fact it 's good . You always want to have a little bit of pause or nonspeech around the speech , say for recognition purposes . Uh , but just {disfmarker} just u w you know get an id I just wanted to have an idea of the {disfmarker} {vocalsound} of how much extra you allowed um {disfmarker} so that I can interpret the numbers if I compared that with a forced alignment segmentation . postdoc c: I can't answer that , phd g: So . postdoc c: but {disfmarker} but my main goal was {pause} um , in these areas where you have a three - way overlap {vocalsound} and one of the overlaps involves " yeah " , {vocalsound} and it 's swimming in this huge bin , {vocalsound} I wanted to get it so that it was clo more closely localized . phd g: Mm - hmm . Mm - hmm . Right . But are we talking about , I don't know , {pause} a {vocalsound} {pause} tenth of a second ? a {disfmarker} ? You know ? How {disfmarker} how much {disfmarker} how much extra would you allow at most {disfmarker} postdoc c: I {disfmarker} I wanted to {disfmarker} I wanted it to be able to {disfmarker} l he be heard normally , phd g: Mm - hmm . postdoc c: so that if you {disfmarker} if you play {pause} back that bin and have it in the mode where it stops at the boundary , {vocalsound} it sounds like a normal word . phd g: OK . postdoc c: It doesn't sound like the person {disfmarker} i it sounds normal . It 's as if the person could 've stopped there . phd g: Mm - hmm . postdoc c: And it wouldn't have been an awkward place to stop . phd g: OK . postdoc c: Now sometimes you know , it 's {disfmarker} these are involved in places where there was no time . And so , {vocalsound} {vocalsound} there wouldn't be {pause} a gap afterwards because {disfmarker} phd g: OK . postdoc c: I mean some cases , there 're some people {pause} um , who {disfmarker} who have very long {pause} segments of discourse where , {vocalsound} you know , they 'll {disfmarker} they 'll breath {pause} and then I put a break . phd g: Mm - hmm . postdoc c: But other than that , it 's really pretty continuous and this includes things like going from one sentence into the {disfmarker} u one utterance into the next , one sentence into the next , um , w without really stopping . I mean {disfmarker} i they , i you know in writing you have this {vocalsound} two spaces and a big gap phd g: Mm - hmm . postdoc c: you know . phd g: Right . postdoc c: But {disfmarker} but uh {pause} {vocalsound} i some people are planning and , you know , I mean , a lot {disfmarker} we always are planning {pause} what we 're going to say next . phd g: OK . postdoc c: But uh , in which case , the gap between {pause} these two complete syntactic units , {vocalsound} um , which of course n spoken things are not always complete syntactically , but {disfmarker} {vocalsound} but it would be a shorter p shorter break {vocalsound} than {vocalsound} maybe you might like . phd g: Mm - hmm . postdoc c: But the goal there was to {pause} not have {vocalsound} the text be so {disfmarker} so crudely {pause} parsed in a time bin . I mean , because {vocalsound} from a discourse m purpose {pause} it 's {disfmarker} {vocalsound} it 's more {disfmarker} {vocalsound} it 's more useful to be able to see {disfmarker} and also you know , from a speech recognition purpose my impression is that {vocalsound} if you have too long a unit , it 's {disfmarker} it doesn't help you very much either , cuz of the memory . phd g: Well , yeah . That 's fine . postdoc c: So , that means that {vocalsound} the amount of time after something is variable depending partly on context , but my general goal {vocalsound} when there was {pause} sufficient space , room , pause {pause} after it {pause} to have it be {pause} kind of a natural feeling {pause} gap . phd g: OK . postdoc c: Which I c I don't know what it would be quantified as . You know , Wally Chafe says that {vocalsound} um , {vocalsound} in producing narratives , the spurts that people use {vocalsound} tend to be , {vocalsound} uh , that the {disfmarker} the {disfmarker} what would be a pause might be something like two {disfmarker} two seconds . phd g: Mmm . postdoc c: And um , that would be , you know one speaker . The discourse {disfmarker} {vocalsound} the people who look at turn taking often do use {disfmarker} phd g: Mm - hmm . postdoc c: I was interested that you chose uh , {vocalsound} you know um , {comment} the {disfmarker} you know that you use cuz I think that 's a unit that would be more consistent with sociolinguistics . Yeah . phd g: Well we chose um , you know , half a second because {vocalsound} if {disfmarker} if you go much larger , you have a {disfmarker} y you know , your {disfmarker} your statement about how much overlap there is becomes less , {vocalsound} um , precise , postdoc c: Mm - hmm . phd g: because you include more of actual pause time into what you consider overlap speech . Um , so , it 's sort of a compromise , phd b: Yeah . {comment} {vocalsound} {vocalsound} Yeah , I also used I think something around zero point five seconds for the speech - nonspeech detector {disfmarker} phd g: and {disfmarker} {vocalsound} it 's also based {disfmarker} I mean Liz suggested that value based on {vocalsound} the distribution of pause times that you see in Switchboard and {disfmarker} and other corpora . postdoc c: Mm - hmm . phd g: Um {disfmarker} So {disfmarker} phd b: for the minimum silence length . phd g: Mm - hmm . I see . phd b: So . phd g: Yeah . postdoc c: Mm - hmm . phd g: OK . postdoc c: In any case , this {disfmarker} this uh , meeting {pause} that I hand {disfmarker} I {disfmarker} I hand - adjusted two of them I mentioned before , phd g: Mm - hmm . postdoc c: and I sent {disfmarker} I sent email , phd g: OK , postdoc c: so {disfmarker} phd g: So {disfmarker} so at some point we will try to fine - tune our forced alignment postdoc c: And I sent the {comment} {pause} path . phd g: maybe using those as references because you know , what you would do is you would play with different parameters . And to get an object You need an objective {vocalsound} measure of how closely you can align the models to the actual speech . And that 's where your your data would be {pause} very important to have . So , I will {disfmarker} Um {disfmarker} phd b: Yeah and hopefully the new meetings {pause} which will start from the channelized version will {disfmarker} will have better time boundaries {pause} and alignments . phd g: Mm - hmm . Right . postdoc c: But I like this idea of {disfmarker} uh , for our purposes for the {disfmarker} for the IBM preparation , {vocalsound} uh , n having these {pause} joined together , phd b: Yeah . Yeah . postdoc c: and uh {disfmarker} It makes a lot of sense . And in terms of transcription , it would be easy to do it that way . phd g: Yeah . postdoc c: The way that they have with the longer units , phd g: Yeah . postdoc c: not having to fuss with adding these units at this time . phd b: Yeah . Whi - which could have one drawback . If there is uh a backchannel in between those three things , phd g: Right . postdoc c: Mm - hmm . phd b: the {disfmarker} the n the backchannel will {disfmarker} will occur at the end of {disfmarker} of those three . postdoc c: Yes . phd b: And {disfmarker} and in {disfmarker} in the {disfmarker} in the previous version where in the n which is used now , {vocalsound} there , the backchannel would {disfmarker} would be in - between there somewhere , so . postdoc c: I see . phd b: That would be more natural postdoc c: Yeah . Well , phd b: but {disfmarker} postdoc c: that 's {disfmarker} that 's right , but you know , thi this brings me to the other f stage of this which I discussed with you earlier today , phd b: Yeah . postdoc c: which is {vocalsound} the second stage is {vocalsound} um , w what to do {pause} in terms of the transcribers adjustment of these data . I discussed this with you too . Um , the tr so the idea initially was , we would get {vocalsound} uh , for the new meetings , so the e EDU meetings , that {vocalsound} Thilo ha has now presegmented all of them for us , on a channel by channel basis . And um , so , I 've assigned {disfmarker} I 've {disfmarker} I 've assigned them to our transcribers and um , so far I 've discussed it with one , with uh {disfmarker} And I had a {pause} about an hour discussion with her about this yesterday , we went through {vocalsound} uh EDU - one , at some extent . And it occurred to me that {vocalsound} um {disfmarker} that {vocalsound} basically what we have in this kind of a format is {disfmarker} you could consider it as a staggered mixed file , we had some discussion over the weekend a about {disfmarker} at {disfmarker} at this other meeting that we were all a at {disfmarker} um , {vocalsound} about whether the tran the IBM transcribers should hear a single channel audio , or a mixed channel audio . And um , {vocalsound} in {disfmarker} in a way , by {disfmarker} by having this {disfmarker} this chunk and then the backchannel {vocalsound} after it , it 's like a stagal staggered mixed channel . And um , {vocalsound} it occurred {pause} to me in my discussion with her yesterday that um , um , the {disfmarker} {pause} the {disfmarker} the maximal gain , it 's {disfmarker} from the IBM {pause} people , may be in long stretches of connected speech . So it 's basically a whole bunch of words {vocalsound} which they can really do , because of the continuity within that person 's turn . So , what I 'm thinking , and it may be that not all meetings will be good for this , {comment} but {disfmarker} but what I 'm thinking is that {vocalsound} in the EDU meetings , they tend to be {vocalsound} driven by a couple of dominant speakers . And , if the chunked files focused on the dominant speakers , {vocalsound} then , when {disfmarker} when it got s patched together when it comes back from IBM , we can add the backchannels . It seems to me {vocalsound} that {vocalsound} um , you know , the backchannels per - se wouldn't be so hard , but then there 's this question of the time {pause} @ @ {comment} uh , marking , and whether the beeps would be {vocalsound} uh y y y And I 'm not exactly sure how that {disfmarker} how that would work with the {disfmarker} with the backchannels . And , so um {disfmarker} And certainly things that are {vocalsound} intrusions of multiple words , {vocalsound} taken out of context and displaced in time from where they occurred , {vocalsound} that would be hard . So , m my {vocalsound} thought is {pause} i I 'm having this transcriber go through {vocalsound} the EDU - one meeting , and indicate a start time {nonvocalsound} f for each dominant speaker , endpoi end time for each dominant speaker , and the idea that {vocalsound} these units would be generated for the dominant speakers , {vocalsound} and maybe not for the other channels . grad a: Yeah the only , um , disadvantage of that is , then it 's hard to use an automatic method to do that . The advantage is that it 's probably faster to do that than it is to use the automated method and correct it . So . postdoc c: Well , it {disfmarker} grad a: We 'll just have to see . postdoc c: OK . I think {disfmarker} {vocalsound} I {disfmarker} I think um , you know , the original plan was that the transcriber would adjust the t the boundaries , and all that for all the channels but , {vocalsound} you know , that is so time - consuming , and since we have a bottleneck here , we want to get IBM things that are usable s as soon as possible , then this seemed to me it 'd be a way of gett to get them a flood of data , which would be useful when it comes back to us . And um {disfmarker} grad a: Yeah . postdoc c: Oh also , at the same time she {disfmarker} when she goes through this , she 'll be {vocalsound} uh {disfmarker} If there 's anything that {vocalsound} was encoded as a pause , but really has something transcribable in it , {vocalsound} then she 's going to {vocalsound} uh , make a mark {disfmarker} w uh , so you know , so {vocalsound} that {disfmarker} that bin would be marked as it {disfmarker} as double dots and she 'll just add an S . And in the other {disfmarker} in the other case , if it 's marked as speech , {vocalsound} and really there 's nothing transcribable in it , then she 's going to put a s dash , and I 'll go through and it {disfmarker} and um , you know , with a {disfmarker} {vocalsound} {vocalsound} with a substitution command , get it so that it 's clear that those are the other category . I 'll just , you know , recode them . But um , {vocalsound} um , the transcribable events {pause} that um , I 'm considering in this , {vocalsound} uh , continue to be {vocalsound} laugh , as well as speech , and cough and things like that , so I 'm not stripping out anything , just {disfmarker} just you know , being very lenient in what 's considered speech . Yeah ? phd d: Jane ? In terms of the {disfmarker} this new procedure you 're suggesting , {vocalsound} um , u what is the {disfmarker} grad a: It 's not that different . phd d: So I 'm a little confused , because how do we know where to put beeps ? Is it {disfmarker} i d y is it {disfmarker} postdoc c: Oh , OK . grad a: Transcriber will do it . postdoc c: So what it {disfmarker} what it {disfmarker} what it involves is {disfmarker} is really a s uh , {vocalsound} uh , the original pr procedure , but {vocalsound} only applied to {pause} uh , a certain {pause} strategically chosen {pause} s aspect of the data . grad a: We pick the easy parts of the data basically , postdoc c: So {disfmarker} grad a: and transcriber marks it by hand . postdoc c: You got it . grad a: And because {disfmarker} phd d: But after we 've done Thilo 's thing . grad a: No . postdoc c: Yes ! grad a: Oh , after . Oh , OK , postdoc c: Yes ! grad a: I didn't {disfmarker} I didn't understand that . postdoc c: Oh yeah ! grad a: OK . phd b: So , I 'm @ @ {disfmarker} now I 'm confused . postdoc c: OK . We start with your presegmented version {disfmarker} phd g: OK , and I 'm leaving . grad e: Yeah , I have to go as well . phd g: So , um {disfmarker} grad a: OK , leave the mikes on , and just put them on the table . grad e: OK . Thanks . postdoc c: We start with the presegmented version {disfmarker} grad a: Let me mark you as no digits . phd b: You start with the presegmentation , r {vocalsound} yeah ? postdoc c: Yeah . And then um , {vocalsound} the transcriber , {vocalsound} instead of going painstakingly through all the channels and moving the boundaries around , and deciding if it 's speech or not , but not transcribing anything . OK ? Instead of doing that , which was our original plan , {vocalsound} the tra They focus on the dominant speaker {disfmarker} phd d: Mm - hmm . They just {vocalsound} do that on {pause} the main channels . postdoc c: Yeah . So what they do is they identify who 's the di dominant speaker , and when the speaker starts . phd d: OK . phd b: Yeah ? OK . postdoc c: So I mean , you 're still gonna {disfmarker} phd b: And you just {disfmarker} postdoc c: So we 're {disfmarker} It 's based on your se presegmentation , that 's the basic {pause} thing . phd b: and you just use the s the segments of the dominant speaker then ? For {disfmarker} for sending to {disfmarker} to IBM or {disfmarker} ? postdoc c: Yeah . Exactly . phd d: So , now Jane , my question is {vocalsound} when they 're all done adjusting the w time boundaries for the dominant speaker , {comment} have they then also erased the time boundaries for the other ones ? postdoc c: Mm - hmm . Uh No . No , no . Huh - uh . S phd d: So how will we know who {disfmarker} phd b: Yeah . postdoc c: That 's {disfmarker} that 's why she 's notating the start and end points of the dominant speakers . So , on a {disfmarker} you know , so {vocalsound} i in EDU - one , i as far as I listened to it , you start off with a {disfmarker} a s section by Jerry . So Jerry starts at minute so - and - so , and goes until minute so - and - so . And then Mark Paskin comes in . And he starts at {vocalsound} minute such - and - such , and goes on till minute so - and - so . OK . And then {vocalsound} meanwhile , she 's listening to {vocalsound} {pause} both of these guys ' channels , determining if there 're any cases of misclassification of speech as nothing , and nothing as speech , phd d: Mm - hmm . OK . postdoc c: and {vocalsound} a and adding a tag if that happens . phd d: So she does the adjustments on those guys ? postdoc c: But you know , I wanted to say , his segmentation is so good , that {vocalsound} um , the part that I listened to with her yesterday {vocalsound} didn't need any adjustments of the bins . phd b: On that meeting . phd d: Mm - hmm . postdoc c: So far we haven't . So this is not gonna be a major part of the process , at least {disfmarker} least not in {disfmarker} not on ones that {disfmarker} that really {disfmarker} phd d: So if you don't have to adjust the bins , why not just do what it {disfmarker} for all the channels ? postdoc c: Mm - hmm ? phd d: Why not just throw all the channels to IBM ? postdoc c: Well there 's the question o of {pause} whether {disfmarker} Well , OK . She i It 's a question of how much time we want our transcriber to invest here {vocalsound} when she 's gonna have to invest that when it comes back from IBM anyway . phd d: Mm - hmm . postdoc c: So if it 's only inserting " mm - hmm "s here and there , then , wouldn't that be something that would be just as efficient to do at this end , instead of having it go through I B M , then be patched together , then be double checked here . phd d: Mm - hmm . Right . phd b: Yeah . But {disfmarker} But then we could just use the {disfmarker} the output of the detector , and do the beeping on it , and send it to I B phd d: Without having her check anything . phd b: Yeah . professor f: Right . postdoc c: Well , I guess {disfmarker} grad a: I think we just {disfmarker} we just have to listen to it and see how good they are . phd b: For some meetings , I 'm {disfmarker} I 'm sure it {disfmarker} i n postdoc c: I 'm {disfmarker} I 'm open to that , it was {disfmarker} professor f: Yeah , if it 's working well , phd b: That 's {disfmarker} And some {disfmarker} on some meetings it 's good . professor f: that sounds like a good idea since as you say you have to do stuff with the other end anyway . phd b: Yeah . postdoc c: Well yea OK , good . I mean the detector , this {disfmarker} phd d: Yeah , I mean we have to fix it when it comes back anyhow . phd b: Yeah . postdoc c: Now , you were saying that they {disfmarker} they differ in how well they work depending on channel s sys systems and stuff . phd b: Yeah . So we should perhaps just select meetings on which the speech - nonspeech detection works well , postdoc c: But EDU is great . phd b: and just use , {vocalsound} those meetings to {disfmarker} to {disfmarker} to send to IBM and , do the other ones . grad a: Release to begin with . postdoc c: How interesting . You know {disfmarker} professor f: What 's the problem {disfmarker} the l I forget . Is the problem the lapel , or {disfmarker} or {disfmarker} phd b: Uh , it really depends . Um , my {disfmarker} my {disfmarker} my impression is that it 's better for meetings with fewer speakers , and it 's better for {disfmarker} {vocalsound} for meetings where nobody is breathing . professor f: Oh , phd b: Yeah , professor f: the dead meetings . phd b: get {disfmarker} That 's it . phd d: So in fact this might suggest an alternative sort of a {disfmarker} a c a hybrid between these two things . grad a: No , the undead meeting , yeah . postdoc c: Yeah . Yeah ? phd d: So the {disfmarker} the one suggestion is you know we {disfmarker} {vocalsound} we run Thilo 's thing and then we have somebody go and adjust all the time boundaries phd b: Yeah . postdoc c: Yeah ? phd d: and we send it to IBM . The other one is {vocalsound} we just run his thing and send it to IBM . phd b: Yeah . phd d: There 's a {disfmarker} a another possibility if we find that there are some problems , phd b: Yeah . Yeah . phd d: and that is {vocalsound} if we go ahead and we {vocalsound} just run his , and we generate the beeps file , then we have somebody listen beeps file . phd b: Yeah . And erase {disfmarker} phd d: And they listen to each section and say " yes , no " whether that section is phd b: Yeah . postdoc c: Is intelligible . phd d: i i intelligible or not . And it just {disfmarker} You know , there 's a little interface which will {disfmarker} for all the " yes " - es it {disfmarker} then that will be the final {vocalsound} beep file . phd b: Yeah . grad a: Blech . postdoc c: That 's interesting ! Cuz that 's {disfmarker} that 's directly related to the e end task . grad a: Stress test . phd d: Mm - hmm . postdoc c: How interesting ! phd d: Yeah . I mean it wouldn't be that much fun for a transcriber to sit there , hear it , beep , yes or no . phd b: Nope . professor f: I {disfmarker} I {disfmarker} I don't know . phd d: But it would be quick . professor f: It would be {disfmarker} kind of quick but they 're still listening to everything . phd d: But there 's no adjusting . And that 's what 's slow . There 's no adjusting of time boundaries . postdoc c: Well , {vocalsound} eh , listening does take time too . phd d: Yeah . professor f: Yeah . I don't know , I {disfmarker} I think I 'm {disfmarker} I 'm really tending towards {disfmarker} grad a: One and a half times real time . professor f: I mean , {vocalsound} what 's the worst that happens ? Do the transcribers {disfmarker} I mean as long as th on the other end they can say there 's {disfmarker} there 's something {disfmarker} conventions so that they say " huh ? " phd d: Yeah . Right . They {disfmarker} they {disfmarker} professor f: and then we can flag those later . phd d: Yeah . That 's true . professor f: i i It {disfmarker} i phd d: We can just catch it at the {disfmarker} catch everything at this side . professor f: Yeah . phd d: Well maybe that 's the best way to go , postdoc c: How interesting ! phd d: just {disfmarker} grad a: I mean it just depends on how {disfmarker} postdoc c: Well EDU {disfmarker} phd b: Yeah , grad a: Sorry , go ahead . phd b: u u u postdoc c: So I was gonna say , EDU - one is good enough , phd b: Yeah . postdoc c: maybe we could include it in this {disfmarker} in this set of uh , this stuff we send . phd b: Yeah there 's {disfmarker} I {disfmarker} I think there are some meetings where it would {disfmarker} would {disfmarker} It 's possible like this . grad a: Yeah I {disfmarker} I think , we won't know until we generate a bunch of beep files automatically , listen to them and see how bad they are . phd b: Yeah . Yeah . phd d: Yeah . postdoc c: Mm - hmm . phd d: We won't be able to s include it with this first thing , grad a: If {disfmarker} postdoc c: Hmm . Oh , OK . phd d: because there 's a part of the process of the beep file which requires knowing the normalization coefficients . postdoc c: Oh , I see . phd d: And {disfmarker} {vocalsound} So a grad a: That 's not hard to do . Just {disfmarker} it takes {disfmarker} you know , it just takes five minutes rather than , taking a second . phd d: OK phd b: Yeah . grad a: So . I just hand {disfmarker} hard - coded it . phd d: Right , except I don't think that {disfmarker} the c the instructions for doing that was in that directory , right ? I {disfmarker} I didn't see where you had gener grad a: No , but it 's easy enough to do . phd b: What {disfmarker} professor f: But I {disfmarker} but I have a {disfmarker} phd b: Doing the gain ? It 's no problem . Adjusting the gain ? phd d: n Doing th No , getting the coefficients , for each channel . phd b: Yeah , that 's no problem . postdoc c: Know what numbers . phd d: OK . So we just run that one {disfmarker} grad a: There are lots of ways to do it . phd b: We can do that . grad a: I have one program that 'll do it . You can find other programs . phd b: Yeah . I {disfmarker} I used it , so . phd d: We just run that grad a: Yep . phd b: Yeah . phd d: J - sound - stat ? OK . professor f: Yeah . grad a: Minus D , capital D . phd b: Yeah . professor f: But {disfmarker} but {disfmarker} but I {disfmarker} I {disfmarker} I have {pause} another suggestion on that , which is , {vocalsound} since , really what this is , is {disfmarker} is {disfmarker} is trying to in the large , send the right thing to them and there is gonna be this {disfmarker} this post - processing step , um , why don't we check through a bunch of things by sampling it ? phd d: Mm - hmm . professor f: Right ? In other words , rather than , um , uh , saying we 're gonna listen to everything {disfmarker} grad a: I didn't mean listen to everything , I meant , just see if they 're any good . professor f: Yeah . So y you do a bunch of meetings , you listen to {disfmarker} to a little bit here and there , phd d: Yeah . professor f: if it sounds like it 's almost always right and there 's not any big problem you send it to them . phd d: Send it to them . phd b: Yeah . phd d: OK . professor f: And , you know , then they 'll send us back what we {disfmarker} w what {disfmarker} what they send back to us , postdoc c: Oh , that 'd be great . professor f: and we 'll {disfmarker} we 'll fix things up and {vocalsound} some meetings will cost more time to fix up than others . grad a: We should {disfmarker} Yeah . phd b: Yeah . grad a: And we should just double - check with Brian on a few simple conventions on how they should mark things . phd b: Sure . phd d: OK . When they {disfmarker} when there 's either no speech in there , phd b: Yeah . Yeah . phd d: or {vocalsound} something they don't understand , postdoc c: Yeah . Mm - hmm . phd d: things like that . grad a: Yeah , cuz @ @ uh what I had originally said to Brian was well they 'll have to mark , when they can't distinguish between the foreground and background , professor f: Yeah . grad a: because I thought that was gonna be the most prevalent . But if we send them without editing , then we 're also gonna hafta have m uh , notations for words that are cut off , phd d: Mm - hmm . phd b: Yeah . phd d: Mm - hmm . grad a: and other sorts of , uh , acoustic problems . phd b: Yeah . postdoc c: They do already . phd d: And they may just guess at what those cut - off words are , postdoc c: Yeah . phd d: but w I mean we 're gonna adjust {disfmarker} everything when we come back {disfmarker} grad a: But what {disfmarker} what we would like them to do is be conservative so that they should only write down the transcript if they 're sure . phd b: Yeah . grad a: And otherwise they should mark it so that we can check . phd b: Mark it . Sure . Yeah . Yeah . phd d: Mm - hmm . postdoc c: Well , we have the unintelligibility {pause} convention . grad a: Mm - hmm . postdoc c: And actually they have one also , grad a: Right . postdoc c: which {disfmarker} professor f: i Can I maybe have {disfmarker} have an order of {disfmarker} it 's probably in your paper that I haven't looked at lately , but {disfmarker} postdoc c: Certainty . professor f: Uh , an order of magnitude notion of {disfmarker} of how {disfmarker} on a good meeting , how often uh , do you get segments that come in the middle of words and so forth , and uh {disfmarker} in a bad meeting how {vocalsound} often ? phd b: Uh . postdoc c: Was is it in a {disfmarker} in a {disfmarker} what {disfmarker} what is the t professor f: Well he 's saying , you know , that the {disfmarker} the EDU meeting was a good {disfmarker} good meeting , postdoc c: In a good meeting , what ? phd b: Yeah . postdoc c: Yeah . professor f: right ? postdoc c: Oh I see , professor f: Uh , and so {disfmarker} so {disfmarker} so it was almost {disfmarker} it was almost always doing the right thing . postdoc c: the characteristics . professor f: So I wanted to get some sense of what {disfmarker} what almost always meant . And then , uh in a bad meeting , {vocalsound} or p some meetings where he said oh he 's had some problems , what does that mean ? postdoc c: Uh - huh . OK . professor f: So I mean does one of the does it mean one percent and ten percent ? Or does it mean {vocalsound} five percent and fifty percent ? postdoc c: OK . professor f: Uh {disfmarker} phd b: So {disfmarker} professor f: Or {disfmarker} Maybe percentage isn't the right word , postdoc c: Just phd b: Yeah th professor f: but you know how many {disfmarker} how many per minute , or {disfmarker} You know . phd b: Yeah , the {disfmarker} the problem is that , nnn , the numbers Ian gave in the paper is just uh , some frame error rate . So that 's {disfmarker} that 's not really {disfmarker} {vocalsound} What will be effective for {disfmarker} for the transcribers , is {disfmarker} They have to {disfmarker} yeah , in in they have to insure that that 's a real s spurt or something . And {disfmarker} but , {vocalsound} the numbers {disfmarker} Oops . Um {disfmarker} postdoc c: Hmm ! phd b: Let me think . So the {pause} speech {disfmarker} the amount of speech that is missed by the {pause} detector , for a good meeting , I th is around {pause} or under one percent , I would say . But there can be {disfmarker} Yeah . For {disfmarker} yeah , but there can be more {disfmarker} There 's {disfmarker} There 's more amount speech {disfmarker} uh , more amount of {disfmarker} Yeah well , the detector says there is speech , but there is none . So that {disfmarker} that can be a lot when {disfmarker} when it 's really a breathy channel . professor f: But I think that 's less of a problem . phd b: Yeah . professor f: They 'll just listen . It 's just wasted time . phd b: Yeah . professor f: And th and that 's for a good meeting . Now what about in a meeting that you said we 've {disfmarker} you 've had some more trouble with ? phd b: I can't {comment} really {disfmarker} hhh , {comment} {pause} Tsk . {comment} I {pause} don't have really representative numbers , I think . That 's really {disfmarker} I {disfmarker} I did {pause} this on {disfmarker} on four meetings and only five minutes of {disfmarker} of every meet of {disfmarker} of these meetings so , {vocalsound} it 's not {disfmarker} not that representative , but , it 's perhaps , Fff . Um {disfmarker} Yeah , it 's perhaps then {disfmarker} it 's perhaps five percent of something , which s uh the {disfmarker} the frames {disfmarker} speech frames which are {disfmarker} which are missed , but um , I can't {disfmarker} can't really tell . professor f: Right . So I {disfmarker} {vocalsound} So i Sometime , we might wanna go back and look at it more in terms of {vocalsound} how many times is there a spurt that 's {disfmarker} that 's uh , interrupted ? phd b: Yeah . Yeah . Yeah . professor f: Something like that ? postdoc c: The other problem is , that when it {disfmarker} when it uh d i on the breathy ones , where you get {vocalsound} {vocalsound} breathing , uh , inti indicated as speech . professor f: And {disfmarker} phd b: So {disfmarker} postdoc c: And I guess we could just indicate to the transcribers not to {pause} encode that if they {disfmarker} We could still do the beep file . professor f: Yeah again I {disfmarker} I think that that is probably less of a problem because if you 're {disfmarker} if there 's {disfmarker} {vocalsound} If {disfmarker} if a {disfmarker} if a word is {disfmarker} is split , then they might have to listen to it a few times to really understand that they can't quite get it . postdoc c: OK . OK . phd b: But {disfmarker} postdoc c: OK . professor f: Whereas if they listen {nonvocalsound} to it and there 's {disfmarker} don't hear any speech I think they 'd probably just listen to it once . phd b: Yeah . professor f: So there 'd {disfmarker} you 'd think there 'd be a {disfmarker} a factor of three or four in {disfmarker} in , uh , cost function , postdoc c: OK . professor f: you know , between them or something . phd b: Yeah , so {disfmarker} but I think that 's {disfmarker} n that really doesn't happen very often that {disfmarker} that {disfmarker} that a word is cut in the middle or something . That 's {disfmarker} that 's really not {disfmarker} not normal . professor f: So {disfmarker} so what you 're saying is that nearly always what happens when there 's a problem is that {disfmarker} is that uh , there 's {vocalsound} some uh , uh nonspeech that uh {disfmarker} that is b interpreted as speech . phd b: That is marked as speech . Yeah . Yeah . professor f: Well then , we really should just send the stuff . postdoc c: That would be great . professor f: Right ? Because that doesn't do any harm . phd b: Yeah , it 's {disfmarker} professor f: You know , if they {disfmarker} they hear you know , a dog bark and they say what was the word , they {comment} you know , they {disfmarker} phd b: Yeah , I als I {disfmarker} professor f: Ruff ruff ! phd b: Yeah I also thought of {disfmarker} there {disfmarker} there are really some channels where it is almost {comment} um , only bre breathing in it . And to {disfmarker} to re - run 's professor f: Yeah ? phd b: Eh , um . Yeah . I 've got a {disfmarker} a {pause} P - a {pause} method with loops into the cross - correlation with the PZM mike , and then to reject everything which {disfmarker} which seems to be breath . professor f: Uh - huh . phd b: So , I could run this on those breathy channels , and perhaps throw out {disfmarker} grad a: That 's a good idea . postdoc c: Wow , that 's a great idea . professor f: Yeah . But I think {disfmarker} I th Again , I think that sort of {disfmarker} that that would be good , phd b: Yeah . professor f: and what that 'll do is just cut the time a little further . phd b: Yeah . phd d: Mm - hmm . professor f: But I think none of this is stuff that really needs somebody doing these {disfmarker} these uh , uh , explicit markings . phd d: Yeah . postdoc c: Excellent . Oh , I 'd be delighted with that , I {disfmarker} I was very impressed with the {disfmarker} with the result . Yeah . professor f: Yeah , cuz the other thing that was concerning me about it was that it seemed kind of specialized to the EDU meeting , and {disfmarker} and that then when you get a meeting like this or something , phd b: Yeah . professor f: and {disfmarker} {vocalsound} and you have a b a bunch of different dominant speakers postdoc c: Oh yeah , interesting . professor f: you know , how are you gonna handle it . postdoc c: Oh yeah . professor f: Whereas this sounds like a more general solution postdoc c: Oh yeah , I pr I much prefer this , professor f: is {disfmarker} postdoc c: I was just trying to find a way {disfmarker} Cuz I {disfmarker} I don't think the staggered mixed channel is awfully good as a way of handling overlaps . professor f: Yeah . Uh - huh . postdoc c: But {disfmarker} but uh {disfmarker} phd d: Well good . That {disfmarker} that really simplifies thing then . postdoc c: Yeah . phd d: And we can just , you know , get the meeting , process it , put the beeps file , send it off to IBM . postdoc c: Mm - hmm . phd d: You know ? phd b: Yeah . phd d: With very little {pause} work on our side . phd b: Process it , hear into it . I would {disfmarker} phd d: Do what ? phd b: Um , {pause} listen to it , and then {disfmarker} grad a: Or at least sample it . phd b: Yeah . phd d: Well , sample it . phd b: Yeah . phd d: Sample it . professor f: I {disfmarker} I would just use some samples , phd b: Yeah . Yeah . professor f: make sure you don't send them three hours of " bzzz " {comment} or something . phd d: Yeah . phd b: No . phd d: Yeah . Right . phd b: That won't be good . postdoc c: Yeah . phd d: Yeah . Yeah that would be very good . phd b: Yeah . phd d: And then we can you know {disfmarker} professor f: Yeah . phd d: That 'll oughta be a good way to get the pipeline going . postdoc c: Oh , I 'd be delighted . Yeah . phd b: And there 's {disfmarker} there 's one point which I {comment} uh {disfmarker} {vocalsound} yeah , which {disfmarker} which I r {vocalsound} we covered when I {disfmarker} when I r listened to one of the EDU meetings , professor f: Great . phd b: and that 's {vocalsound} that somebody is playing sound from his laptop . grad a: Uh - huh phd b: And i {vocalsound} the speech - nonspeech detector just assigns randomly the speech to {disfmarker} to one of the channels , so . Uh - I haven't - I didn't think of {disfmarker} of s of {vocalsound} this before , grad a: What can you do ? phd b: but what {disfmarker} what shall we do about s things like this ? postdoc c: Well you were suggesting {disfmarker} You suggested maybe just not sending that part of the meeting . grad a: Yep . Mmm . postdoc c: But {disfmarker} phd b: But , sometimes the {disfmarker} {vocalsound} the {disfmarker} the laptop is in the background and some {disfmarker} somebody is {disfmarker} is talking , and , {vocalsound} that 's really a little bit confusing , but {disfmarker} grad a: It 's a little bit confusing . professor f: That 's life . phd b: Yeah . grad a: I mean , {comment} what 're we gonna do ? phd b: Yeah . grad a: Even a hand - transcription would {disfmarker} phd b: OK . postdoc c: Do you {disfmarker} professor f: Yeah . grad a: a hand - transcriber would have trouble with that . phd b: Yeah , grad a: So . phd b: that 's {disfmarker} that 's a second question , " what {disfmarker} what will different transcribers do with {disfmarker} with the laptop sound ? " postdoc c: Would you {disfmarker} would {disfmarker} professor f: What was the l what was the laptop sound ? postdoc c: Yeah , go ahead . professor f: I mean was it speech , phd b: Yeah . professor f: or was it {disfmarker} phd b: It 's speech . professor f: Great . postdoc c: Well , so {disfmarker} I mean {disfmarker} So my standard approach has been if it 's not someone close - miked , then , they don't end up on one of the close - miked channels . They end up on a different channel . And we have any number of channels available , professor f: Uh - huh . phd b: Yeah . postdoc c: I mean it 's an infinite number of channels . phd b: But , postdoc c: So just put them on some other channel . phd b: when thi when this is sent to {disfmarker} to the I M - eh , I B M transcribers , I don't know if {disfmarker} if they can tell that 's really {disfmarker} postdoc c: Yeah , that 's right . grad a: Yeah cuz there will be no channel on which it is foreground . phd b: Yeah . Yeah . grad a: Uh {disfmarker} postdoc c: Well , they have a convention , in their own procedures , {vocalsound} which is for a background {pause} sound . grad a: Right , but , uh , in general I don't think we want them transcribing the background , cuz that would be too much work .  phd b: Yeah . grad a: Right ? For it {disfmarker} because in the overlap sections , then they 'll phd d: Well I don't think Jane 's saying they 're gonna transcribe it , but they 'll just mark it as being {disfmarker} there 's some background stuff there , grad a: But that 's gonna be all over the place . postdoc c: Yeah . phd d: right ? grad a: How w how will they tell the difference between that sort of background and the dormal {disfmarker} normal background of two people talking at once ? phd b: Yeah . postdoc c: Oh , I think {disfmarker} I think it 'd be easy to to say " background laptop " . grad a: How would they know that ? phd d: But wait a minute , why would they treat them differently ? phd b: Yeah . postdoc c: Well because one of them {disfmarker} grad a: Because otherwise it 's gonna be too much work for them to mark it . They 'll be marking it all over the place . phd b: Yeah . postdoc c: Oh , I s background laptop or , background LT {vocalsound} {vocalsound} wouldn't take any time . grad a: Sure , but how are they gonna tell bet the difference between that and two people just talking at the same time ? postdoc c: And {disfmarker} phd b: Yeah . postdoc c: Oh , you can tell . Acoustically , can't you tell ? phd b: It 's really good sound , so {disfmarker} postdoc c: Oh is it ? Oh ! professor f: Well , I mean , isn't there a category something like uh , " sounds for someone for whom there is no i close mike " ? phd b: Yeah that would be very important , grad a: But how do we d how do we do that for the I B M folks ? postdoc c: Yeah . phd b: yeah . grad a: How can they tell that ? phd d: Well we may just have to do it when it gets back here . grad a: Yes , that 's my opinion as well . phd b: Yeah . grad a: So we don't do anything for it {disfmarker} with it . postdoc c: OK . phd d: Yeah . postdoc c: That sounds good . grad a: And they 'll just mark it however they mark it , postdoc c: That sounds good . phd d: Yeah . grad a: and we 'll correct it when it comes back . phd b: So th professor f: Yeah . phd b: there was a category for @ @ {comment} speech . postdoc c: OK . grad a: Yeah , the default . postdoc c: Yeah , s a grad a: No , not default . phd b: OK . postdoc c: Well , as it comes back , we have a uh {disfmarker} when we can use the channelized interface for encoding it , then it 'll be easy for us to handle . phd b: Yeah . postdoc c: But {disfmarker} {vocalsound} but if {disfmarker} if out of context , they can't tell if it 's a channeled speak uh , you know , a close - miked speaker or not , {vocalsound} then that would be confusing to them . phd b: OK . grad a: Right . phd b: OK . postdoc c: I don't know , I {disfmarker} it doesn't {disfmarker} I don't {disfmarker} Either way would be fine with me , I don't really care . professor f: Yeah . So . Shall we uh , do digits and get out of here ? grad a: Yep . postdoc c: I have o I have one question . Do you think we should send the um {disfmarker} that whole meeting to them and not worry about pre - processing it ? professor f: Yes ma ' postdoc c: Or {disfmarker} Uh , what I mean is {vocalsound} we {disfmarker} we should {vocalsound} leave the {vocalsound} part with the audio in the uh , beep file that we send to IBM for that one , or should we {vocalsound} start after the {disfmarker} that part of the meeting is over in what we send . professor f: Which part ? phd b: With {disfmarker} postdoc c: So , the part where they 're using sounds from their {disfmarker} from their laptops . phd b: with the laptop sound , or {disfmarker} ? just {disfmarker} postdoc c: w If we have speech from the laptop should we just uh , excise that from what we send to IBM , or should we {vocalsound} i give it to them and let them do with it what they can ? phd d: I think we should just {disfmarker} it {disfmarker} it 's gonna be too much work if we hafta {vocalsound} worry about that I think . postdoc c: OK , that 'd be nice to have a {disfmarker} a uniform procedure . phd d: Yeah , I think if we just {disfmarker} m send it all to them . you know . grad a: Worry about it when we get back . postdoc c: Good . And see how well they do . phd d: Let {disfmarker} Yeah , worry about it when we get back in . postdoc c: And give them freedom to {disfmarker} {vocalsound} to indicate if it 's just not workable . professor f: Yeah . postdoc c: Yeah , phd d: Yeah . postdoc c: OK , professor f: Yeah . postdoc c: excellent . professor f: Cuz , I wouldn't {disfmarker} don't think we would mind {pause} having that {pause} transcribed , if they did it . grad a: I think {disfmarker} phd d: Yeah , e grad a: As I say , we 'll just have to listen to it and see how horrible it is . postdoc c: Yeah , yeah . phd b: Yeah . grad a: Sample it , rather . postdoc c: OK . Alright . phd b: I think that {disfmarker} that will be a little bit of a problem phd d: Yeah . postdoc c: That 's great . phd b: as it really switches around between {vocalsound} two different channels , I think . grad a: Mm - hmm , and {disfmarker} and they 're very {disfmarker} it 's very audible ? on the close - talking channels ? phd b: What {disfmarker} what I would {disfmarker} Yeah . grad a: Oh well . I mean , it 's the same problem as the lapel mike . professor f: Yeah . phd b: Yeah . grad a: But {disfmarker} postdoc c: Oh , interesting . phd b: Comparable , yeah . professor f: Yeah . phd b: OK . postdoc c: OK , alright . Digits . professor f: Let 's do digits . postdoc c: OK , so we read the transcript number first , right ? grad a: Are we gonna do it altogether or separately ? phd b: So {disfmarker} What time is it ? professor f: Uh , {vocalsound} why don't we do it together , postdoc c: Uh , quarter to four . phd b: Oh , OK . professor f: that 's {disfmarker} that 's a nice fast way to do it . postdoc c: Mm - hmm . professor f: One , two , three , go ! postdoc c: It 's kind of interesting if there 're any more errors in these , {vocalsound} than we had the first set . grad a: Nnn , yeah , I think there probably will be . phd b: Yeah . phd d: Do you guys plug your ears when you do it ? grad a: I do . phd b: No . postdoc c: I usually do . phd d: I do . phd b: I don't . postdoc c: I didn't this time . phd d: You don't ? phd b: No . professor f: I haven't been , phd d: How can you do that ? professor f: no . phd d: I {disfmarker} I {disfmarker} professor f: Uh , concentration . phd b: Perhaps there are {vocalsound} lots of errors in it phd d: Gah ! grad a: Total concentration . Are you guys ready ? phd d: You hate to have your ears plugged ? professor f: Yeah . phd d: Really ?