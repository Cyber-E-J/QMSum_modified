grad e: OK , we 're on . professor b: OK . grad e: So , I mean , everyone who 's on the wireless check that they 're on . phd f: C we {disfmarker} grad g: Alright . postdoc c: I see . Yeah . phd f: Yeah . grad e: OK , our agenda was quite short . professor b: Oh , could you {pause} close the door , maybe ? Yeah . grad e: Sure . Two items , which was , uh , digits and possibly stuff on {disfmarker} on , uh , forced alignment , which Jane said that Liz and Andreas had in information on , professor b:  grad e: but they didn't , phd f: Mm - hmm . professor b: I guess the only other thing , uh , for which I {disfmarker} grad e: so . phd f: We should do that second , because Liz might join us in time for that . grad e: OK . professor b: Um . OK , so there 's digits , alignments , and , um , I guess the other thing , {vocalsound} which I came unprepared for , uh , {vocalsound} is , uh , to dis s s see if there 's anything anybody wants to discuss about the Saturday meeting . grad e: Right . professor b: So . Any {disfmarker} I mean , maybe not . grad e: Digits and alignments . But {disfmarker} professor b: Uh . phd f: Talk about aligning people 's schedules . professor b: Yeah . grad e: Yeah . postdoc c: Mm - hmm . professor b: Yeah . I mean {disfmarker} Right . Yeah , I mean , it was {disfmarker} grad e: Yeah , it 's forced alignment of people 's schedules . phd f: Yeah . phd d: Forced align . phd f: If we 're very {disfmarker} professor b: Yeah . phd f: Yeah . professor b: With {disfmarker} with {disfmarker} whatever it was , a month and a half or something ahead of time , the only time we could find in common {disfmarker} roughly in common , was on a Saturday . phd d: Yeah . professor b: Ugh . grad e: Yep . phd f: It 's pretty sad . professor b: Yeah . phd f: Yeah . postdoc c: Have {disfmarker} Have we thought about having a conference call to include him in more of {disfmarker} {vocalsound} in more of the meeting ? I {disfmarker} I mean , I don't know , if we had the {disfmarker} if we had the telephone on the table {disfmarker} professor b: No . But , h I mean , he probably has to go do something . phd f: No , actually I {disfmarker} I have to {disfmarker} I have to shuttle {pause} kids from various places to various other places . professor b: Right ? postdoc c: I see . OK . professor b: Yeah . phd f: So . And I don't have {disfmarker} and I don't , um , have a cell phone phd d: A cell phone ? phd f: so I can't be having a conference call while driving . professor b: R r right . postdoc c: No . {comment} It 's not good . professor b: So we have to {disfmarker} we {disfmarker} postdoc c: That 's not good . phd f: Plus , it would make for interesting noise {disfmarker} background noise . professor b:  grad e: Yep . phd f: Uh {disfmarker} professor b: So we have to equip him with a {disfmarker} with a {disfmarker} {vocalsound} with a head - mounted , uh , cell phone grad e: Ye - we and we 'd have to force you to read lots and lots of digits , professor b: and {disfmarker} grad e: so it could get real {disfmarker} {vocalsound} real car noise . phd f: Oh , yeah . phd d: Yeah . phd f: Oh , yeah . grad g: Take advantage . phd d: And with the kids in the background . phd f: I 'll let {disfmarker} I 'd let {disfmarker} phd d: Yeah . phd f: I let , uh , my five - year - old have a try at the digits , eh . professor b: Yeah . grad e: So , anyway , I can talk about digits . Um , did everyone get the results or shall I go over them again ? I mean that it was basically {disfmarker} the only thing that was even slightly surprising was that the lapel did so well . Um , and in retrospect that 's not as surprising as maybe i it shouldn't have been as surprising as I {disfmarker} as {disfmarker} as I felt it was . The lapel mike is a very high - quality microphone . And as Morgan pointed out , that there are actually some advantages to it in terms of breath noises and clothes rustling {pause} if no one else is talking . phd d: Yeah . phd f: Exactly . grad e: Um , so , uh {disfmarker} grad g: Mm - hmm . professor b: Well , it 's {disfmarker} Yeah , sort of the bre the breath noises and the mouth clicks and so forth like that , the lapel 's gonna be better on . grad g: It 's g it {disfmarker} phd d: Or the cross - talk . Yeah . professor b: The lapel is typically worse on the {disfmarker} on clothes rustling , but if no one 's rustling their clothes , grad e: Right . I mean , a lot of people are just sort of leaning over and reading the digits , professor b: it 's {disfmarker} it 's {disfmarker} grad e: so it 's {disfmarker} it 's a very different task than sort of the natural . phd d: Yeah . You don't move much during reading digits , I think . professor b: Yeah . grad e: So . professor b: Yeah . grad e: Right . grad g: Probably the fact that it picks up other people 's speakers {disfmarker} other people 's talking is an indication of that it {disfmarker} the fact it is a good microphone . phd d: Yeah . professor b: Right . So in the digits , in most {disfmarker} most cases , there weren't other people talking . grad e: Right . Right . grad g: So . professor b: So . phd f: D do the lapel mikes have any directionality to them ? professor b: There typically don't , no . phd f: Because I {disfmarker} I suppose you could make some that have sort of {disfmarker} that you have to orient towards your mouth , grad e: They have a little bit , phd f: and then it would {disfmarker} grad e: but they 're not noise - cancelling . So , uh {disfmarker} professor b: They 're {disfmarker} they 're intended to be omni - directional . grad e: Right . professor b: And th it 's {disfmarker} and because you don't know how people are gonna put them on , you know . phd f: Mm - hmm . grad e: Right . So , also , Andreas , on that one the {disfmarker} the back part of it should be right against your head . And that will he keep it from flopping aro up and down as much . phd f: It is against my head . grad e: OK . professor b: Yeah . Um . Yeah , we actually talked about this in the , uh , front - end meeting this morning , too . Much the same thing , grad e: Uh - huh . professor b: and {disfmarker} and it was {disfmarker} uh , I mean , there the point of interest to the group was primarily that , um , {vocalsound} the , uh {disfmarker} the system that we had that was based on H T K , that 's used by , you know , {pause} all the participants in Aurora , {vocalsound} was so much worse {vocalsound} than the {disfmarker} than the S R grad e: Everybody . professor b: And the interesting thing is that even though , {vocalsound} yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on , {vocalsound} it 's just not as good as having a {disfmarker} a l very large amount of data and training up a {disfmarker} a {disfmarker} a nice good big {vocalsound} HMM . Um , also you had the adaptation in the SRI system , which we didn't have in this . Um . So . Um . phd f: And we know {disfmarker} Di - did I send you some results without adaptation ? grad e: No . professor b: I s I think Stephane , uh , had seen them . grad e: Or if you did , I didn't include them , cuz it was {disfmarker} professor b: So {disfmarker} phd f: Yeah , I think I did , actually . So there was a significant loss from not doing the adaptation . professor b: Yeah . phd f: Um . A {disfmarker} a {disfmarker} a couple percent or some I mean {disfmarker} Well , I don't know it {disfmarker} Overall {disfmarker} Uh , I {disfmarker} I don't remember , but there was {disfmarker} {nonvocalsound} there was a significant , um , loss or win {comment} from adaptation {disfmarker} with {disfmarker} with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small {disfmarker} like point one percent on the natives {disfmarker} uh , win from doing , um , you know , adaptation to {pause} the recognition hypotheses . And {pause} I tried both means adaptation and means and variances , and the variances added another {disfmarker} or subtracted another point one percent . So , {vocalsound} it 's , um {disfmarker} that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation . grad e: Right . professor b: But I think one thing is that , uh , I would presume {disfmarker} Hav - Have you ever t {vocalsound} Have you ever tried this exact same recognizer out on the actual TI - digits test set ? phd f: This exact same recognizer ? No . professor b: It might be interesting to do that . Cuz my {disfmarker} my {disfmarker} cuz my sense , um {disfmarker} phd f: But {disfmarker} but , I have {disfmarker} I mean , people {disfmarker} people at SRI are actually working on digits . grad e: I bet it would do even slightly better . phd f: I could {disfmarker} and they are using a system that 's , um {disfmarker} you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth , professor b: Mm - hmm . phd f: and I could ask them what they get {pause} on TI - digits . professor b: Yeah , bu although I 'd be {disfmarker} I think it 'd be interesting to just take this exact actual system so that these numbers were comparable phd f: Mm - hmm . professor b: and try it out on TI - digits . phd f: Well , Adam knows how to run it , professor b: Yeah . grad e: Yeah . No problem . phd f: so you just make a f professor b: Yeah . Yeah . Cuz our sense from the other {disfmarker} from the Aurora , uh , task is that {disfmarker} grad e: And try it with TI - digits ? phd f: Mm - hmm . professor b: I mean , cuz we were getting sub one percent {vocalsound} numbers on TI - digits also with the tandem thing . phd f: Mm - hmm . professor b: So , {vocalsound} one {disfmarker} so there were a number of things we noted from this . phd f: Mmm . professor b: One is , yeah , the SRI system is a lot better than the HTK {disfmarker} phd f: Hmm . professor b: this , you know , very limited training HTK system . phd f: Mm - hmm . professor b: Uh , but the other is that , um , the digits {vocalsound} recorded here in this room with these close mikes , i uh , are actually a lot harder than the {pause} studio - recording TI - digits . I think , you know , one reason for that , uh , might be that there 's still {disfmarker} even though it 's close - talking , there still is some noise and some room acoustics . phd f: Mm - hmm . Mm - hmm . professor b: And another might be that , uh , I 'd {disfmarker} I would presume that in the studio , uh , uh , situation recording read speech that if somebody did something a little funny or n pronounced something a little funny or made a little {disfmarker} that they didn't include it , grad e: They didn't include it . professor b: they made them do it again . grad e: Whereas , I took out {pause} the ones that I noticed that were blatant {disfmarker} that were correctable . professor b: Mmm . Yeah . grad e: So that , if someone just read the wrong digit , I corrected it . professor b: Yeah . grad e: And then there was another one where Jose couldn't tell whether {disfmarker} I couldn't tell whether he was saying zero or six . And I asked him and he couldn't tell either . grad i: Hmm . grad e: So I just cut it out . professor b: Yeah . grad e: You know , so I just e edited out the first , i uh , word of the utterance . Um , so there 's a little bit of correction but it 's definitely not as clean as TI - digits . So my expectations is TI - digits would , especially {disfmarker} I think TI - digits is all {pause} American English . professor b: Mm - hmm . grad e: Right ? So it would probably do even a little better still on the SRI system , but we could give it a try . phd f: Well . But {pause} remember , we 're using a telephone bandwidth front - end here , uh , on this , uh {disfmarker} on this SRI system , so , {vocalsound} um , I was {disfmarker} I thought that maybe that 's actually a good thing because it {disfmarker} it gets rid of some of the {disfmarker} uh , the noises , um , you know , in the {disfmarker} the {disfmarker} below and above the {disfmarker} um , the , you know , speech bandwidth professor b: Mm - hmm . Mm - hmm . phd f: and , um , I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . And of course we can't do that or {disfmarker} grad e: Wha - what 's TI - digits ? I thought t professor b: It 's wide - band , yeah . It 's {disfmarker} in {disfmarker} in fact , we looked it up grad e: It is wide - band . OK . professor b: and it was actually twenty kilohertz sampling . grad e: Oh , that 's right . I {disfmarker} I did look that up . phd f: Mm - hmm . grad e: I couldn't remember whether that was TI - digits or one of the other digit tasks . professor b: Yeah . phd f: Right . But {disfmarker} but , I would {disfmarker} Yeah . It 's {disfmarker} it 's easy enough to try , just run it on {disfmarker} professor b: Yeah . grad e: Mm - hmm . professor b: See w grad e: So , Morgan , you 're getting a little breath noise . phd f: Now , eh , does {disfmarker} grad e: You might wanna move the mike down a little bit . phd f: one {disfmarker} one issue {disfmarker} one issue with {disfmarker} with that is that {vocalsound} um , the system has this , uh , notion of a speaker to {disfmarker} which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL {pause} estimation . professor b: Mm - hmm . phd f: So {disfmarker} grad e: Yeah , I noticed the script that extracted it . phd f: Do y ? Is {disfmarker} ? So does {disfmarker} so th so does {disfmarker} does , um , {vocalsound} the TI - digits database have speakers that are known ? grad e: Yep . Yep . phd f: And is there {disfmarker} is there enough data or a comparable {disfmarker} comparable amount of data to {disfmarker} to what we have in our recordings here ? grad e: That I don't know . I don't know . I don't know how many speakers there are , professor b: Yeah . grad e: and {disfmarker} and how many speakers per utterance . phd f: OK . professor b: Well , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would {disfmarker} phd f: Right . Uh , but I 'm not so much worried about the adaptation , actually , than {disfmarker} than the , um , {vocalsound} um {disfmarker} the , uh , VTL estimation . grad e: Right . phd f: If you have only one utterance per speaker you might actually screw up on estimating the {disfmarker} the warping , uh , factor . So , um {disfmarker} grad e: I strongly suspect that they have more speakers than we do . So , uh {disfmarker} phd f: Right . But it 's not the amount of speakers , it 's the num it 's the amount of data per speaker . grad e: Right . So we {disfmarker} we could probably do an extraction that was roughly equivalent . phd f: Right . Right . grad e: Um . phd f: So {disfmarker} grad e: So , although I {disfmarker} I sort of know how to run it , there are a little {disfmarker} a f few details here and there that I 'll have to {pause} dig out . phd f: OK . The key {disfmarker} So th the system actually extracts the speaker ID from the waveform names . grad e: Right . I saw that . phd f: And there 's a {disfmarker} there 's a script {disfmarker} and that is actually all in one script . So there 's this one script that parses waveform names and extracts things like the , um , speaker , uh , ID or something that can stand in as a speaker ID . So , we might have to modify that script to recognize the , um , speakers , {vocalsound} um , in the {disfmarker} in the , uh , um , {vocalsound} TI - digits {pause} database . grad e: Right . Right . And that , uh {disfmarker} phd f: Or you can fake {disfmarker} you can fake {pause} names for these waveforms that resemble the names that we use here for the {disfmarker} for the meetings . grad e: Right . phd f: That would be the , sort of {disfmarker} probably the safest way to do {disfmarker} grad e: I might have to do that anyway to {disfmarker} to do {disfmarker} because we may have to do an extract to get the {pause} amount of data per speaker about right . phd f: Uh - huh . grad e: The other thing is , isn't TI - digits isolated digits ? phd f: Right . grad e: Or is that another one ? I 'm {disfmarker} I looked through a bunch of the digits t corp corpora , and now they 're all blurring . professor b: Mm - hmm . grad e: Cuz one of them was literally people reading a single digit . And then others were connected digits . professor b: Yeah . Most of TI - digits is connected digits , I think . grad e: OK . professor b: The {disfmarker} I mean , we had a Bellcore corpus that we were using . It was {disfmarker} {vocalsound} that 's {disfmarker} that was isolated digits . grad e: Maybe it 's the Bell Gram . Bell Digits . Alright . professor b: Um . phd f: By the way , I think we can improve these numbers if we care to compr improve them {vocalsound} by , um , {vocalsound} not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting . grad e: Yep . phd f: Because that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that should really improve things , um , further . And then you use those adapted models , which are not speaker adapted but sort of acous you know , channel adapted {disfmarker} grad e: Channel adapted . phd f: use that as the starting models for your speaker adaptation . professor b: Yeah . {vocalsound} But the thing is , uh {disfmarker} I mean , w when you {disfmarker} it depends whether you 're ju were just using this as a {disfmarker} {vocalsound} a starter task for {disfmarker} you know , to get things going for conversational or if we 're really interested i in connected digits . And I {disfmarker} I think the answer is both . And for {disfmarker} for connected digits over the telephone you don't actually want to put a whole lot of effort into adaptation phd f: Well , I don't know . professor b: because {vocalsound} somebody {pause} gets on the phone and says a number and then you just want it . You don't {disfmarker} don't , uh {disfmarker} postdoc c: This is {disfmarker} this {disfmarker} that one 's better . phd f: Right . postdoc c: Mm - hmm . phd f: Um , but , you know , I {disfmarker} uh , my impression was that you were actually interested in the far - field microphone , uh , problem , I mean . So , you want to {disfmarker} you want to {disfmarker} That 's the obvious thing to try . postdoc c: Oh . Oh . professor b: Right . phd f: Right ? Then , eh {disfmarker} because you {disfmarker} you don't have any {disfmarker} postdoc c: Yeah . phd f: That 's where the most m acoustic mismatch is between the currently used models and the {disfmarker} the r the set up here . professor b: Right . phd f: So . professor b: Yeah . So that 'd be anoth another interesting data point . phd f: Mm - hmm . professor b: I mean , I {disfmarker} I guess I 'm saying I don't know if we 'd want to do that as the {disfmarker} as {disfmarker} phd d: Other way . grad e: Other way . Liz {disfmarker} phd a: Now you 're all watching me . grad e: It f it clips over your ears . phd a: Alright . This way . grad e: There you go . postdoc c: If you have a strong fe if you have a strong preference , you could use this . phd a: You 're all watching . This is terrible . postdoc c: It 's just we {disfmarker} we think it has some spikes . So , uh , we {disfmarker} we didn't use that one . phd a: I 'll get it . postdoc c: But you could if you want . professor b: Yeah . At any rate , I don't know if w postdoc c: I don't know . And Andre - Andreas , your {disfmarker} your microphone 's a little bit low . professor b: Yeah . phd f: It is ? professor b: I don't know if we wanna use that as the {disfmarker} postdoc c: Yeah . grad e: Uh , it pivots . phd f: Uh . postdoc c: So if you see the picture grad e: It {disfmarker} it {disfmarker} like this . phd f: I I {disfmarker} postdoc c: and then you have to scr phd f: I {disfmarker} I already adjusted this a number of times . grad e: Eh . phd f: I {disfmarker} I grad e: Yeah , I think these mikes are not working as well as I would like . phd f: can't quite seem to {disfmarker} Yeah , I think this contraption around your head is not {pause} working so well . professor b: Too many adju too many adjustments . Yeah . Anyway , what I was saying is that I {disfmarker} I think I probably wouldn't want to see that as sort of like the norm , that we compared all things to . postdoc c: That looks good . Yeah . professor b: To , uh , the {disfmarker} to have {disfmarker} have all this ad all this , uh , adaptation . But I think it 's an important data point , if you 're {disfmarker} if {disfmarker} Yeah . phd f: Right . professor b: Um . The other thing that {disfmarker} that , uh {disfmarker} of course , what Barry was looking at was {disfmarker} was just that , the near versus far . And , yeah , the adaptation would get {vocalsound} th some of that . phd f: Mm - hmm . professor b: But , I think even {disfmarker} even if there was , uh , only a factor of two or something , like I was saying in the email , I think that 's {disfmarker} {vocalsound} that 's a big factor . So {disfmarker} phd f: Mm - hmm . professor b: N grad e: Liz , you could also just use the other mike if you 're having problems with that one . postdoc c: Well . phd a: OK . postdoc c: Yeah . This would be OK . We {disfmarker} we {disfmarker} we think that this has spikes on it , phd a: It 's this thing 's {disfmarker} This is too big for my head . postdoc c: so it 's not as good acoustically , phd f: Yeah , basically your ears are too big . postdoc c: but {disfmarker} phd f: I mean , mine are too . E th everybody 's ears are too big for these things . phd a: No , my {disfmarker} my {disfmarker} But this is too big for my head . So , I mean , {comment} {comment} it doesn't {disfmarker} you know , it 's sit phd f: Uh {disfmarker} postdoc c: Well , if you 'd rather have this one then it 's {disfmarker} phd a: OK . professor b: Yeah . grad e: Oh , well . professor b: It 's {pause} great . grad e: So the {disfmarker} To get that , uh , pivoted this way , it pivots like this . phd a: No this way . Yeah . grad e: Yeah . There you go . postdoc c: And there 's a screw that you can tighten . grad e: And then it {disfmarker} phd a: Right . grad e: Right . phd a: I already {pause} tried to get it close . postdoc c: Good . grad e: So if it doesn't bounce around too much , that 's actually good placement . phd a: OK . postdoc c: That looks good . grad e: But it looks like it 's gonna bounce a lot . professor b: So , where were we ? Uh {disfmarker} {vocalsound} Yeah . postdoc c: Yeah . grad e: Digits . Adaptation . professor b: Uh , adaptation , non - adaptation , um , factor of two , um {disfmarker} Oh , yeah . I know what I was go w phd f: What k u By the way , wh what factor of two did you {disfmarker} ? professor b: Oh , no , no . phd f: I mean {disfmarker} professor b: It 's tha that {disfmarker} that we were saying , you know , well is {disfmarker} how much worse is far than near , you know . phd f: Oh , th OK . professor b: And I mean it depends on which one you 're looking at , phd f: That factor of two . professor b: but for the everybody , it 's {vocalsound} little under a factor or two . phd f: Mm - hmm . professor b: Yeah . I {disfmarker} I know what I was thinking was that maybe , uh , i i we could actually t t try at least looking at , uh , some of the {disfmarker} the large vocabulary speech from a far microphone , at least from the good one . phd f: Mm - hmm . professor b: I mean , before I thought we 'd get , you know , a hundred and fifty percent error or something , but if {disfmarker} {vocalsound} if , uh {disfmarker} if we 're getting thirty - five , forty percent or something , {vocalsound} u um {disfmarker} phd f: Mm - hmm . phd a: Actually if you run , though , on a close - talking mike over the whole meeting , during all those silences , you get , like , four hundred percent word error . professor b: Mm - hmm . Right . I understand . But doing the same kind of limited thing {disfmarker} phd a: Or {disfmarker} or some high number . professor b: Yeah , sure . Get all these insertions . But I 'm saying if you do the same kind of limited thing {vocalsound} as people have done in Switchboard evaluations or as {disfmarker} a phd a: Yeah . Where you know who the speaker is and there 's no overlap ? And you do just the far - field for those regions ? professor b: Yeah . Yeah . The same sort of numbers that we got those graphs from . Right ? grad e: Could we do exactly the same thing that we 're doing now , but do it with a far - field mike ? professor b: Yeah , do it with one of {disfmarker} on grad e: Cuz we extract the times from the near - field mike , but you use the acoustics from the far - field mike . phd a: Right . I understand that . I just meant that {disfmarker} so you have {pause} three choices . There 's , um {disfmarker} You can use times where that person is talking only from the transcripts but the segmentations were {disfmarker} were synchronized . Or you can do a forced alignment on the close - talking to determine that , the you know , within this segment , these really were the times that this person was talking and elsewhere in the segment other people are overlapping and just front - end those pieces . Or you can run it on the whole data , which is {disfmarker} which is , you know , a {disfmarker} professor b: But {disfmarker} but {disfmarker} but how did we get the {disfmarker} how did we determine the links , uh , that we 're testing on in the stuff we reported ? phd a: In the H L T paper we took {pause} segments that are channel {disfmarker} time - aligned , which is now h being changed in the transcription process , which is good , and we took cases where the transcribers said there was only one person talking here , because no one else had time {disfmarker} any words in that segment and called that " non - overlap " . professor b: And tha And that 's what we were getting those numbers from . phd a: Yes . Tho - good {disfmarker} the good numbers . professor b: Right . phd a: The bad numbers were from {pause} the segments where there was overlap . professor b: Well , we could start with the good ones . phd a: Yeah . professor b: But anyway {disfmarker} so I think that we should try it once with {vocalsound} the same conditions that were used to create those , and in those same segments just use one of the P Z phd a: Right . So we {disfmarker} we can do that . Yeah . professor b: And then , you know , I mean , the thing is if we were getting , uh {disfmarker} what , thirty - five , forty percent , something like that on {disfmarker} on that particular set , uh , does it go to seventy or eighty ? phd a: Right . professor b: Or , does it use up so much memory we can't decode it ? phd a: It might also depend on which speaker th it is and how close they are to the PZM ? professor b: Uh {disfmarker} phd a: I don't know how different they are from each other . phd f: You want to probably choose the PZM channel that is closest to the speaker . phd a: To be best {disfmarker} phd d: Yeah . grad e: For this particular digit ones , I just picked that one . phd a: f professor b: Well {disfmarker} phd a: OK . So we would then use that one , too , grad e: So {disfmarker} phd f: Oh , OK . professor b: This is kind of central . phd a: or {disfmarker} ? professor b: You know , it 's {disfmarker} so i but I would {disfmarker} I 'd pick that one . It 'll be less good for some people than for other , but I {disfmarker} I 'd like to see it on the same {disfmarker} exact same data set that {disfmarker} that we did the other thing on . grad e: Actually {disfmarker} I sh actually should 've picked a different one , professor b: Right ? grad e: because {pause} that could be why the PDA is worse . Because it 's further away from most of the people reading digits . phd d: It 's further away . Yeah . Yeah . professor b: That 's probably one of the reasons . postdoc c: Hmm . Mm - hmm . phd a: Well , yeah . You could look at , I guess , that PZM or something . grad e: Yep . professor b: But the other is , it 's very , uh {disfmarker} I mean , even though there 's {disfmarker} I 'm sure the f f the {disfmarker} the SRI , uh , front - end has some kind of pre - emphasis , it 's {disfmarker} it 's , uh {disfmarker} {vocalsound} still , th it 's picking up lots of low - frequency energy . phd f: Mm - hmm . professor b: So , even discriminating against it , I 'm sure some of it 's getting through . Um . But , yeah , you 're right . Prob - a part of it is just the distance . phd a: And aren't these pretty bad microphones ? grad e: Yep . phd a: I mean {disfmarker} professor b: Well , they 're bad . But , I mean , if you listen to it , it sounds OK . You know ? u Yeah . grad e: Yeah . When you listen to it , uh , the PZM and the PDA {disfmarker} Yeah , th the PDA has higher sound floor but not by a lot . It 's really pretty {disfmarker} uh , pretty much the same . phd a: I just remember you saying you got them to be cheap on purpose . Cheap in terms of their quality . So . professor b: Well , they 're {pause} twenty - five cents or so . grad e: Th - we wanted them to be {disfmarker} to be typical of what would be in a PDA . professor b: Yeah . phd a: Mm - hmm . grad e: So they are {disfmarker} they 're not the PZM three hundred dollar type . They 're the twenty - five cent , professor b: Yeah . grad e: buy them in packs of thousand type . phd a: I see . professor b: But , I mean , the thing is people use those little mikes for everything because they 're really not bad . grad e: Everything . phd a: Mm - hmm . professor b: I mean , if you 're not {vocalsound} doing something ridiculous like feeding it to a speech recognizer , they {disfmarker} they {disfmarker} {vocalsound} they {disfmarker} you know , you can hear the sou hear the sounds just fine . phd a: Right . professor b: You know , it 's {disfmarker} They {disfmarker} I mean , i it 's more or less the same principles as these other mikes are built under , it 's just that {pause} there 's less quality control . They just , you know , churn them out and don't check them . Um . So . So that was {disfmarker} Yeah . So that was i interesting result . So like I said , the front - end guys are very much interested in {disfmarker} in this is as {disfmarker} as well and phd f: So {disfmarker} so , but where is this now ? I mean , what 's {disfmarker} where do we go from here ? grad e: Yeah . That was gonna be my question . phd f: I mean , we {disfmarker} so we have a {disfmarker} we have a {disfmarker} a system that works pretty well but it 's not , you know , the system that people here are used to using {disfmarker} to working with . professor b: Well , I think what we wanna do is we want to {disfmarker} eh , phd f: So what {disfmarker} what do we do now ? professor b: and we 've talked about this in other {pause} contexts {disfmarker} we want to {vocalsound} have the ability to feed it different features . phd f: Mm - hmm . professor b: And then , um , {vocalsound} from the point of view of the front - end research , it would be s uh , substituting for HTK . phd f: OK . OK . professor b: I think that 's the key thing . And then if we can feed it different features , then we can try all the different things that we 're trying there . phd f: OK . Alright . professor b: And then , um , uh , also Dave is {disfmarker} is thinking about using the data in different ways , uh , to {vocalsound} um , uh , explicitly work on reverberation phd f: Mm - hmm . professor b: starting with some techniques that some other people have {pause} found somewhat useful , and {disfmarker} Yeah . phd f: OK . So {disfmarker} so the key {pause} thing that 's missing here is basically the ability to feed , you know , other features {vocalsound} i into the recognizer professor b: Right . phd f: and also then to train the system . professor b: Right . phd f: OK . And , uh , es I don't know when Chuck will be back but that 's exactly what he {disfmarker} he 's gonna {disfmarker} professor b: H h He 's {disfmarker} he 's sort of back , but he drove for fourteen hours an and wasn't gonna make it in today . phd f: Oh , OK . So , I think that 's one of the things that he said he would be working on . Um . grad e: Yeah . phd f: Just sort of t to make sure that {pause} we can do that professor b: Yeah . phd f: and {disfmarker} Um . professor b: Right . phd f: It 's {disfmarker} uh , I mean , the {disfmarker} the front - end is f i tha that 's in the SRI recognizer is very nice in that it does a lot of things on the fly but it unfortunately {pause} is not {pause} designed and , um {disfmarker} {vocalsound} like the , uh , ICSI system is , where you can feed it from a pipeline of {disfmarker} of the command . So , the {disfmarker} what that means probably for the foreseeable future is that you have to , uh , dump out , um {disfmarker} you know , if you want to use some new features , you have to dump them into individual files and {pause} give those files to the recognizer . grad e: We do {disfmarker} we tend to do that anyway . phd f: OK . grad e: Oh . So , although you {disfmarker} you can pipe it as well , we tend to do it that way because that way you can concentrate on one block and not keep re - doing it over and over . phd f: Oh , OK . professor b: Yeah . phd f: Alright . professor b: Yeah . So I 've {disfmarker} I {disfmarker} grad e: So tha that 's exactly what the P - file {pause} is for . professor b: Yeah . phd f: Yeah , the {disfmarker} the {disfmarker} the cumbersome thing is {disfmarker} is , um {disfmarker} is that you actually have to dump out little {disfmarker} little files . phd a: Uh {disfmarker} phd f: So for each segment that you want to recognize {vocalsound} you have to {pause} dump out {pause} a separate file . grad e: Uh - huh . phd f: Just like i th like th as if there were these waveform segments , but instead you have sort of feature file segments . But , you know {disfmarker} So . professor b: Cool . OK . So the s the {disfmarker} the next thing we had on the agenda was something about alignments ? phd a: Oh . Yes , we have {disfmarker} I don't know , did you wanna talk about it , or {disfmarker} ? I can give a {disfmarker} I was just telling this to Jane and {disfmarker} and {disfmarker} W we {disfmarker} we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors {pause} that were occurring and um , some of the errors occurring very frequently are just things like the first word being moved to as early as possible in the recognition , which is a um , I think was both a {disfmarker} a pruning {pause} problem and possibly a problem with needing constraints on word locations . And so we tried both of these st things . We tried saying {disfmarker} I don't know , I got this {vocalsound} whacky idea that {disfmarker} just from looking at the data , that when people talk {pause} their words are usually chunked together . It 's not that they say one word and then there 's a bunch of words together . They 're {comment} might say one word and then another word far away if they were doing just backchannels ? But in general , if there 's , like , five or six words and one word 's far away from it , that 's probably wrong on average . So , um {disfmarker} And then also , ca the pruning , of course , was too {disfmarker} too severe . phd f: So that 's actually interesting . The pruning was the same value that we used for recognition . And we had lowered that {disfmarker} we had used tighter pruning after Liz ran some experiments showing that , you know , it runs slower and there 's no real difference in {disfmarker} phd a: Actually it was better with {disfmarker} slightly better or about th grad e: No gain . phd a: it was the same with tighter pruning . phd f: Right . So for free recognition , this {disfmarker} the lower pruning value is better . phd a: It 's probably cuz the recognition 's just bad en at a point where it 's bad enough that {disfmarker} that you don't lose anything . phd f: You {disfmarker} Correct . Right . Um , but it turned out for {disfmarker} for {disfmarker} to get accurate alignments it was really important to open up the pruning significantly . phd a: Right . professor b: Hmm . phd f: Um {pause} because otherwise it would sort of do greedy alignment , um , in regions where there was no real speech yet from the foreground speaker . professor b: Mm - hmm . phd f: Um , {vocalsound} so that was one big factor that helped improve things and then the other thing was that , you know , as Liz said the {disfmarker} we f enforce the fact that , uh , the foreground speech has to be continuous . It cannot be {disfmarker} you cannot have a background speech hypothesis in the middle of the foreground speech . You can only have background speech at the beginning and the end . phd a: Yeah . I mean , yeah , it isn't always true , and I think what we really want is some clever way to do this , where , um , you know , from the data or from maybe some hand - corrected alignments from transcribers that things like words that do occur just by themselves {pause} a alone , like backchannels or something that we did allow to have background speech around it {disfmarker} phd d: Yeah . phd a: those would be able to do that , postdoc c: Sorry . phd a: but the rest would be constrained . So , I think we have a version that 's pretty good for the native speakers . I don't know yet about the non - native speakers . And , um , we basically also made noise models for the different {disfmarker} sort of grouped some of the {pause} mouth noises together . Um , so , and then there 's a background speech model . And we also {disfmarker} There was some neat {disfmarker} or , interesting cases , like there 's one meeting where , {vocalsound} um , Jose 's giving a presentation and he 's talking about , um , the word " mixed {pause} signal " and someone didn't understand , uh , that you were saying " mixed " {disfmarker} I think , Morgan . And so your speech - ch was s saying something about mixed signal . phd h: Yeah , yeah . phd a: And the next turn was a lot of people saying " mixed " , like " he means mixed signal " or " I think it 's mixed " . And the word " mixed " in this segment occurs , like , a bunch of times . phd h: Sh phd a: And Chuck 's on the lapel here , and he also says " mixed " but it 's at the last one , and of course the aligner th aligns it everywhere else to everybody else 's " mixed " , phd h: Yeah . phd a: cuz there 's no adaptation yet . So there 's {disfmarker} {vocalsound} I think there 's some issues about {disfmarker} u We probably want to adapt at least the foreground speaker . But , I guess Andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . Like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker . phd f: Oh {disfmarker} phd d: Yeah . phd a: So there 's some things there , phd h: Oh . phd a: especially when you get lots of the same words , uh , occurring in the {disfmarker} phd f: Well , the {disfmarker} I {disfmarker} I think you can do better by {vocalsound} uh , cloning {disfmarker} so we have a reject phone . And you {disfmarker} and what we wanted to try with {disfmarker} you know , once we have this paper written and have a little more time , {vocalsound} uh , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , like fragments and stuff , and the other copy would be adapted to the background speaker . phd a: Right . I mean , in general we actually {disfmarker} phd f: And {disfmarker} phd a: Right now the words like {pause} partial words are {pause} reject models and you normally allow those to match to any word . phd f: Mm - hmm . phd a: But then the background speech was also a reject model , and so this constraint of not allowing rejects in between {disfmarker} you know , it needs to differentiate between the two . So just sort of working through a bunch of debugging kinds of issues . phd f: Right . phd a: And another one is turns , like people starting with {vocalsound} " well I think " and someone else is {pause} " well how about " . So the word " well " is in this {disfmarker} in this {pause} segment multiple times , and as soon as it occurs usually the aligner will try to align it to the first person who says it . But then that constraint of sort of {disfmarker} uh , proximity constraint will push it over to the person who really said it in general . grad e: Is the proximity constraint a hard constraint , or did you do some sort of probabilistic weighting distance , or {disfmarker} ? phd f: We {disfmarker} we didn't {disfmarker} phd a: Right now it 's a kluge . phd f: No . We {disfmarker} w OK . We {disfmarker} it 's straightforward to actually just have a {disfmarker} a penalty that doesn't completely disallows it but discourages it . But , um , we just didn't have time to play with , you know , tuning yet another {disfmarker} yet another parameter . grad e: The ve level . Yeah . phd a: Yeah . phd f: And really the reason we can't do it is just that we don't have a {disfmarker} we don't have ground truth for these . So , {vocalsound} we would need a hand - marked , um , {vocalsound} word - level alignments or at least sort of the boundaries of the speech betw you know , between the speakers . Um , and then use that as a reference and tune the parameters of the {disfmarker} of the model , uh , to op to get the best {pause} performance . phd a: Yeah . professor b: G given {disfmarker} I {disfmarker} I mean , I wa I wa I was gonna ask you anyway , uh , how you assessed that things were better . phd f: Mm - hmm . phd a: I looked at them . I spent two days {disfmarker} um , in Waves {disfmarker} professor b: OK . phd a: Oh , it was painful because {vocalsound} the thing is , you know the alignments share a lot in common , so {disfmarker} And you 're {disfmarker} yo you 're looking at these segments where there 's a lot of speech . I mean , a lot of them have a lot of words . Not by every speaker professor b: Yeah . phd a: but by some speaker there 's a lot of words . No , not {disfmarker} professor b: Yeah . phd a: I mean that if you look at the individual segments from just one person you don't see a lot of words , phd h: Ju professor b: Yeah . phd a: but altogether you 'll see a lot of words up there . professor b: Yeah . phd f: Mm - hmm . phd d: Yeah . phd a: And so the reject is also mapping and pauses {disfmarker} So I looked at them all in Waves and just lined up all the alignments , and , at first it sort of looked like a mess and then the more I looked at it , I thought " OK , well it 's moving these words leftward and {disfmarker} " You know , it wasn't that bad . It was just doing certain things wrong . So {disfmarker} But , I don't , you know , have time to l {comment} to look at all of them and it would be really useful to have , like , a {disfmarker} a transcriber who could use Waves , um , just mark , like , the beginning and end of the foreground speaker 's real words {disfmarker} like , the beginning of the first word , the end of the last word {disfmarker} and then we could , you know , do some adjustments . postdoc c: Yeah . I {disfmarker} OK . I have to ask you something , is i does it have to be Waves ? Because if we could benefit from what you did , incorporate that into the present transcripts , {comment} that would help . phd f: No . postdoc c: And then , um , the other thing is , I believe that I did hand So . One of these transcripts was gone over by a transcriber and then I hand - marked it myself so that we do have , uh , the beginning and ending of individual utterances . Um , I didn't do it word level , phd f: Mm - hmm . postdoc c: but {disfmarker} but in terms {disfmarker} phd a: Mm - hmm . postdoc c: So I {disfmarker} so for {disfmarker} for one of the N S A groups . And also I went back to the original one that I first transcribed and {disfmarker} and did it w uh , w uh , utterance by utterance for that particular one . So I think you do have {disfmarker} if that 's a sufficient unit , I think that you do have hand - marking for that . But it 'd be wonderful to be able to {vocalsound} benefit from your Waves stuff . phd a: Mm - hmm . phd f: We don't care what {disfmarker} what tool you use . phd a: Yeah . I mean , if {disfmarker} if you can , um {disfmarker} if you wanna {disfmarker} postdoc c: OK . I used it in Transcriber phd f: U uh {disfmarker} postdoc c: and it 's {disfmarker} it 's in the {disfmarker} phd a: well , Jane and I were {disfmarker} just in terms of the tool , talking about this . I guess Sue had had some {pause} reactions . You know , interface - wise if you 're looking at speech , you wanna be able to know really where the words are . And so , {vocalsound} we can give you some examples of sort of what this output looks like , postdoc c: Yeah , that 's right . Middle of the word , or {disfmarker} phd a: um , and see if you can in maybe incorporate it into the Transcriber tool some way , or {disfmarker} postdoc c: Well , I th I 'm thinking just ch e e incorporating it into the representation . phd a: Um . postdoc c: I mean , if it 's {disfmarker} if it 's {disfmarker} phd a: You mean like {disfmarker} Yeah , word start insights . postdoc c: if you have start points , if you have , like , time tags , phd a: Right . postdoc c: which is what I assume . Isn't that what {disfmarker} what you {disfmarker} ? Well , see , Adam would be {disfmarker} phd f: Yeah , whatever you use . phd a: Yeah . phd f: I mean , we convert it to this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And {disfmarker} and then that 's the {disfmarker} that 's what the {disfmarker} grad e: I think Transcriber , uh , outputs CTM . postdoc c: If it {disfmarker} ? OK . phd a: Yeah . postdoc c: So you would know this more than I would . grad e: I think so . phd a: So , I mean {disfmarker} postdoc c: It seems like she {disfmarker} if she 's g if she 's moving time marks around , phd f: Right . postdoc c: since our representation in Transcriber uses time marks , it seems like there should be some way of {disfmarker} of using that {disfmarker} benefitting from that . grad e: Right . phd a: Yeah , it wou the advantage would just be that when you brought up a bin you would be able {disfmarker} if you were zoomed in enough in Transcriber to see all the words , professor b: Mm - hmm . phd a: you would be able to , like , have the words sort of located in time , if you wanted to do that . professor b: So {disfmarker} so if we e e even just had a {disfmarker} a {disfmarker} It sounds like w we {disfmarker} {vocalsound} we almost do . phd a: So . professor b: Uh , if we {disfmarker} We have two . postdoc c: We have two . professor b: Yeah . Just ha uh , trying out {pause} the alignment {vocalsound} procedure that you have on that phd a: Mm - hmm . professor b: you could actually get something , um {disfmarker} uh , uh , get an objective measure . Uh {disfmarker} phd f: Mm - hmm . phd a: You mean on {disfmarker} on the hand - marked , um {disfmarker} So we {disfmarker} we only r hav I only looked at actually alignments from one meeting that we chose , professor b: Yeah . phd a: I think MR four , just randomly , um {disfmarker} And {disfmarker} phd f: Actually , not randomly . phd a: Not randomly {disfmarker} phd f: We knew {disfmarker} we knew that it had these insertion errors from {disfmarker} phd a: It had sort of {pause} average recognition performance in a bunch of speakers phd f: Yeah . Yeah . phd a: and it was a Meeting Recorder meeting . Um . But , yeah , we should try to use what you have . I did re - run recognition on your new version of MR one . postdoc c: Oh , good . phd a: I {disfmarker} I mean the {disfmarker} the one with Dan {pause} Ellis in it {vocalsound} and Eric . postdoc c: Good ! Uh - huh . Yeah , exactly . Yeah . Yeah . grad g: I don't think that was the new version . phd a: Um {disfmarker} That {disfmarker} Yeah , actually it wasn't the new new , it was the medium new . postdoc c: OK . phd a: But {disfmarker} but we would {disfmarker} we should do the {disfmarker} the latest version . postdoc c: OK . grad g: Yeah . phd a: It was the one from last week . grad g: You {disfmarker} did you adjust the {disfmarker} the utterance times , um , for each channel ? postdoc c: Yes . Yes , I did . And furthermore , I found that there were a certain number where {disfmarker} {vocalsound} not {disfmarker} not a lot , but several times I actually {vocalsound} moved an utterance from {vocalsound} Adam 's channel to Dan 's or from Dan 's to Adam 's . So there was some speaker identif And the reason was because {vocalsound} I transcribed that at a point before {disfmarker} {vocalsound} uh , before we had the multiple audio available f so I couldn't switch between the audio . I {disfmarker} I transcribed it off of the mixed channel entirely , which meant in overlaps , I was at a {disfmarker} at a terrific disadvantage . phd a: Right . Right . postdoc c: In addition it was before the channelized , uh , possibility was there . And finally I did it using the speakers of my , um {disfmarker} {vocalsound} of {disfmarker} you know , off the CPU on my {disfmarker} on my machine cuz I didn't have a headphone . phd a: Right . postdoc c: So it @ @ , like , I mean {disfmarker} Yeah , I {disfmarker} I mean , i in retrospect {vocalsound} it would 've been good to ha {vocalsound} have got I should 've gotten a headphone . But in any case , um , thi this is {disfmarker} this was transcribed in a {disfmarker} in a , {vocalsound} uh , less optimal way than {disfmarker} than the ones that came after it , and I was able to {disfmarker} you know , an and this meant that there were some speaker identif identifications which were changes . grad g: Well , I know there were some speaker labelling problems , um , after interruptions . postdoc c: Yeah . Fixed that . grad g: Is that what you 're referring to ? I mean , cuz there 's this one instance when , for example , you 're running down the stairs . postdoc c: Oh , well {disfmarker} grad g: I remember this meeting really well . phd d: Yeah . phd a: Don {disfmarker} Don has had {disfmarker} {vocalsound} He knows {disfmarker} he can just read it like a play . grad g: Right . It 's a {disfmarker} Yeah , I 've {disfmarker} I 've {disfmarker} I 'm very well acquainted with this meeting . phd d: Yeah . grad g: Yeah , I can s phd a: " And then she said , and then he said . " grad g: Yeah , I know it by heart . So , um , {vocalsound} there 's one point when you 're running down the stairs . postdoc c: Uh - oh . grad g: Right ? And , like , there 's an interruption . You interrupt somebody , but then there 's no line after that . For example , there 's no speaker identification after that line . postdoc c: Uh - huh . grad g: Is that what you 're talking about ? Or were there mislabellings as far as , like , the a Adam was {disfmarker} ? postdoc c: That was fixed , um , before {disfmarker} i i i I think I I think I understood that pretty {disfmarker} grad g: Yeah . Cuz I thought I let you know about that . postdoc c: Thank you for mentioning . Yeah , no , tha that {disfmarker} That I think went away a couple of versions ago , grad g: Yeah . OK . postdoc c: but it 's good to know . grad g: But you 're actually saying that certain , uh , speakers were mis mis - identified . postdoc c: Yeah . So , with {disfmarker} under {disfmarker} um , uh , listening to the mixed channel , there were times when , as surprising as that is , I got Adam 's voice confused with Dan 's and vice versa {disfmarker} grad g: OK . postdoc c: not for long utterances , grad g: OK . phd a: Yeah . postdoc c: but jus just a couple of places , professor b: Mm - hmm . postdoc c: and embedde embedded in overlaps . The other thing that was w interesting to me was that I picked up a lot of , um , backchannels which were hidden in the mixed signal , phd a: Right . postdoc c: which , you know , I mean , you c not {disfmarker} not too surprising . But the other thing that {disfmarker} I {disfmarker} I hadn't thought about this , but I thou I wanted to raise this when you were {disfmarker} uh , with respect to also a strategy which might help with the alignments potentially , but that 's {disfmarker} When I was looking at these backchannels , they were turning up usually {disfmarker} {vocalsound} very often in {disfmarker} w well , I won't say " usually " {disfmarker} but anyway , very often , I picked them up in a channel {vocalsound} w which was the person who had asked a question . S so , like , someone says " an and have you done the so - and - so ? " And then there would be backchannels , but it would be the person who asked the question . Other people weren't really doing much backchannelling . And , you know , sometimes you have the {disfmarker} Yeah , uh - huh . phd a: Well , that 's interesting . Yeah . postdoc c: I mean , i it wouldn't be perfect , but {disfmarker} but it does seem more natural to give a backchannel when {disfmarker} when you 're somehow involved in the topic , phd a: No , that 's really interesting . professor b: Mm - hmm . postdoc c: and the most natural way is for you to have initiated the topic by asking a question . phd f: Well , phd a: That 's interesting . phd f: I think {disfmarker} No . I think it 's {disfmarker} actually I think what 's going on is backchannelling is something that happens in two - party conversations . postdoc c: Mm - hmm . phd f: And if you ask someone a question , you essentially initiating a little two - party conversation . postdoc c: Yeah . phd a: Well , actu Yeah , when we looked at this {disfmarker} postdoc c: Exactly . phd f: So then you 're {disfmarker} so and then you 're expected to backchannel because the person is addressing you directly and not everybody . postdoc c: Exactly . Exactly my point . An - and so this is the expectation thing that {disfmarker} uh , uh , phd f: Yeah . Yeah . phd a: Mm - hmm . phd f: Right . postdoc c: just the dyadic {disfmarker} phd f: Right . postdoc c: But in addition , you know , if someone has done this analysis himself and isn't involved in the dyad , but they might also give backchannels to verify what {disfmarker} what the answer is that this {disfmarker} that the {disfmarker} the answerer 's given {disfmarker} professor b: H phd a: Right . professor b: I tell you , I say {disfmarker} I say " uh - huh " a lot , phd a: It 's {disfmarker} postdoc c: There you go . phd a: Well , but it 's interesting cuz , uh {disfmarker} professor b: while people are talking to each other . phd a: But there are fewer {disfmarker} I think there are fewer " uh - huhs " . postdoc c: There you go . Yeah . Yeah . phd a: I mean , just from {disfmarker} We were looking at word frequency lists to try to find the cases that we would allow to have the reject words in between in doing the alignment . You know the ones we wouldn't constrain to be next to the other words . postdoc c: Oh , yeah . phd a: And " uh - huh " is not as frequent as it sort of would be in Switchboard , if you looked at just a word frequency list of one - word short utterances . And " yeah " is way up there , but not " uh - huh " . And so I was thinking thi it 's not like {pause} you 're being encouraged by everybody else to keep {pause} talking in the meeting . And uh , that 's all , I I 'll stop there , cuz I I think what you say makes a lot of sense . postdoc c: Well , that 's right . And that would {disfmarker} phd a: But it was sort of {disfmarker} postdoc c: Well , an And what you say is the {disfmarker} is the re uh , o other side of this , which is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and {disfmarker} and these {disfmarker} phd a: Right . There 's just probably less backchannelling in general , postdoc c: Mm - hmm . So that 's good news , really . phd a: even if you consider every other person altogether one person in the meeting , but we 'll find out anyway . We were {disfmarker} I guess the other thing we 're {disfmarker} we 're {disfmarker} I should say is that we 're gonna , um try {disfmarker} compare this type of overlap analysis to Switchboard , where {disfmarker} phd f: And phd a: and CallHome , where we have both sides , so that we can try to answer this question of , you know , {vocalsound} is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard professor b: Mm - hmm . grad e: Mm - hmm . phd a: and we don't know what people are doing . Try to create a paper out of that . professor b: Yeah . I mean , y y you folks have probably {pause} already told me , but were {disfmarker} were you intending to do a Eurospeech submission , or {disfmarker} ? phd a: Um , you mean the one due tomorrow ? professor b: Yeah . phd a: Yeah . Well , we 're still , like , writing the scripts for doing the research , and we will {disfmarker} Yes , we 're gonna try . postdoc c: Mm - hmm . phd a: And I was telling Don , do not {pause} take this as an example of how people should work . professor b: Do as I say , grad g: That 's r phd a: So , {comment} we will try . professor b: don't do as I do . Yeah . phd a: It 'll probably be a little late , grad e: Well {disfmarker} phd a: but I 'm gonna try it . grad e: It is different . In previous years , Eurospeech only had the abstract due by now , not the full paper . phd a: Right . grad g: Right . grad e: And so all our timing was off . I 've given up on trying to do digits . I just don't think that what I have so far makes a Eurospeech paper . phd a: Well , I 'm no We may be in the same position , and I figured {vocalsound} we 'll try , because that 'll at least get us to the point where we have {disfmarker} We have this really nice database format that Andreas and I were working out that {disfmarker} It {disfmarker} it 's not very fancy . It 's just a ASCII line by line format , but it does give you information {disfmarker} phd f: It 's the {disfmarker} it 's the spurt format . phd a: It {disfmarker} Yeah , we 're calling these " spurts " after Chafe . I was trying to find what 's a word for {pause} a continuous region with {pause} pauses around it ? postdoc c: Hmm . professor b: Yeah . I know that th the Telecom people use {disfmarker} use " spurt " for that . postdoc c: Good . phd a: They do ? Oh ! professor b: Yes . phd f: Oh . phd a: Oh . professor b: And that 's {disfmarker} I mean , I {disfmarker} I was using that for a while when I was doing the rate of speech stuff , phd a: I would jus professor b: because I {disfmarker} because I looked up in some books and I found {disfmarker} OK , I wanna find a spurt {vocalsound} in which {disfmarker} phd a: Ah , right ! It 's just , like , defined by the acoustics . professor b: and {disfmarker} an because {disfmarker} cuz it 's another question about how {pause} many pauses they put in between them . grad e: Horrible . phd a: Right . professor b: But how fast do they do {pause} the words within the spurt ? phd a: Right . professor b: Yeah . phd a: Well , that 's what we were calling spurt , grad e: It 's gonna {disfmarker} grad g: you know " Burst " also ? grad e: Burst . grad g: Isn't " burst " is used also ? phd a: so {disfmarker} grad e: Spurt has the horrible name overloading with other {disfmarker} with hardware at ICSI . professor b: Here . Just very locally , yeah . phd a: Well , well , Chafe had this wor I think it was Chafe , or somebody had a {disfmarker} the word " spurt " originally , professor b: But {disfmarker} but that just {disfmarker} phd h: Here @ @ {disfmarker} phd a: and so I {disfmarker} But tha that 's good to know . postdoc c: Actually {disfmarker} phd a: Was thi it 's Chafe ? postdoc c: Well , see , I know S Sue wrote about spurts of development . phd f: So maybe we should talk {disfmarker} phd a: Maybe it was Sue {disfmarker} ? Y postdoc c: But , in any case , I think it 's a good term , phd a: So we have spurts and we have spurt - ify dot shell and spurt - ify professor b: Yeah . postdoc c: and , uh {disfmarker} grad e: Hmm ! professor b: Yeah . postdoc c: And ma maybe {disfmarker} maybe Chafe did . phd f: Uh . phd a: And then it 's got all {disfmarker} it 's a verb now . postdoc c: I know {disfmarker} I know Ch - Chafe dealt with {disfmarker} phd f: So s grad g: That 's cool . phd f: W uh , w postdoc c: Chafe speaks about intonation units . phd a: Yes . Right . postdoc c: But maybe he speaks about spurts as well phd f: We postdoc c: and I just don't know . Yeah , go ahead . grad e: I 've heard " burst " also . phd f: So what we 're doing {disfmarker} uh , this {disfmarker} this is just {disfmarker} maybe someone has s some {disfmarker} some ideas about how to do it better , grad g: Mmm . phd f: but we {disfmarker} So we 're taking these , uh , alignments from the individual channels . We 're {disfmarker} from each alignment we 're producing , uh , one of these CTM files , postdoc c: Great . phd f: which essentially has {disfmarker} it 's just a linear sequence of words with the begin times for every word and the duration . phd a: It looks like a Waves label file almost . Right ? phd f: And {disfmarker} and {disfmarker} and of course {disfmarker} phd a: It 's just {disfmarker} phd f: Right . But it has {disfmarker} one {disfmarker} the first column has the meeting name , so it could actually contain several meetings . Um . And the second column is the channel . Third column is the , um , start times of the words and the fourth column is the duration of the words . And then we 're , um {disfmarker} OK . Then we have a messy alignment process where we actually insert into the sequence of words the , uh , tags for , like , where {disfmarker} where sentence {disfmarker} ends of sentence , question marks , um , {vocalsound} various other things . phd a: Yeah . These are things that we had Don {disfmarker} phd f: Uh . phd a: So , Don sort of , um , propagated the punctuation from the original transcriber {disfmarker} phd f: Right . phd a: so whether it was , like , question mark or period or , {vocalsound} um , you know , comma and things like that , and we kept the {disfmarker} and disfluency dashes {disfmarker} uh , kept those in because we sort of wanna know where those are relative to the spurt overlaps {disfmarker} phd f: Mm - hmm . Right . phd a: sp overlaps , phd f: So {disfmarker} so those are actually sort of retro - fitted into the time alignment . phd a: or {disfmarker} phd f: And then we merge all the alignments from the various channels and we sort them by time . And then there 's a {disfmarker} then there 's a process where you now determine the spurts . That is {disfmarker} Actually , no , you do that before you merge the various channels . So you {disfmarker} you id identify by some criterion , which is pause length {disfmarker} you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight . professor b: Mm - hmm . phd f: And then you merge everything in terms of , you know , linearizing the sequence based on the time marks . And then {vocalsound} you extract the individual channels again , but this time you know where the other people start and end talking {disfmarker} you know , where their spurts start and end . And so you extract the individual channels , uh , one sp spurt by spurt as it were . Um , and inside the words or between the words you now have begin and end {pause} tags for overlaps . So , you {disfmarker} you basically have everything sort of lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech . grad e: Right . phd a: Uh , I mean , I think that 's actually really u useful also phd f: And {disfmarker} phd a: because even if you weren't studying overlaps , if you wanna get a transcription for the far - field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? You have to be able to {pause} get a transcript like {disfmarker} like this anyway , just for doing far - field recognition . So , you know , it 's {disfmarker} it 's sort of {disfmarker} phd f: Yeah . phd a: I thi it 's just an issue we haven't dealt with before , how you time - align things that are overlapping anyway . postdoc c: That 's wonderful . phd f: So {disfmarker} phd a: I mean , i I never thought about it before , grad e: Well {disfmarker} phd f: And {disfmarker} and we {disfmarker} phd a: but {disfmarker} grad e: Y yes . phd f: In {disfmarker} grad e: I mean , s when I came up with the original data {disfmarker} suggested data format based on the transcription graph , there 's capability of doing that sort of thing in there . phd a: Right . But you can't get it directly from the transcription . postdoc c: Mm - hmm . Yeah , that 's right . phd f: Right . Well , this is {disfmarker} this is just {disfmarker} phd a: Yeah , this is like a poor man 's ver formatting version . But it 's , you know {disfmarker} It 's clean , it 's just not fancy . grad e: Right . phd a: Um . phd f: Well , there 's lots of little things . It 's like there 're twelve different scripts which you run and then at the end you have what you want . But , um , at the very last stage we throw away the actual time information . All we care about is whether {disfmarker} that there 's a certain word was overlapped by someone else 's word . So you sort of {disfmarker} at that point , you discretize things into just having overlap or no overlap . Because we figure that 's about the level of analysis that we want to do for this paper . grad e: Mm - hmm . phd f: But if you wanted to do a more fine - grained analysis and say , you know , how far into the word is the overlap , you could do that . phd a: Yeah . phd f: It 's just {disfmarker} it 'll just require more {disfmarker} phd a: Just {pause} sort of huge . phd f: you know , slightly different {disfmarker} postdoc c: What 's interesting is it 's exactly what , um , i in discussing with , um , Sue about this , phd a: Yeah . postdoc c: um , she , um , i i i indicated that that {disfmarker} you know , that 's very important for overlap analysis . phd a: Yeah . It 's {disfmarker} it 's nice to know , phd f: Right . phd a: and also I think as a human , like , I don't always hear these in the actual order that they occur . So I can have two foreground speakers , you know , Morgan an and {vocalsound} um , Adam and Jane could all be talking , and I could align each of them to be starting their utterance at the correct time , and then look where they are relative to each other , and that 's not really what I heard . postdoc c: And that 's another thing she said . phd a: Cuz it 's just hard to do . postdoc c: This is {disfmarker} This is Bever 's {disfmarker} Bever 's effect , phd a: Y Yeah . postdoc c: when {disfmarker} where {disfmarker} In psy ps psycho - linguistics you have these experiments where people have perceptual biases a as to what they hear , phd a: It 's sort of {disfmarker} Yeah , you sort of move things around until you get to a {pause} low information point postdoc c: that {disfmarker} that {disfmarker} Not the best {disfmarker} phd a: and yo then you can bring in the other person . So it 's {vocalsound} actually not even possible , I think , for any person to listen to a mixed signal , even equalize , and make sure that they have all the words in the right order . So , I guess , we 'll try to write this Eurospeech paper . postdoc c: Mm - hmm . Superb . phd a: I mean , we will write it . Whether they accept it {pause} late or not , I don't know . Um , and the good thing is that we have {disfmarker} It 's sort of a beginning of what Don can use to link the prosodic features from each file to each other . phd f: Yeah . professor b: Yeah . That 's the good thing about these pape phd a: So . i You know , might as well . phd f: Plus , mayb phd h: Hmm ? phd a: We - I ju Otherwise we won't get the work done {comment} {vocalsound} on our deadline . phd f: I don't know , m professor b: Yeah . phd f: I mean , u u Jane likes to look at data . Maybe , you know , you could {disfmarker} you could look at this format and see if you find anything interesting . professor b: Yeah . phd f: I don't know . phd a: Yeah . professor b: No , it 's {disfmarker} that 's the good thing about these pape paper deadlines and , uh , you know , class projects , and {disfmarker} {vocalsound} and things like that , postdoc c: Well , what I 'm thinking is {disfmarker} phd f: Yeah . postdoc c: Yeah . phd a: Right . phd f: Mm - hmm . postdoc c: Well , my {disfmarker} phd f: Well th th the other thing that {disfmarker} that {disfmarker} that yo that you usually don't tell your graduate students is that these deadlines are actually not that , um , you know , strictly enforced , professor b: because you {disfmarker} you really get g phd a: Forces you to do the work . postdoc c: Yeah . professor b: Yeah . phd a: Exactly . grad e: Strict . phd f: because {pause} the {disfmarker} professor b: Oh , now it 's out in the public , this {disfmarker} this {disfmarker} this secret information . phd f: because {disfmarker} phd a: Right . professor b: Yeah . postdoc c: I think we can ha phd f: bec b {vocalsound} Nah {disfmarker} phd a: So {disfmarker} grad e: No . professor b: No . postdoc c: Nah . phd f: i Because these {disfmarker} the conference organizers actually have an interest in getting lots of submissions . phd a: Right . grad e: Right . phd f: I mean , a {disfmarker} a monetary interest . professor b: Yeah . phd f: So {disfmarker} {vocalsound} Um . professor b: Th - that 's {disfmarker} that 's true . postdoc c: And good ones , good ones , which sometimes means {pause} a little extra time . phd f: And good submission professor b: That 's {disfmarker} phd f: Right . professor b: That 's true . phd f: Well {disfmarker} That 's another issue , professor b: By th by the way , this is totally unfair , you may {disfmarker} you may feel , phd f: but {disfmarker} professor b: but the {disfmarker} the , uh {disfmarker} the morning meeting folks actually have an {disfmarker} an extra month or so . phd f: Mm - hmm . phd d: Yep . grad e: Yep . The Aurora {disfmarker} there 's a special Aurora {disfmarker} phd a: Uh {disfmarker} phd f: When {disfmarker} professor b: There 's a special Aurora session phd a: Oh . professor b: and the Aurora pe people involved in Aurora have till Ma - uh , early May {pause} or something to turn in their paper . phd f: Mmm . phd a: Oh . phd f: Mmm . phd a: Oh , well maybe we 'll submit to s {comment} {vocalsound} Actually {disfmarker} phd f: Well , then you can just {disfmarker} Maybe you can submit the digits paper on e for the Aurora session . phd h: Yeah . phd a: Yeah . phd d: Yeah . grad e: Oh , I could ! phd a: Yeah . professor b: I if it w grad e: I could submit that to Aurora . professor b: Well {disfmarker} grad e: That would be pretty {disfmarker} pretty {disfmarker} phd f: Yeah . professor b: i it has {disfmarker} phd a: Yeah . professor b:  grad e: S That wouldn't work . professor b: No , it wouldn't work . grad e: It 's not Aurora . professor b: It 's {disfmarker} it 's not the Aurora {disfmarker} I mean , it {disfmarker} it 's {disfmarker} it 's actually the Aurora task . phd a: Maybe they 'll get s grad e: Aurora 's very specific . professor b: It phd a: Well , maybe it won't be after this {vocalsound} deadline {pause} extension . phd f: But {disfmarker} but the people {disfmarker} I mean , a {disfmarker} a paper that is not on Aurora would probably be more interesting at that point phd a: Maybe they 'll {disfmarker} phd f: because everybody 's so sick and tired of the Aurora task . phd d: Yeah . grad e: Oh , I thought you meant this was just the digits section . I didn't know you meant it was Aurora digits . professor b: Yeah . phd f: Well , no . If you {disfmarker} if you have {disfmarker} it 's to {disfmarker} if you discuss some relation to the Aurora task , like if you use the same {disfmarker} professor b: This is not the Aurora task . So they just do a little grep for {disfmarker} phd a: Do {disfmarker} uh , d d Do not {disfmarker} do not {disfmarker} we are not setting a good example . phd f: Um . Well , a relation other than negation , maybe , phd a: This is not a {disfmarker} phd f: um . So . phd a: Anyway . phd f: I don't know . phd a: But the good thing is this does {disfmarker} grad e: Well , I I don't know . I mean , you could {disfmarker} you could do a paper on {pause} what 's wrong with the Aurora task by comparing it to {pause} other ways of doing it . phd f: How well does an Aurora system do on {disfmarker} on {disfmarker} you know , on digits collected in a {disfmarker} in this environment ? phd h:  grad e: Different way . Yeah . phd f: Yeah . professor b: Maybe . phd f: Maybe . grad e: Pretty hokey . professor b: I think it 's a littl little far - fetched . Nah , I mean , the thing is Aurora 's pretty closed community . grad e: Yep . professor b: I mean , you know , the people who were involved in the {disfmarker} {vocalsound} the only people who are allowed to test on that are people who {disfmarker} who made it above a certain threshold in the first round , phd f: Mm - hmm . grad e: It 's very specific . professor b: uh {vocalsound} w in ninety - nine and it 's {disfmarker} it 's sort of a {disfmarker} it 's {disfmarker} not like a {disfmarker} phd f: Well , that 's maybe why they don't f know that they have a crummy system . I mean , a crummy back - end . No , I mean {disfmarker} I mean , seriously , if you {disfmarker} if you have a very {disfmarker} No , I 'm sorry . phd a: Uh , {comment} " beep " {vocalsound} " bee " grad e: I mean , th phd f: No . I didn't mean anybody {disfmarker} any particular system . I meant this H T K back - end . professor b: Oh , you don't like HTK ? phd f: If they {disfmarker} phd h: Yeah . phd f: I don't h I don't have any stock in HTK or Entropic or anything . professor b: No . I mean , this {disfmarker} it it 's the HTK {pause} that is trained on a very limited amount of data . grad e: It 's d it 's very specific . phd f: Right . professor b: Yeah . phd f: But so , if you {disfmarker} But maybe you should , you know , consider more {disfmarker} using more data , or {disfmarker} I mean {disfmarker} professor b: Oh , yeah . I {disfmarker} I really think that that 's true . And they i i phd f: If yo if you sort of hermetically stay within one task and don't look left and right , then you 're gonna {disfmarker} grad e: But they {disfmarker} they had {disfmarker} professor b: i But {disfmarker} grad e: They had something very specific in mind when they designed it . Right ? professor b: Well , u i phd f: Right . grad e: And so {disfmarker} so you can {disfmarker} you can argue about maybe that wasn't the right thing to do , but , you know , they {disfmarker} they {disfmarker} they had something specific . professor b: But , one of the reasons I have Chuck 's messing around with {disfmarker} with the back - end that you 're not supposed to touch {disfmarker} I mean , for the evaluations , yes , we 'll run a version that hasn't been touched . phd f: Mm - hmm . Mm - hmm . professor b: But , uh , one of the reasons I have him messing around with that , because I think it 's sort of an open question that we don't know the answer to . People always say very glibly {vocalsound} that i if you s show improvement on a bad system , that doesn't mean anything , cuz it may not be {disfmarker} {vocalsound} show {disfmarker} uh , because , you know , it doesn't tell you anything about the good system . phd f: Mm - hmm . professor b: And I {disfmarker} I 've always sort of felt that that depends . You know , that if some peopl If you 're actually are getting at something that has some {pause} conceptual substance to it , it will port . phd f: Mm - hmm . professor b: And in fact , most methods that people now use were originally tried with something that was not their absolute {pause} best system at some level . But of course , sometimes it doesn't , uh , port . So I think that 's {disfmarker} that 's an interesting question . If we 're getting {pause} three percent error on , uh , u uh , English , uh , nati native speakers , {vocalsound} um , using the Aurora system , and we do some improvements and bring it from three to two , {vocalsound} do those same improvements bring , uh , th you know , the SRI system from one point three to {disfmarker} you know , to {vocalsound} point eight ? phd f: Hmm . Mm - hmm . grad e: Zero . professor b: Well . You know , so that 's {disfmarker} that 's something we can test . phd f: Mmm . Right . professor b: So . Anyway . phd f: OK . professor b: I think we 've {disfmarker} {vocalsound} we 've covered that one up extremely well . postdoc c: Mm - hmm . phd f: Whew ! professor b: OK . So , um {disfmarker} Yeah . So tha so we 'll {disfmarker} you know , maybe you guys 'll have {disfmarker} have one . Uh , you {disfmarker} you and , uh {disfmarker} and Dan have {disfmarker} have a paper that {disfmarker} that 's going in . phd d: Yeah . professor b: You know , that 's {disfmarker} that 's pretty solid , on the segmentation {pause} stuff . phd d: Yeah . Yeah . I will send you the {disfmarker} the final version , professor b: Yeah . And the Aurora folks here will {disfmarker} will definitely get something in on Aurora , phd d: which is not {disfmarker} phd f: Actually this {disfmarker} this , um {disfmarker} So , there 's another paper . professor b: so . phd f: It 's a Eurospeech paper but not related to meetings . But it 's on digits . So , um , uh , a colleague at SRI developed a improved version of MMIE training . professor b: Uh - huh . phd f: And he tested it mostly on digits because it 's sort of a {disfmarker} you know , it doesn't take weeks to train it . professor b: Right . phd f: Um . And got some very impressive results , um , with , you know , discriminative , uh , Gaussian training . Um , you know , like , um , error rates {pause} go from {disfmarker} I don't know , in very noisy environment , like from , uh , uh {disfmarker} I for now I {disfmarker} OK , now I have the order of magnit I 'm not sure about the order of magnitude . Was it like from ten percent to {vocalsound} eight percent or from e e you know , point {disfmarker} you know , from one percent to point eight percent ? professor b: H i it got {disfmarker} it got better . phd f: I mean , it 's a {disfmarker} professor b: Yeah , yeah . phd d: Yeah . phd f: It got better . That 's the important thing . grad e: Hey , that 's the same percent relative , phd f: Yeah . But it 's {disfmarker} grad e: so {disfmarker} phd f: Yeah . Right . professor b: Yeah . phd f: It 's , uh , something in {disfmarker} professor b: Yeah . grad e: Twenty percent relative gain . phd f: Right . professor b: Yeah . phd f: Yeah . professor b: Yeah . Um , {vocalsound} let 's see . I think the only thing we had left was {disfmarker} unless somebody else {disfmarker} Well , there 's a couple things . Uh , one is {pause} anything that , um , {vocalsound} anybody has to say about Saturday ? Anything we should do in prep for Saturday ? Um {disfmarker} I guess everybody knows about {disfmarker} I mean , u um , Mari was asking {disfmarker} was trying to come up with something like an agenda and we 're sort of fitting around people 's times a bit . But , um , {vocalsound} clearly when we actually get here we 'll {pause} move things around this , as we need to , but {disfmarker} so you can't absolutely count on it . phd d: OK . professor b: But {disfmarker} but , uh {disfmarker} phd d: Yeah . phd a: Are we meeting in here probably or {disfmarker} ? OK . professor b: Yeah . That was my thought . phd a: Yeah . professor b: I think this is {disfmarker} phd f: Are we recording it ? phd a: We won't have enough microphones , professor b:  phd a: but {disfmarker} professor b: u No . I {disfmarker} I hadn't in intended to . phd a: There 's no way . professor b: We won we wanna {disfmarker} I mean , they 're {disfmarker} there 's gonna be , uh , Jeff , Katrin , Mari and two students . phd f: OK . professor b: So there 's five {pause} from there . grad e: And Brian . professor b: And Brian 's coming , phd f: But you know th professor b: so that 's six . grad e: And plus all of us . phd f: Mm - hmm . professor b: Uh {disfmarker} phd f: Can use the Oprah mike . phd a: Depends how fast you can {pause} throw it . grad e: It seems like too many {disfmarker} too much coming and going . phd a: It 's just {disfmarker} Yeah . phd f: Mm - hmm . phd a: We don't even have enough channel {disfmarker} professor b: Well {disfmarker} phd f: Because it would be a different kind of meeting , phd d: Yeah . phd f: that 's what I 'm {disfmarker} professor b: Well {disfmarker} phd f: But {disfmarker} phd h: Yeah . professor b: I hadn't {pause} really thought of it , phd f: Maybe just {disfmarker} maybe not the whole day professor b: but {disfmarker} phd f: but just , you know , maybe some {disfmarker} I mean , professor b: Maybe part of it . phd f: part of it ? professor b: Maybe part of it . grad e: Make everyone read digits . professor b: At the same time . phd a: At the same time . grad e: At the same time . phd f: Please . phd h:  professor b: Yeah . phd a: We c professor b: I don't know . phd a: That 's their initiation into our professor b: Any phd a: w grad e: Into our {disfmarker} our {disfmarker} our cult . phd a: Yeah , our {disfmarker} Yeah , our {disfmarker} phd f: Maybe the sections that are not right afte you know , after lunch when everybody 's still munching and {disfmarker} phd a: So can you send out a schedule once you know it , jus ? professor b: OK . Well {disfmarker} phd a: Is {disfmarker} is there a r ? professor b: OK . Yeah . I guess I sent it around a little bit . phd a: There 's a res Is it changed now , or {disfmarker} ? professor b: But {disfmarker} I hadn't heard back from Mari after I {disfmarker} I u u uh , brought up the point abou about Andreas 's schedule . So , {vocalsound} um , maybe when I get back there 'll be {pause} some {disfmarker} some mail from her . phd a: OK . professor b: So , I 'll make a {disfmarker} postdoc c: I 'm looking forward to seeing your representation . That 'd be , uh {disfmarker} phd a: And w we should get {pause} the two meetings from y postdoc c: I 'd like to see that . Yeah . phd a: I mean , I know about the first meeting , um , but the other one that you did , the NSA one , which we {pause} hadn't done cuz we weren't running recognition on it , because the non - native speaker {disfmarker} postdoc c: Mm - hmm . phd a: there were five non - native speakers . postdoc c: Mm - hmm . I see . Mm - hmm . phd a: But , it would be useful for the {disfmarker} to see what we get {pause} with that one . So . postdoc c: Great . OK . It 's , uh , two thousand eleven twenty - one one thousand . phd a: Yeah , three . Right . So {disfmarker} postdoc c: Great . I sent email when I finished the {disfmarker} that one . phd a: N S A three , I think . postdoc c: That was sort of son Yeah , that 's right . That 's right . That 's much simpler . phd a: I don't know what they said but I know the number . professor b: Th - that part 's definitely gonna confuse somebody who looks at these later . phd f: Right . professor b: I mean , this is {disfmarker} we we 're recording secret NSA meetings ? phd f: Um . Not the {disfmarker} professor b: I mean , it 's {disfmarker} phd f: Yeah . postdoc c: Yeah . Not that NSA . phd f: Uh . The {disfmarker} th the {disfmarker} phd a: They are hard to understand . professor b: It 's network services and applications . phd f: Wait . phd a: They 're very , uh , out there . phd f: The {disfmarker} phd a: I have no idea what they 're talking about . professor b: Yeah . phd f: The , um {disfmarker} th the other good thing about the alignments is that , um , it 's not always the machine 's fault if it doesn't work . So , you can actually find , um , phd a: It 's the person 's fault . phd f: problem {disfmarker} uh , proble phd a: It 's Morgan 's fault . phd f: You can find {disfmarker} professor b: It 's always Morgan 's fault . phd f: You can find , uh , problems with {disfmarker} with the transcripts , um , you know , grad e: Oh . phd a: Yeah . phd f: and go back and fix them . phd a: Tha - There are some cases like where the {disfmarker} the wrong speaker {disfmarker} uh , these ca Not a lot , but where the {disfmarker} the wrong person {disfmarker} the {disfmarker} the speech is addre attached to the wrong speaker phd f: But {disfmarker} phd a: and you can tell that when you run it . Or at least you can get {pause} clues to it . postdoc c: Interesting . phd a: So these are from the early transcriptions that people did on the mixed signals , like what you have . postdoc c: I guess it does w Mm - hmm . It also raises the possibility of , um , using that kind of representation {disfmarker} I mean , I don't know , this 'd be something we 'd wanna check , {comment} but maybe using that representation for data entry and then displaying it on the channelized , uh , representation , cuz it {disfmarker} I think that the {disfmarker} I mean , my {disfmarker} my preference in terms of , like , looking at the data is to see it {pause} in this kind of musical score format . phd a: Mm - hmm . postdoc c: And also , s you know , Sue 's preference as well . phd a: Yeah , if you can get it to {disfmarker} postdoc c: And {disfmarker} and {disfmarker} but , I mean , this {disfmarker} if this is a better interface for making these kinds of , uh , you know , lo clos local changes , then that 'd be fine , too . I don't {disfmarker} I have no idea . I think this is something that would need to be checked . Yeah . professor b: OK . Th - the other thing I had actually was , I {disfmarker} I didn't realize this till today , but , uh , this is , uh , Jose 's last day . grad e: Yeah . phd h: Is my last {disfmarker} my last day . phd a: Oh ! postdoc c: Oh . phd f: Oh ! grad e: You 're not gonna be here tomorrow ? phd h: My {disfmarker} {vocalsound} my last meeting {pause} about meetings . grad e: Oh , that 's right . Tomorrow {disfmarker} phd h: Yeah . phd d: The last meeting meeting ? phd h: Because , eh , I leave , eh , the next Sunday . grad e: It 's off . phd a: Oh . phd f: Mm - hmm . phd h: I will come back to home {disfmarker} to Spain . professor b: Yeah . phd a: Oh . professor b: I d so I {disfmarker} I jus phd f: Mm - hmm . phd h: And I {disfmarker} I would like to {disfmarker} to {disfmarker} to say thank you very much , eh , to all people {pause} in the group and at ICSI , phd f: Mm - hmm . grad e: Yeah . It was good having you . phd f: Mmm . phd a: Yeah . phd h: because I {disfmarker} I enjoyed @ @ very much , phd f: Mmm . phd h: uh . And I 'm sorry by the result of overlapping , because , eh , {vocalsound} I haven't good results , eh , yet but , eh , {vocalsound} I {disfmarker} {vocalsound} I pretend {comment} to {disfmarker} to continuing out to Spain , eh , during the {disfmarker} the following months , professor b: Uh - huh . phd h: eh , because I have , eh , another ideas but , eh , I haven't enough time to {disfmarker} to {disfmarker} {vocalsound} with six months it 's not enough to {disfmarker} {vocalsound} to {disfmarker} to research , grad e: Yep . professor b: Yeah . phd h: eh , and e i I mean , if , eh , the topic is , eh , so difficult , uh , in my opinion , there isn't {disfmarker} professor b: Yeah . Maybe somebody else will come along and will be , uh , interested in working on it and could start off from where you are also , you know . They 'd make use of {disfmarker} of what you 've done . phd h: Yeah . professor b: Yeah . phd h: Yeah . But , eh , I {disfmarker} I will try to recommend , eh , at , eh , {vocalsound} the Spanish government but , eh , the following @ @ scholarship , eh , eh , {vocalsound} eh , will be here {pause} more time , because eh , i in my opinion is {disfmarker} is better , {vocalsound} eh , for us {pause} to {disfmarker} to spend more time here and to work more time i i in a topic . professor b: Yeah , it 's a very short time . phd h: No ? But , uh {disfmarker} professor b: Yeah . Yeah . grad e: Yeah , six months is hard . phd h: Yeah . It is . grad e: I think a year is a lot better . phd h: Yeah . professor b: Yeah . phd h: It 's difficult . You {disfmarker} e you have , eh {disfmarker} you are lucky , and you {disfmarker} you find a solution {comment} in {disfmarker} in {disfmarker} in some few tim uh , months , eh ? OK . But , eh , I think it 's not , eh , common . But , eh , anyway , thank you . Thank you very much . Eh , I {disfmarker} I bring the chocolate , eh , to {disfmarker} {vocalsound} {vocalsound} to tear , uh , with {disfmarker} with you , phd a: Oh . postdoc c: Ah . phd f: Mmm . postdoc c: Nice . phd h: uh . I {disfmarker} I hope if you need , eh , something , eh , from us in the future , I {disfmarker} I will be at Spain , {vocalsound} to you help , uh . professor b: Well . grad e: Great . postdoc c: Great . phd a: Right . professor b: Thank you , Jose . postdoc c: Thank you . phd h: And , thank you very much . phd f: Have a good trip . professor b: Yeah . postdoc c: Yeah . phd f: Keep in touch . phd h: Thank you . professor b: Yeah . OK . I guess , uh , unless somebody has something else , we 'll read {disfmarker} read our digits grad e: Digits ? professor b: and we 'll get our {disfmarker} phd d: Uh . professor b: get our last bit of , uh , Jose 's {disfmarker} Jose {disfmarker} Jose 's digit {disfmarker} phd d: Oops . grad e: Are we gonna do them simultaneously or {disfmarker} ? phd h: You {disfmarker} eh {disfmarker} professor b: Uh , I 'm sorry ? phd h: Ye - ye you prefer , eh , to eat , eh , chocolate , eh , at the coffee break , eh , at the {disfmarker} ? {vocalsound} Or you prefer now , before after {disfmarker} ? postdoc c: Well , we have a time {disfmarker} phd f: No , we prefer to keep it for ourselves . phd d: During {disfmarker} postdoc c: Well , we have a s a time {disfmarker} time constraint . phd f: Yeah , yeah . phd d: during digits . professor b: So keep it away from that end of the table . postdoc c: Yeah . phd f: Yeah . phd h: Yeah . phd a: Why is it that I can read your mind ? postdoc c: Yeah . grad e: Well , we 've gotta wait until after di after we take the mikes off . phd d: No , no . grad e: So are we gonna do digits simultaneously phd a: You {disfmarker} This is our reward if we {pause} do our digi professor b: Well ? Yeah . postdoc c: OK . phd d: Yeah . grad e: or what ? phd d: Simultaneous digit chocolate task . phd h: I {disfmarker} I think , eh , it 's enough , eh , for more peopl for more people {pause} after . professor b: We 're gonna {disfmarker} we 're gonna do digits at the same {disfmarker} phd a: Oh . phd f: Mmm ! postdoc c: That 's nice . phd h: But , eh {disfmarker} phd f: Mm - hmm . phd a: Oh , thanks , Jose . professor b: Um . postdoc c: Wow . phd h: To Andreas , the idea is {disfmarker} is good . {vocalsound} s To eat here . professor b: Well {disfmarker} phd f: Mmm . postdoc c: Wow . Very nice . phd f: Oh . phd a: Oh , wow . professor b: Tha - that 's {disfmarker} that looks great . phd f: Oh , yeah . Th - it doesn't {disfmarker} it won't leave this room . professor b: Alright , so in the interest of getting to the {disfmarker} phd a: We could do digits while other people eat . phd d: Yeah . phd a: So it 's background crunching . phd d: Yeah . phd h: Yeah . phd f: Mmm . phd a: We don't have background chewing . postdoc c: Nice . phd h: Is , eh , a {disfmarker} another acoustic event . phd d: Background crunch . Yeah . phd a: No , we don't have any data with background eating . phd f: Mmm . phd d: Yeah . phd a: I 'm serious . You professor b: She 's {disfmarker} she 's serious . phd a: I am serious . grad e: It 's just the rest of the digits {disfmarker} the rest of the digits are very clean , professor b: She is serious . phd f: Mmm . phd a: Well {disfmarker} ? phd h: Are you {disfmarker} ? Oh , they 're clean . phd d: Yeah ! grad e: um , without a lot of background noise , phd a: And it {disfmarker} You have to write down , like , while y what you 're {disfmarker} what ch chocolate you 're eating grad e: so I 'm just not sure {disfmarker} phd a: cuz they might make different sounds , like n nuts {disfmarker} chocolate with nuts , chocolate without nuts . postdoc c: Oh . professor b: Um {disfmarker} phd d: Crunchy frogs . phd f: Chocolate adaptation . professor b: Actually {disfmarker} {vocalsound} actually kind of careful cuz I have a strong allergy to nuts , so I have to sort of figure out one without th phd a: That w Oh , yeah , they {disfmarker} they might . professor b: It 's hard to {disfmarker} hard to say . phd a: Maybe those ? They 're so {disfmarker} I don't know . professor b: I don't know . Um {disfmarker} phd a: This is {disfmarker} You know , this is a different kind of speech , professor b: Well {disfmarker} phd h: Take {disfmarker} take several . phd a: looking at chocolates , deciding {disfmarker} phd f: Mmm . phd a: you know , it 's another style . professor b: Yeah . I may {disfmarker} I may hold off . phd f: Mmm . professor b: But if I was {disfmarker} eh , but maybe I 'll get some later . Thanks . phd f: Mmm . professor b: Well {disfmarker} well , why don't we {disfmarker} ? He {disfmarker} he 's worried about a ticket . Why don't we do a simultaneous one ? phd a: OK . professor b: Simultaneous one ? postdoc c: OK . grad e: OK . phd f: Mmm . phd a: And you laughed at me , too , f the first time I said that . professor b: OK . grad e: Remember to read the transcript number , please . phd f: Right . phd h: OK . professor b: I have to what ? phd d: Oops . phd h: Yeah . phd a: You laughed at me , too , the first time I sa said {disfmarker} professor b: I did , phd a: You really shouldn't , uh , te professor b: and now I love it so much . grad e: OK , everyone ready ? phd a: You have to sort of , um {disfmarker} Jose , if you haven't done this , you have to plug your ears while you 're t talking professor b: W wait {disfmarker} wait a minute {disfmarker} wait a minute . W we want {disfmarker} we want {disfmarker} phd a: so that you don't get confused , I guess . professor b: we want it synchronized . phd a: Yeah . Oh , you 've done this one before ? postdoc c: Hey , you 've done this before . Haven't you ? phd h: Yeah . phd d: That 's {disfmarker} phd a: Together ? postdoc c: You 've read {pause} digits together with us , haven't you {disfmarker} I mean , at the same time ? phd a: I 'm not {disfmarker} we {disfmarker} we {disfmarker} Oh , and you haven't done this either . professor b: OK . postdoc c: Oh , you haven't ! phd h: No . postdoc c: Oh , OK . phd d: Oh , yeah . phd a: I the first time is {pause} traumatic , professor b: We phd a: but {disfmarker} professor b: Y {vocalsound} Yeah , bu postdoc c: Oh , and the groupings are important , phd h: Mmm . postdoc c: so yo you 're supposed to pause between the groupings . phd h: The grouping . professor b: Yeah . phd h: Yeah . professor b: OK . So , uh {disfmarker} phd f: You mean that the {disfmarker} the grouping is supposed to be synchronized ? professor b: No , no . postdoc c: No . grad e: Yeah , sure . phd f: No ? phd a: That 'd be good . professor b: Synchronized digits . postdoc c: No . phd f: No ? phd a: We - we 'll give everybody the same sheet phd f: It 's like a {disfmarker} like a Greek {disfmarker} like a Greek choir ? phd a: but they say different {disfmarker} phd f: You know ? professor b: Yes . grad e: Hey , what a good idea . phd f: Like {disfmarker} grad e: We could do the same sheet for everyone . phd f: Yeah . grad e: Have them all read them at once . phd a: Well , different digits phd d: Eh {disfmarker} phd a: but same groupings . grad e: Or {disfmarker} or just same digits . phd a: So they would all be {disfmarker} Yeah . postdoc c: Yeah . That 'd be good . grad e: See if anyone notices . professor b: There 's so many possibilities . postdoc c: And then {disfmarker} then we can sing them next time . professor b: Uh . OK , why don't we go ? Uh , one two three {disfmarker} Go ! postdoc c: OK . Mmm ! professor b: And Andreas has the last word . grad e: Did you read it twice or what ? phd a: He 's try No , he 's trying to get good recognition performance . postdoc c: He had the h phd h: Yeah . postdoc c: He had the {disfmarker} the long form . phd h: Yeah . grad e: And we 're off . phd f: No .